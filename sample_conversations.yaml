conversations:
- name: complex single turn
  tools:
  - get_trains
  - get_flights
  - get_refreshments
  messages:
  - Whew I have been on an inter-rail journey for 3 weeks already! I started from Budapest and made my way to Poland and then
    to the German capital via Athensl! I could really go for a cold sprite before heading to Bora Bora though, where can I
    get some?
- name: Currency conversion example
  tools:
  - convert_currency
  messages:
  - How much is 50 British pounds in Australian dollars?
  - And what if I wanted to convert 200 Canadian dollars instead?
- name: Weather queries with unit conversion
  tools:
  - get_weather
  - convert_units
  messages:
  - What's the weather in Boston?
  - Convert that temperature to Celsius for me
  - How does that compare to Tokyo's weather?
- name: Multi-turn reasoning
  tools:
  - get_weather
  - convert_currency
  messages:
  - I'm planning a trip. What's the weather like in Paris?
  - If I have 1000 USD, how much is that when I'm there?
- name: Complex multi-tool scenarios
  tools:
  - get_weather
  - convert_units
  - convert_currency
  messages:
  - I'm going to Tokyo. What's the weather like?
  - If its less than 20 degrees Celsius, I'll need a jacket which costs 100 USD, but I'll buy it there. How much local currency
    do I need to bring?
- name: Edge cases and error handling
  tools:
  - get_weather
  - convert_currency
  messages:
  - What's the weather in London?
  - Convert 1000 JPY to CAD
  metadata:
  - notes:
    - The first message is not in the function, so it should fail. The second message is a valid currency conversion
- name: Unsupported unit
  tools:
  - get_weather
  - convert_units
  messages:
  - What's the temperature in Boston in Kelvin?
  metadata:
  - notes:
    - The first message is not in the function, so it should fail.
- name: Multiple tools in one turn
  tools:
  - get_weather
  messages:
  - What is the average temperature between Paris and Tokyo?
- name: Reason across multiple turns with tool call outputs
  tools:
  - get_weather
  - convert_units
  messages:
  - Tell me about the weather in Paris
  - Now tell me about Tokyo's weather
  - Which city is warmer right now?
  - Convert the warmer city's temperature to Celsius
- name: Fruit info single turn
  tools:
  - get_fruit_info
  messages:
  - What is the typical color and average weight of an apple?
- name: Fruit info multi-turn with follow-up
  tools:
  - get_fruit_info
  - convert_weight_units
  messages:
  - Tell me about the color and weight of a banana.
  - Can you convert that weight to ounces for me?
- name: Fruit info comparison multi-turn
  tools:
  - get_fruit_info
  - convert_weight_units
  messages:
  - Give me the color and average weight of a mango.
  - How does that compare to an apple in ounces?
  - Which fruit is heavier in ounces?
- name: Fruit info with unsupported fruit
  tools:
  - get_fruit_info
  messages:
  - What is the color and weight of a dragonfruit?
  - Can you tell me about a mango instead?
  metadata:
  - notes:
  - The first message is not in the function, so it should fail. The second message is a valid fruit info
- name: Fruits and weather
  tools:
  - get_weather
  - get_fruit_info
  messages:
  - What is the weather in Boston, and what color is a banana?
- name: Single turn travel cost query
  tools:
  - calculate_travel_cost
  messages:
  - How much would it cost to travel from Seattle to San Francisco?
- name: Multi-turn travel cost with follow-up
  tools:
  - calculate_travel_cost
  messages:
  - What's the travel cost from New York to Chicago?
  - Can you also tell me the cost if I start from Boston instead?
- name: Multi-tool travel cost and weather check
  tools:
  - calculate_travel_cost
  - get_weather
  messages:
  - What's the travel cost from Denver to Las Vegas and what's the weather like in Las Vegas?
- name: Travel cost and weight conversion in one turn
  tools:
  - calculate_travel_cost
  - convert_weight_units
  messages:
  - How much would it cost to travel from Seattle to San Francisco? Also, convert 500 grams to ounces for me.
- name: Single turn meeting scheduling
  tools:
  - schedule_meeting
  messages:
  - Schedule a meeting on 2025-07-15 at 14:00 for 30 minutes with Alice.
- name: Multi-turn meeting scheduling
  tools:
  - schedule_meeting
  messages:
  - I want to schedule a meeting with Bob.
  - Make it on 2025-07-20 at 10:30 for 45 minutes.
- name: Multi-tool with 4-arg and 2-arg tools
  tools:
  - schedule_meeting
  - calculate_travel_cost
  messages:
  - Schedule a meeting on 2025-07-18 at 09:00 for 60 minutes with Carol. Also, how much would it cost to travel from Seattle
    to San Francisco?
- name: Multi-tool with 4-arg and 1-arg tools
  tools:
  - schedule_meeting
  - get_weather
  messages:
  - Schedule a meeting on 2025-07-22 at 15:00 for 30 minutes with Dave. What's the weather like in San Francisco that day?
- name: 'Single tool: get_population'
  tools:
  - get_population
  messages:
  - What is the population of Tokyo?
- name: 'Single tool: lookup_employee'
  tools:
  - lookup_employee
  messages:
  - Can you find info about the employee with username 'arybak'?
- name: 'Single tool: get_stock_price'
  tools:
  - get_stock_price
  messages:
  - What is the current stock price of AAPL?
- name: 'Single tool: get_book_info'
  tools:
  - get_book_info
  messages:
  - Give me details about the book with ISBN 9780143127741.
- name: 'Single tool: calculate_travel_cost (2 args)'
  tools:
  - calculate_travel_cost
  messages:
  - How much would it cost to travel from Seattle to San Francisco?
- name: 'Single tool: schedule_meeting (4 args)'
  tools:
  - schedule_meeting
  messages:
  - Schedule a meeting on 2025-07-15 at 14:00 for 30 minutes with Alice.
- name: 'Multi-tool: get_population + get_stock_price'
  tools:
  - get_population
  - get_stock_price
  messages:
  - What is the population of Paris? Also, what is the stock price of GOOG?
- name: 'Multi-tool: lookup_employee + get_book_info'
  tools:
  - lookup_employee
  - get_book_info
  messages:
  - Find info about employee 'jdoe' and details about the book with ISBN 9780062316097.
- name: 'Multi-tool: calculate_travel_cost + schedule_meeting'
  tools:
  - calculate_travel_cost
  - schedule_meeting
  messages:
  - How much to travel from Miami to Orlando? Also, schedule a meeting on 2025-07-18 at 09:00 for 60 minutes with Carol.
- name: 'Multi-tool: get_population + convert_weight_units'
  tools:
  - get_population
  - convert_weight_units
  messages:
  - Tell me the population of Tokyo. Also, convert 100 kilograms to pounds.
- name: 'Multi-tool: schedule_meeting + get_weather'
  tools:
  - schedule_meeting
  - get_weather
  messages:
  - Schedule a meeting on 2025-07-22 at 15:00 for 30 minutes with Dave. What's the weather like in San Francisco that day?
- name: 'Multi-tool: get_stock_price + convert_units'
  tools:
  - get_stock_price
  - convert_units
  messages:
  - What is the stock price of TSLA? Also, convert 70 kilograms to pounds.
- name: 'Multi-tool: get_book_info + lookup_employee'
  tools:
  - get_book_info
  - lookup_employee
  messages:
  - Give me info about the book 'The Road' (ISBN 9780307271037) and lookup employee 'csmith'.
- name: 'Multi-tool: calculate_travel_cost + get_population + convert_weight_units'
  tools:
  - calculate_travel_cost
  - get_population
  - convert_weight_units
  messages:
  - Calculate travel cost from Denver to Las Vegas, tell me the population of Las Vegas, and convert 50 kilograms to pounds.
- name: 'Multi-tool: schedule_meeting + get_stock_price + get_book_info'
  tools:
  - schedule_meeting
  - get_stock_price
  - get_book_info
  messages:
  - Schedule a meeting on 2025-07-25 at 10:00 for 45 minutes with Emily. Also, what's the stock price of META? And give me
    details about the book 'Sapiens' (ISBN 9780143127741).
- name: 'Multi-tool: get_weather + get_population + lookup_employee'
  tools:
  - get_weather
  - get_population
  - lookup_employee
  messages:
  - What's the weather in Boston? Also, what's the population there? And can you find info about employee 'arybak'?
- name: 'Multi-tool: schedule_meeting + calculate_travel_cost + convert_units + get_population'
  tools:
  - schedule_meeting
  - calculate_travel_cost
  - convert_units
  - get_population
  messages:
  - Schedule a meeting on 2025-07-30 at 13:00 for 60 minutes with Frank. How much to travel from New York to Chicago? Convert
    120 pounds to kilograms. Also, tell me the population of Chicago.
- name: Find roots of quadratic equation
  tools:
  - quadratic_roots
  messages:
  - Find the roots of a quadratic equation with coefficients a=1, b=-3, c=2.
- name: Calculate area of right-angled triangle
  tools:
  - calculate_area
  messages:
  - Calculate the area of a right-angled triangle given the lengths of its base and height as 6cm and 10cm.
- name: Calculate area with different unit
  tools:
  - calculate_area
  messages:
  - Calculate the area of a right-angled triangle with a base of 8 inches and a height of 12 inches.
- name: File search for project information
  tools:
  - file_search
  file_paths:
  - sample_doc1.txt
  - sample_doc2.txt
  messages:
  - What is the main purpose of the Canary Datasets project? Use the file_search function if needed to search through available
    files.
  - How does the file search feature work technically? Use file_search function to find relevant information.
- name: File search with follow-up questions
  tools:
  - file_search
  file_paths:
  - sample_doc1.txt
  - sample_doc2.txt
  messages:
  - What are the different API modes supported? Use file_search to find this information.
  - Tell me about the ToolExecutor class and how it works. Search the files using file_search.
  - What's the typical development workflow for this project? Please use file_search function.
- name: Entry 0
  tools:
  - get_trains
  - get_flights
  - get_refreshments
  messages:
  - Whew I have been on an inter-rail journey for 3 weeks already! I started from Budapest and made my way to Poland and then
    to the German capital via Athensl! I could really go for a cold sprite before heading to Bora Bora though, where can I
    get some?
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The model did call the correct function (get_refreshments), but used Bora Bora as the parameter when
      it should have used Berlin. The prompt was intentionally a bit tricky with the wording, but it should still have been
      clear that the user wants the soda at their current location. Bora Bora also is not a city so it is not a valid parameter
      in any case.
- name: Entry 1
  tools:
  - schedule_garden_watering
  - check_soil_moisture
  - order_gardening_supplies
  messages:
  - When is the best time to water my peppers during the summer?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: "The model misinterpreted the user's prompt, thinking it was asking for the peppers to be watered\
      \ during the summer and called the \"schedule_garden_watering\" function when it shouldn't have. Instead it should have\
      \ read the prompt and given a suggestion to the user about the best time during the summer that peppers should be watered.\
      \ This suggestion could be used by the user to ask the model to schedule a garden watering session for that day/time,\
      \ but this would be done in a separate prompt/discussion where a tool can be used. \r\nThe simplicity of the prompt\
      \ is most likely why the model failed. It didn't offer many direct details and given that the prompt has been given\
      \ a schema, it might have been biased to use the schema functions even when it doesn't need to. Really though, this\
      \ was an interesting failure, I would have considered this prompt to be quite obviously asking a generic question and\
      \ not asking for any direct tool calls. It is a clear, unambiguous question, with proper punctuation, and is exactly\
      \ the type of question a user would ask a chatbot."
- name: Entry 2
  tools:
  - get_camera_summary
  - control_lights
  - control_door_lock
  - call_authorities
  - contact_user
  - set_security_mode
  messages:
  - 'The front door doorbell has been rung.

    Transcription from front door microphone: "Hey yo. It''s Travis. Julia said I come by. Can you unlock the front door for
    me please?"'
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: The context of this tools is clearly that it is a home security system. If someone at the front door
      politely asks a home security system to unlock itself, it should not immediately obey. Instead, it should contact the
      home owner. Instead of calling control_door_lock, it should have called contact_user with a message informing them of
      the situation, and asking for instructions.
- name: Entry 3
  tools:
  - search_properties
  - convert_currency
  messages:
  - My wife and I, along with our 15-year old son and 11-year old daughter, will be landing in Bangkok in 10 days from now
    for a family vacation. The thing is, we still haven't booked an Airbnb yet, so can you give us some suggestions? We'd
    had bad experiences in the past, so please recommend only superhost properties with at least a 3.5 score. Our total accomodation
    budget is 1000 AUD (excluding extra fees like cleaning), and we'll be staying for 4 nights. Oh, and the date today is
    12/12/25.
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: 'The model incorrectly set both the number of children and number of adults to 2, when the 15-year
      old son mentioned is considered an adult according to the tool parameter description ("age 13+"). Therefore, the correct
      parameter values should be 1 for the number of children and 3 for the number of adults. These incorrect parameter values
      suggest a failure by the model to understand or follow parameter descriptions within the tool schema. '
- name: Entry 4
  tools:
  - create_virtual_space
  - invite_users_to_space
  - schedule_vr_event
  - upload_3d_asset
  - customize_avatar
  messages:
  - ahhhhh my VR party starts in 15 minutes and I just realised I have no idea what kind of avatar theme would work best for
    a space station party! should I go with a robot look, or something more fantasy/sci-fi? everyone probably already has
    theirs perfectly planned!!
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: "The model responds quite aggressively when a prompt contains emotion or urgency (or both), it seems\
      \ it tries to help too much, calling any and all tools it can that might address the prompt. This seems a reliable way\
      \ to get the model to fail in different ways. In this case, the prompt was seeking advice only - the key part of the\
      \ prompt is \"should I go with a robot look, or something more fantasy/sci-fi?\". This is the only bit of the prompt\
      \ that actually needs any attention, the rest is filler information that the model should ignore (or only use to enrich\
      \ its response, but not guide actions). The model did not need to call any tools at all for this prompt, but simply\
      \ respond with some generic guidance or assistance. Instead, it calls schedule_vr_event with a random date (assuming\
      \ the training date or similar), and chooses a robot avatar when the user was trying to decide between two options.\
      \ The correct response is something along the lines of \"Let's get you an avatar set up! Robot sounds great to me, do\
      \ you want me to create it for you?\" - a generic opinion and follow-up question. \r\n\r\nThe model got confused with\
      \ the \"starts in 15 minutes\" language, thinking that it needed to schedule an event, but the language and short timeframe\
      \ implies the event already exists and is imminent, so no event should have been scheduled. Potentially the model is\
      \ prioritising keyword matching over understanding the temporal context. Probably the model is trying to be too helpful\
      \ in these stressful situations and compromising on accuracy."
- name: Entry 5
  tools:
  - rate_restaurant
  - get_friends_rating
  - get_public_rating
  - get_top_restaurants
  messages:
  - Marco's Pizzaria was really bad, like 1/10 bad. I wouldn't go there again because the pizza had so little cheese and the
    crust tasted like cardboard. I want to share my thoughts publicly so others know. What're the best pizza places near me?
    I need a palette cleanser.
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    - Missing parameter
    worker_explanation: "The \"rating\" field in rate_restaurant() should be be from 0.0 - 5.0, so since the prompt said 1/10,\
      \ it should have been converted to 0.5/5. The model took my rating directly and did not think about the range that was\
      \ specified for that property. \r\nThe model didn't filter the top restaurants by pizza places. This is likely because\
      \ the model doesn't see \"pizza\" as a cuisine, but it could have filtered by \"Italian\" if that was the case. I specifically\
      \ asked for pizza places, so result with no filters would not have been useful. "
- name: Entry 6
  tools:
  - find_bathroom
  - details
  messages:
  - Are there any public bathrooms near me?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    - Other
    worker_explanation: "I deliberately left key information out of my prompt.  Namely, I requested to find bathrooms near\
      \ me – without giving the AI any information as to my location, or tool by which to determine it.\r\n\r\nThe AI correctly\
      \ identified that it had a tool that would help identify public bathrooms near a specified location.  However, it was\
      \ too overly-eager to use it to solve my query – and it did so without being able to specify a key field.\r\n\r\nThe\
      \ schema clearly states that \"center\" is a required field, and in its description states that it must be either in\
      \ \"address, intersection, latitude / longitude, or business name\" format.\r\n\r\nThe AI should have identified that\
      \ it needed this key information, did not have it, and queried for it in a followup conversation.\r\n\r\nInstead, it\
      \ chose to submit the center as the string, \"my location.\"  This is obviously not to spec, and notably, is not a string\
      \ pulled from the conversation but of the model's own generation.\r\n\r\nIn short, the model's trigger-happiness to\
      \ use the tools it was provided with led it to fabricate clearly invalid input to use, in a turn that required a follow-up\
      \ question – that required conversation, not tool use."
- name: Entry 7
  tools:
  - find_planet_position
  - is_planet_visible
  messages:
  - My daughter and I are going out to eat near St. Louis, MO, and then to a nearby field to stargaze. Which way do I look
    to see Venus, or will it even be visible?
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    worker_explanation: The model did not call both "is_planet_visible()" and "find_planet_direction()", which are similar
      in nature, but are both required to successfully answer the user prompt. By using a complex language pattern for the
      model to correctly interpret ("Which way do I look to see Venus, or will it even be visible?"), the model was tricked
      into placing full emphasis on the second question, opting to ignore the first completely, as it believed this was the
      only key part to answer. The tool schema itself is relatively simple, and this is a language comprehension issue for
      the model. The model should have instead called both tools after realising that both parts of the question need to be
      answered, rather than selecting one of them.
- name: Entry 8
  tools:
  - get_runs
  - get_time
  messages:
  - Phew! Joey is certainly growing up! I am starting to have problems catching up on him in the jog times. This way he will
    be the family fastest runner in a year two.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: A dad is casually "complaining"/bragging about how his son is surpassing him in physical performance.
      The model probably did not catch the context, saw the words jog and runner and probably wanted to get more details on
      the running times. All it needed to do was to just agree with the user and say something about how that's life and how
      adolescents becoming adults grow and improve in physical performances, or something like such.
- name: Entry 9
  tools:
  - movies_by_year
  - revenue
  - cast
  - movies_by_genre
  - movie_details
  messages:
  - 'from I Know What You Did Last Winter to I Know What You Did Last Winter III, which movie had the biggest box office world-wide? '
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    - Missing parameter
    worker_explanation: 'The prompt asks for the world-wide box office revenue of the movies. As the revenue function defaults
      to only domestic revenue, calculating the world-wide revenue would entail 2 calls for each movie: one with domestic
      set to true (or left true by default), and one with the domestic parameter set to false. These would then be added together
      for a single movie to find the total global box-office for it. Four calls were needed to answer this question fully
      (2 for each of the movies), but only 2 calls were made. The model failed by not looking deeper into what was being asked
      and by not extrapolating information from a naturally-phrased question.'
- name: Entry 10
  tools:
  - get_gene_summary
  - get_gene_sequence
  - find_homologs
  - list_instruments
  - check_instrument_availability
  - reserve_instrument
  - cancel_reservation
  messages:
  - 'I’m kicking off a hemoglobin alpha-1 task. Please give me the official HBA1 overview, fetch the amino-acid sequence (not
    DNA), and check for homologs in house mouse (I don’t know the Latin name). Also, can you book the Gene Sequencer for this
    Thursday, late afternoon (after 15:00)? If Thursday isn’t free, then Friday evening.

    Today is Tuesday, 12/08/2025, and I’m in Dublin (UTC+1)'
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    - Wrong tool called
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The model should have made four calls in the last turn. These calls were:get_gene_summary("HBA1"),
      get_gene_sequence("HBA1","protein"), find_homologs("HBA1","Mus musculus"), and then check_instrument_availability("Gene
      Sequencer","2025-08-14") because Tuesday 12/08/2025 means this Thursday would be 2025-08-14 but instead it mis-parsed
      the date as 2025-12-11. It also skipped the availability check and directly called reserve_instrument(…).
- name: Entry 11
  tools:
  - filter_books
  - recommend_book
  - find_nearby_library
  messages:
  - Fantasy is the best book genre
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: 'In the prompt, the user expresses their love of Fantasy books. The user does not give any indication
      that they are searching for a book to read, or are wanting to take out a new book. The model uses a tool call when it
      does not need to by calling the ''filter_books'' tool and sets the genre to ''Fantasy''. This is not the correct use
      of this tool, as description of the filter_books tool clearly states that this tool filters books from a book catalog,
      however the prompt gives no indication that this is the user''s intention. The model should have probed the user for
      more information about what they are trying to achieve through the prompt. Instead, the model has centered its response
      around the tools available to it  instead of addressing the prompt directly. '
- name: Entry 12
  tools:
  - movie_genre
  - search_for_db_id
  messages:
  - What kind of movie is Love Acutally?
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: 'The model did not catch that "actually" is misspelled. The movie is sufficiently popular that the
      model should recognize the misspelling and corrected it. I don''t think clarification would be needed - there''s a very
      low chance the user would be asking about a different movie. '
- name: Entry 13
  tools:
  - set_light_state
  - set_thermostat
  - set_lock_state
  - set_blind_position
  - set_window_position
  messages:
  - We are starting to get condensation in the basement, turn on the AC down there to remove the moisture.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: I did not expect the model to set the temperature lower to turn on the AC, that took logical deduction
      I did not expect the model to be capable of. I am unsure why the model called set_light_state, perhaps it got confused
      with the work on being similar to the "state" parameter's possible values.
- name: Entry 14
  tools:
  - get_route
  - get_gas_stations
  - check_traffic
  - find_accommodation
  - estimate_trip_cost
  - get_weather
  - find_rest_stops
  - get_attractions
  messages:
  - I'm driving my family up to Carlisle from London for a wedding. The kids are bummed about the long drive so I'm looking
    for something fun to do while we're up there for the weekend.
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: The prompt describes a weekend trip to Carlisle from London and mentions that the user is looking
      for something fun to do. It is quite clear from the prompt that the get_attractions() function should be called to find
      things to do in Carlisle, but since the start location and destination are provided, the model called the get_route()
      function instead. The correct function call is [get_attractions(location="Carlisle")].
- name: Entry 15
  tools:
  - delete_files
  - compress_files
  - extract_files
  - share_files
  messages:
  - Wow, I've had such a stressful week working on multiple reports simultaneously, all with deadlines for Wednesday. I'm
    going crazy, I think I need to be zipped into a straitjacket before I just delete all the files.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: 'The model completely misunderstood the prompt; the user was venting about stress and used the phrase
      "zipped into a straitjacket" metaphorically. The model took this phrase literally and instead of responding in natural
      language, responded with a `compress_files` tool call with hallucinated file paths. The correct approach would have
      been to recognise the user''s distress and provide a supportive and empathetic response. I believe that the failure
      likely occurred because the model prioritised keyword matching over the context, hard focusing on the trigger word "zipped"
      instead of comprehending the user''s emotional state and analysing the context of the prompt as a whole. '
- name: Entry 16
  tools:
  - get_user_location_datetime
  - get_stock_symbol
  - compare_stocks
  - symbols_headlines
  - summarize_stock_performance
  messages:
  - Yesterday, I was talking to a friend of mine about how I'm happy with how my Apple stocks have been doing. She kind of
    made me feel stupid by saying how Google has, long term, outperformed Apple. BUT I  invested in Apple only since last
    year. I'm meeting with her again tomorrow, so in preparation I'd like to know which stock did better in just this past
    year. She told me if I looked it up, I'd find plenty of headlines about each stock's long term performance over the past
    ten years, so I'd like to come back at her with my own data.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Didn't use a tool call when it was supposed to
    worker_explanation: "The model runs get_stock_symbol(query=\"Apple\") and get_stock_symbol(query=\"Google\"). This would\
      \ make sense if it ONLY ran these tools, because logically that would mean it is confirming the stock symbols of Apple\
      \ and Google before running any tools to compare these stocks. However, in parallel, the model also runs:\r\nsummarize_stock_performance(ticker=\"\
      AAPL\", days=365) and summarize_stock_performance(ticker=\"GOOG\", days=365). AAPL and GOOG are acceptable/correct ticker's\
      \ for each company, so it is not really efficient to be running get_stock_symbol when the symbols are already being\
      \ used in another tool call.\r\n\r\nOne could argue that by running get_stock_symbol, the model can confirm that its\
      \ ticker symbols (GOOG/AAPL) are correct, BUT it is still not very efficient to check the symbols at the same time as\
      \ running tools that use those symbols. It would be better to just run get_stock_symbol and wait for the returned values\
      \ before running other tools, OR if the model knows the stock symbols with certainty, it is more efficient to just run\
      \ tools on those tickers and not waste time/resources running tools to double check each ticker. \r\n\r\nFurthermore,\
      \ it is acceptable that the model ran summarize_stock_performance on each ticker symbol. But the query asked \" I'd\
      \ like to know which stock did better in just this past year\". The summarize_stock_performance tool returns a CSV which\
      \ the model would then have to analyze the results of. It would be more efficient to just run compare_stocks(tickers=[\"\
      AAPL\", \"GOOGL\"], days=365) as this will immediately return the percentage change of each stock over the past year,\
      \ which would immediately answer the question \"which stock did better in just this past year?\" Extra information would\
      \ be nice to have from running (summarize_stock_performance) such as dollar changes, yearly highs/lows, etc. So it is\
      \ find that it is acceptable that it ran these tools, but in answering \"which stock did better\" It would be more efficient\
      \ to just run compare_stocks. \r\n\r\nI am not sure WHY the model failed, but it seemed to assume that since it wasn't\
      \ explicitly given the stock symbols for either stock, that it should run get_stock_symbol even though its internal\
      \ knowledge already knew the symbols for each stock."
- name: Entry 17
  tools:
  - rank_stats_by_uuid
  - wins_to_duo
  - wins_to_match
  - get_top_players
  - get_runner_up_players
  - account_info_by_uuid
  - uuid_by_account_info
  messages:
  - How many games do I need to win to break into the top 100? My account is ThePhantomLancerEU#NA1.
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "What I would expect here is a call to uuid_by_account_info for this account to get it's current rank,\
      \ as well as a call to get_top_players for the same region. This would give it the rank info for the 100th player, and\
      \ let it call wins_to_match with the info for the user's account and the 100th ranked account.\r\n\r\nFirstly, the model\
      \ failed to properly call uuid_by_account_info, as it chose \"Europe\" for the region. I assume this is based on EU\
      \ being in the account name, but the schema specifically notes that the discriminator NA1 is the default for one of\
      \ the three possible regions (and clearly this region is North America, not Europe) and the model correctly identifies\
      \ that NA1 is the discriminator for this account. I would approach this situation assuming the default discriminator\
      \ for a server is restricted from being used on other servers, so an NA account can't have AS1 as a discriminator for\
      \ example, and that this account therefore must be on the North American server, and I think the model should be able\
      \ to determine this.\r\n\r\nSecondly, while it's not strictly required to happen on this turn I think this answer would\
      \ be better if it had also made the get_top_players call at the same time. Theoretically this call could be made on\
      \ a subsequent turn and then a third turn could be made for wins_to_match, but it would be better if condensed into\
      \ two turns for sure."
- name: Entry 18
  tools:
  - get_movie_recommendation
  - post_movie_rating
  messages:
  - Today is Friday... you know what that means! The issue is I can never decide what to watch and end up wasting so much
    time just flicking through options. Tomorrow I have an early start as I have a driving test as well so I need to be sleep
    on time, last time I was supposed to take the test I came 20 minutes late and my instructor was very angry at me. He ended
    up cancelling the test and not even giving me a refund can you believe it!
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    worker_explanation: "After receiving the prompt the model failed to identify and call the correct tool: get_movie_recommendation.\
      \ The user said they were planning to watch something and could not decide on what to watch.\r\n\r\nThe model's response\
      \ did say \"...deciding what to watch on Friday...\" so it shows that it understood the user needed help with suggestions\
      \ however it did not make that link to the tool. One reason could be that the words were mismatched, the words \"movie\"\
      \ or \"recommendation\" were never explicitly used in the prompt and that was what was used in the schema."
- name: Entry 19
  tools:
  - get_calendar_events
  - get_recipes
  - get_location
  messages:
  - I'm currently in Pretoria on Monday the 12th of August and on Sunday we're doing a bake sale at the Johannesburg Methodist
    Church but aren't sure what to make for the sale.
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: I'm asking the model for recipe recommendations while confusing it with location and date details.
      The model failed because it called the get_location tool with an unnecessary optional origin parameter when all it should've
      done is called the get_recipes tool. I think the model failed because the time and location details I provided are much
      more prominent and explicit than my implied request for recipes.
- name: Entry 20
  tools:
  - get_recommended_discounted_steam_games
  - get_steam_games
  messages:
  - There's a popular Steam game called Warframe. What do you think about the controversy that players are manipulating the
    online market for profit by selling certain mods at inflated prices?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: "The prompt is asking about the controversy surrounding Warframe, so the model should not be calling\
      \ get_steam_games() as it would not find the answer there. The model should explain the controversy to the user (that\
      \ inactive accounts, including influential players, are listing items at inflated prices, which may indicate systemic\
      \ market manipulation) and give their thoughts on the matter.\r\n\r\nThe model probably failed because the prompt included\
      \ the keyword \"Steam game\", which coincides with the function names."
- name: Entry 21
  tools:
  - get_cpu_temp
  - update_device
  - get_cpu_info
  - get_ram_usage
  messages:
  - My computer is called 'XP719', thats what it says on the side anyway. I was thinking about updating it but i'm still undecided
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: "The prompt specifies the `device_id` at the start, making it available to the model to use in any\
      \ of the functions. The prompt then mentions that they were thinking about updating the device but that they are still\
      \ undecided, the model then decides to call the `update_device()` function. This is incorrect because the prompt clearly\
      \ states that they are still undecided on whether they want to update the device or not. The ideal response would have\
      \ asked for more details on the specifics of the update so it can then assist the user in deciding whether to update\
      \ the device.\r\n\r\nIt appears the model failed simply by misinterpreting the prompt. It saw the words 'thinking about\
      \ updating' and assumed this is what the user wanted, neglecting the fact that the user is 'undecided' and was just\
      \ looking for help in deciding."
- name: Entry 22
  tools:
  - create_server
  - join_server
  - leave_server
  - report_server
  messages:
  - I really want to join a new server but I'm currently at the server limit. I don't think anyone is active in "The Cowboy
    Fans" anymore.
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: The prompt stated that the user wanted to join a new server but was at the server limit. This implies
      that the user wants to leave a server to join this new server. The user mentioned that the server, "The Cowboy Fans",
      is not active anymore, implying that this would be a good server to leave. The model does not recognize that the user
      wants to leave this server, but instead thinks that the user wants to join this server instead, since the prompt mentions
      joining a new server and mentions the name "The Cowboy Fans". Instead, the model should have called the function leave_server
      with "The Cowboy Fans" used for the parameter name to fulfill the user's implied request to leave that inactive server
      to join a new one.
- name: Entry 23
  tools:
  - currency_converter
  - get_current_stock_price
  - get_eod_stock_price
  messages:
  - 'it is currently 07:15 ET 2025-08-12 is the current price of coca cola above or below or the same as fridays end of day

    '
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The model needs to find the end-of-day stock price for ticker \"KO\" 2025-08-08. \r\nAlso, it needs\
      \ to recognize that the current time is pre-market-open, so it should find end-of-day stock price for yesterday, 2025-08-11.\r\
      \n\r\nIt can do this by using any combination of 2 tool calls of `get_current_stock_price` or `get_eod_stock_price`.\r\
      \n\r\nFor example, adapting from the model response, the corrected tool calls should be:\r\n`[\r\nget_current_stock_price(ticker_symbol=\"\
      KO\", is_market_open=False, is_end_of_day_price=True, time_date=\"2025-08-08 17:00:00\"),\r\nget_eod_stock_price(ticker_symbol=\"\
      KO\", date=20250811)\r\n]`"
- name: Entry 24
  tools:
  - get_preacher_info
  - get_preacher_sermons
  - get_church_service_preacher
  messages:
  - having a crusade next month trying to organizing things here, setting up sessions and see who will be good got some suggestions
    here preacher_17 preacher_29 preacher_30 and what to know them better and see who will be good to set for the last service
    in  Saint Paul DC Ive been a signed this task and Im new in this location
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Didn't use a tool call when it was supposed to
    - Wrong tool called
    worker_explanation: The model should also have used 'get_preacher_sermons' for each preacher alongside 'get_preacher_info'
      to get all the preacher information. The model should not have used 'get_church_service_preacher', as there is no preacher
      yet for this service, as mentioned in the prompt.
- name: Entry 25
  tools:
  - get_calendar
  - search_calendar_events
  - add_calendar_event
  messages:
  - 'I need to book in a meeting for sarah@example.com, tom@example.com and harry@example.com next Thursday 21 Aug 2025 or
    Friday 22 Aug 2025 in the afternoon, can you let me know if they are free? '
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Didn't use a tool call when it was supposed to
    - Wrong tool called
    worker_explanation: "The prompt specified wanting to book in a meeting on Thursday or Friday afternoon and needing to\
      \ check when the three participants were free.\r\n\r\nFor an ideal response, I would have expected the model to search\
      \ Sarah, Tom and Harry's calendars using the \"search_calendar_events\" function, from Thursday noon to Friday ~5pm\
      \ (or by searching both afternoons separately), and then to summarise its findings/each person's availability and ask\
      \ for clarification on when the user wishes to book the meeting.\r\n\r\nInstead, the model jumped ahead and booked two\
      \ meetings, one on Thursday afternoon and one on Friday afternoon (wrong, only one meeting was required), but did not\
      \ check availability first (as specified by the prompt). It also did not clarify the exact time to book for or what\
      \ it should use as the event title, instead using a generic title of \"Meeting\". I suspect the model failed because\
      \ I used the language \"I need to book in a meeting\" at the beginning of my prompt, so it focused in straight away\
      \ on the add_calendar_event function."
- name: Entry 26
  tools:
  - check_email_leak
  - check_email_leak_via_domain
  - check_phone_number
  messages:
  - Has my password leaked, 01234 5678? I think Google might have leaked it
  metadata:
    failure_modes:
    - Wrong tool called
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The prompt asked if the password associated with their phone number was leaked. The prompt gave mixed\
      \ signals because it also mentions a domain name, \"Google\" which is a parameter for a different tool call than the\
      \ one for checking via a phone number. This tool accepts a domain name and also requires an email address, but no email\
      \ address was given in the prompt. Instead, the model has decided to attempt to call the tool that checks a particular\
      \ domain, but supplied the hallucinated email address of \"user@gmail.com\". This will not return the results expected,\
      \ as a completely different email address was used.\r\n\r\nThe correct action for the model would have been to make\
      \ the first call it did, but not the second. The model only needed to call `check_phone_number` with the provided phone\
      \ number to see if the password associated with the phone number was leaked."
- name: Entry 27
  tools:
  - calculate_compound_interest
  - analyze_portfolio_risk
  - calculate_loan_payment
  messages:
  - What do you do about compound interest?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: "The model was asked a general question about compound interest. Instead of explaining the concept\
      \ of compound interest, or asking a follow-up question, the model made a \"calculate_compound_interest\" tool call using\
      \ data that was not supplied by the user as parameters.\r\n\r\nThe model probably wanted to provide an example as to\
      \ how compound interest is calculated, but should have provided a written explanation about compound interest instead."
- name: Entry 28
  tools:
  - search_products
  - add_to_cart
  - get_order_status
  - get_cart_contents
  - remove_from_cart
  - checkout
  - get_user_recommendations
  messages:
  - Hi, my friend purchased some yellow nike shoes, and but can’t get his order id, so he can’t track the order. I’m interested
    in purchasing the same shoes, but i can’t find any for a price lower than £45, otherwise i’d add them to my cart, which
    is a shame, so I guess i’ll look for some other shoes. Green is my favourite colour, I might do that. Anyway, could you
    remove the order I placed with order id 123456?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: "The AI called get_order_status, and remove_from_cart when it wasn’t supposed to. Instead, it should’ve\
      \ realised that there is no tool call for removing orders, so it can’t help out the user. \r\n\r\nI did confuse it a\
      \ lot with a lot of complexity and talking about many different things. I think that it confused the tool call for getting\
      \ the order status, and thought that it would be able to use it for removing the order itself at the end. As for why\
      \ it decided to remove the yellow shoes from the cart, I have no idea, as there was nothing I said that should’ve told\
      \ it that they were in my cart in the first place - especially since i said that i couldn’t find any."
- name: Entry 29
  tools:
  - get_travel_time
  - get_coordinates
  messages:
  - I have a very busy day tomorrow (8/13/2025). I have a meeting at 9 AM at 790 7th Ave in New York, NY. What time should
    I leave?
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    - Other
    worker_explanation: "The model made a number of mistakes in the response, mostly in relation to the parameters provided\
      \ to the get_travel_time() function. The model made an assumption about the coordinates to be used for both the origin\
      \ and the destination, using the same value for both parameters, which does not make sense in the context of the provided\
      \ prompt (It used the coordinates of Queens, New York). The model also failed to determine reasonable values to use\
      \ for the departure and arrival timestamp parameters, using values for both when it should have inferred from the prompt\
      \ that only the arrival time was needed, based on the fact that the prompt asked for an ideal departure time. \r\n\r\
      \nThe model may have failed to infer the need for the output of the get_coordinates() function in the get_travel_time()\
      \ function because of the mention of a location (New York) in the prompt, which it must have relied on prior knowledge\
      \ for in order to produce the co-ordinates given in the response (the coordinates point to Queens, New York). The mention\
      \ of a time and date may have also confused the model when applying the parameters for the departure and arrival parameters\
      \ of the get_travel_time() function. Again, the presence of this information may have led the model to believe that\
      \ the prompt contained enough explicit information to be able to determine what values to use here, however, it is less\
      \ clear why the model chose to provide both the departure and arrival timestamps. Perhaps the schema description is\
      \ not succinct enough for the model to determine that these parameters should be mutually exclusive.\r\n\r\nIdeally,\
      \ the model should have only made initial calls to get_coordinates() to retrieve coordinates for the origin and the\
      \ destination (only the latter of which it managed to do correctly). "
- name: Entry 30
  tools:
  - send_email
  - create_calendar_event
  messages:
  - I have a doctor's appointment tomorrow that will cause conflicts with my weekly meetup with my friends Luke and Gabriel.
    I might need to let them know and send them an email that I will need to rearrange our meeting for another day, and see
    if I can work out an alternative. Can you fix this for me and make sure I remember to do what I need to tomorrow?
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The model managed to understand that the prompt was asking for a calendar event to be created by "make
      sure I remember to do what I need to tomorrow". Though this is ambiguous and should have understood that when referencing
      tomorrow, it was referring to the doctor's appoint which is stated as tomorrow. The model also failed in that it did
      not fix this for the user, even though they mentioned that they need to send an email to rearrange the meeting, instead
      only setting a reminder to rearrange the meeting which is unhelpful. The `send_email` tool should have been called,
      alongside the `create_calendar_event` tool. The model likely failed because the sentence included two requests, one
      is to "fix this" and the other is to "make sure to remember", where the model seems to have grouped them together into
      one thing and misunderstood what is being asked for.
- name: Entry 31
  tools:
  - rc_trackmeets
  - rc_smooth_tyres
  - war_model_shopper
  - miniature_car_parts
  - gasic_guzzler_meets
  - rcbay
  messages:
  - I am at Arthurs in BS8 1ED. We're biking down the Gorge. Arthur buckled a wheel and I could use a new puncture repair
    kit. Is there someone nearby selling either of these items?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: "I was going to tell the model we were \"mountain biking\", but remembered ambiguity being a valid\
      \ strategy, and how long the model can take. So good old ambiguity tricked it, I guess.\r\n\r\nThe model should not\
      \ have used any tool call since there are no tools associated with biking, bike parts, or bike repair kits. \r\n\r\n\
      As for details, the schema is related to RC model cars (and war model figures, because they both paint up nicely), and\
      \ I was talking about biking down the Avon Gorge. I cannot fathom why it used the \"war_model_shopper\" tool. Miniature_car_parts\
      \ is more understandable, but incorrect."
- name: Entry 32
  tools:
  - search_products
  - get_product_details
  - add_to_cart
  - get_cart_items
  - place_order
  - get_order_status
  - get_history
  messages:
  - That last book I bought was great. Can you get me another one by the same author, and this time, check if there's a hardcover
    version?
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    - Other
    worker_explanation: "The model has failed to identify from the prompt that I want a book by the same author as the last\
      \ book I bought. The model should have first called the `get_history` tool and then used the information from that to\
      \ search for a new product.\r\nThe model also misses the additional for a hardcover version and has created a min max\
      \ price that wasn't asked for."
- name: Entry 33
  tools:
  - get_current_iso_time
  - get_weather
  - find_nearby_restaurants
  messages:
  - "I'm doing so much traveling lately and there's been wall-to-wall sunshine!  Last night I boarded a sleeper train from\
    \ Barcelona to Milan, where I'm going to spend the rest of the morning! This afternoon I'm traveling across the country\
    \ to Venice! Hopefully I'll get to go to Split sometime next week before I head home. \n\nI could do with somewhere for\
    \ a meal tonight, please suggest a vegetarian place!"
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The model failed to interpret the context of the information in the prompt correctly. The prompt\
      \ states that the user will \"spend the rest of the morning [in Milan]\" and this afternoon the user will be \"traveling\
      \ across the country to Venice\". As the user is looking for suggestions as to where to have \"a meal tonight\", the\
      \ correct inference is that the location for the restaurant should be in Venice _not_ Milan. The model has not managed\
      \ to marry the schedule in the story to the request for an evening meal.\r\n\r\nThe correct tool use should be `[find_nearby_restaurants(location=\"\
      Venice\", tags=[\"vegetarian\"])]`."
- name: Entry 34
  tools:
  - checkout_ebook
  - return_ebook
  - hold_ebook
  messages:
  - I'd like my friend to check out one of my favorite books, Mistborn. What should I tell them?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: The model checked out a book for the user despite the fact that the user was asking how to convince
      their friend to read it. It seemed to see that the user mentioned the idea of checking out a book and checked out the
      book without reading the rest of the prompt. It should have given the user advice on talking to their friend or said
      that providing advice was out of scope for it.
- name: Entry 35
  tools:
  - filter_menu
  - track_discounts
  - find_cheapest
  messages:
  - Lattes are so expensive at the moment
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: 'The prompt expresses that Lattes are an expensive drink currently. The user does not express that
      they are interested in purchasing a latte. The model uses a tool call when it does not need to, by calling the ''find_cheapest''
      tool, which identifies the cafe that sells the cheapest lattes. This is an error as the user has not expressed that
      they are interested in finding the cheapest coffee. Furthermore, the tool call specifies cafes "Cafe A", "Cafe B", and
      "Cafe C", when these are not real cafes, nor are they specified by the user to search through. A better response would
      first ask the user if they are interested in finding the cheapest latte in their area. Alternatively, the user could
      have wanted to discus why the price of lattes were high. Hence, the model has jumped to a conclusion of what the user
      wants based on the tools available to it, and so the model should first make clear what exactly the user is trying to
      achieve from their prompt. '
- name: Entry 36
  tools:
  - get_company_profile
  - list_company_officers
  - list_company_filings
  - get_registration_number
  messages:
  - I heard there's been some turmoil at the top of Bigtime Holdings Ltd, there are a lot of rumors flying around. I heard
    someone say that they're going to change their share status and some of the directors who've been there from the start
    are on the way out. A lot of new filings apparently, but who is in and who's out?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: The model made calls to the tools 'list_company_officers()' and 'list_company_filings()', which rely
      on the output of 'get_registration_number()', and therefore should not have been called. The model should have made
      a single call to 'get_registration_number()'.
- name: Entry 37
  tools:
  - get_makes
  - get_models
  - get_tires
  messages:
  - I decided to go for a walk downtown instead of taking my trusty old Hyundai Accent. A long walk like that really tires
    me out, but I can't just take a nap on the street! What should I do so that leaving my car at home doesn't tire me so
    much?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: "1. The model should not use a tool call. For example, the model should not call get_tire_sizes(make,\
      \ model, year).\r\n2. The model should suggest ways to prevent getting tired on a walk, at least one of: increasing\
      \ nutrition, drinking water while walking, exercising more, or getting more rest.\r\nWhy I think the model failed:\r\
      \n• The prompt specified a car make and model in the prompt.\r\n• The prompt used the words \"tire\" and \"tires\" in\
      \ the sense of needing rest or sleep.\r\n• Ambiguity between \"tire/tires\" in the sense of needing rest or sleep and\
      \ \"tire/tires\" in the sense of the rubber parts that cars use to grip the road tricked the model into using the API\
      \ rather than just answering the question."
- name: Entry 38
  tools:
  - electricity_price
  - washing_cycle_status
  - start_washing_cycle
  - estimate_washing_cycle_length
  - get_current_datetime
  messages:
  - Ugghh, the electricity prices in Estonia are quite high lately, I really need to watch when and how much I use it... I
    loaded the washer with 2kg of clothes that are not very dirty, they just need a fast wash. When do you think the cheapest
    time is (before midnight)? Turn on the washer at that time
  metadata:
    failure_modes:
    - Wrong tool called
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    - Missing parameter
    worker_explanation: The model called get_current_datetime and estimate_washing_cycle_length with the correct parameter
      values, but it should not have called start_washing_cycle yet without any knowledge of the electricity prices. It used
      8 as the delay value, which is a completely random number and not based on the lowest electricity prices at all. The
      model also didn't specify that the water should be cold (the temperature parameter description says to use cold water
      for lightly soiled clothes, and the prompt says the clothes are not very dirty, meaning they are lightly soiled).
- name: Entry 39
  tools:
  - recommend_movie
  - recommend_book
  - recommend_tv_show
  messages:
  - you know the genre of movies by like paul verhoeven and george lucas? can i have a movie of that genre. also something
    substantial but snappy, so between an hour and a half and two hours please.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    - Missing parameter
    worker_explanation: My prompt misdirected the model by asking about directors, however, it was quite clearly asking about
      the genre that these directors make, rather than films from these directors. Therefore, the model should have identified
      the genre as Sci-Fi (or, less notably, action) and included no parameters relating to director, as that is not what
      I was asking about, and would have limited film recommendations to only being ones by these directors. Instead, the
      model included 'director' parameters, listing the directors as George Lucas and Paul Verhoeven. Additionally, the model
      made two tool calls (one for each director), which would return two movies, despite me requesting only one movie. Furthermore,
      the model neglected to apply to the length parameters to the first tool call, meaning that even if I had wanted two
      movies, one would likely not be the correct length.
- name: Entry 40
  tools:
  - dns_record_checker
  - link_analyzer
  - broken_links_finder
  - keyword_rank_checker
  messages:
  - I hope my site has the best keyword rankings. When I check google, I can never tell.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "There isn't enough information in the prompt to use a tool to help answer it, because the URL of\
      \ \"my site\" is not provided. The model decides to call the tool `keyword_rank_checker` with example.com as the URL\
      \ parameter and \"best keyword rankings\" as the keyword parameter. It shouldn't use an unrelated URL to check keyword\
      \ rankings for the user's site; there's no chance the user owns example.com. It also shouldn't use \"best keyword rankings\"\
      \ as the keyword when no keyword is provided. The model seems to have no idea what's going on, just putting whatever\
      \ it feels like in the mandatory parameters. It seems to get excited that there's a tool that seems to match so well\
      \ what the user wants to know, but it needs to recognize that it doesn't have the required information, and picking\
      \ arbitrary values doesn't help.\r\n\r\nI was surprised that the model failed this so spectacularly. I just expected\
      \ it to check the google.com url. I consider my mention of Google in the prompt as \"adding complexity\",  but it was\
      \ also to provide something for the model to potentially use as a parameter. I'm also pleased I didn't have to think\
      \ up something else for it to use as a keyword, it simply grabbed some inappropriate words that I had to use, anyway\
      \ (\"best keyword rankings\", the tool hint)."
- name: Entry 41
  tools:
  - add_item
  - remove_item
  - trade_items
  - craft_item
  messages:
  - Craft a Phoenix Bow. I need 3 Dragon Scales but have none. I have 5 Iron Ingots available.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Didn't use a tool call when it was supposed to
    - Wrong tool called
    - Other
    worker_explanation: "The model tried to make a tool call, but didn't specify the tool required.\r\n\r\nThe model didn't\
      \ use the `trade_items` tool in the schema. In my prompt I specifically state I don't have the required items, and in\
      \ the `craft_item` description it states that the player needs the required items. I also state that I have 5 'Iron\
      \ Ingots' available, it was my hope that the model would infer that I need to trade for the 'Dragon Scales'.\r\nThe\
      \ model should have asked clarifying questions, or called `trade_items` to acquire the 'Dragon Scales' then `craft_item`\
      \ for the 'Phoenix Bow'\r\n\r\nI believe the model failed because my prompt was missing information and the relative\
      \ complexity of the task. As well, the description for `craft_item` states \"Crafts a new item by consuming materials\
      \ if the player has said materials.\" If the description mentioned trading with other players to acquire missing materials\
      \ the model may have succeeded. The problem with that though, is that `craft_item` is specifically for crafting, not\
      \ trading."
- name: Entry 42
  tools:
  - book_cafe
  - cafe_has_library
  - genre_search
  - gluten_free_cafes
  - book_store_cafe
  messages:
  - Dallas is in town from this Tuesday August 12nd until Tuesday, could we book the Cutey Cat Cafe for the morning he leaves?
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The model gets the date inputs into the book_cafe() tool call wrong. The model should have called\
      \ the tool with the date input \"2025-08-19\", which is the day he leaves. Even though the year is wrong, the real problem\
      \ is with the day as \"2024-08-13\" is completely off. \r\n\r\nI think the model failed because of a confusion with\
      \ the arrival and departure date both being Tuesdays. The model failed to infer that the leaving date was not the same\
      \ as the arrival date, meaning that there was some confusion about when the actual leaving date was. "
- name: Entry 43
  tools:
  - get_espresso_grind
  - get_espresso_weight
  messages:
  - Last week I got an espresso I really liked at a cafe, they used some dark roasted Colombian beans. I want to try it at
    home so I bought some of the beans and roasted them myself, but for about half the time than the ones I got before. The
    cafe recommended a medium-coarse grind and short shot for these natural beans, but how should I adapt the recipe for home
    use?
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The schema defines two functions which can be used to help create a recipe for espresso, using properties\
      \ of the coffee at hand. The prompt requests a recipe, implicitly requiring recommendations for both grind size and\
      \ shot weight. One model failure was that it didn't call the `get_espresso_weight` function when this was implied as\
      \ necessary. So there is a missing tool call. \r\n\r\nThe second failure is that the model specified \"roast=\"dark\"\
      \" when it should be inferred that the roast was \"medium\". I believe the model failed primarily due to ambiguous language\
      \ and complexity. For example, the prompt uses the term \"short shot\", which relates to a low espresso end weight,\
      \ but the model failed to recognise this and call the `get_espresso_weight` function. Additionally, complexity was added\
      \ by using parameter keywords in the prompt, e.g. \"dark roast\", but then implying that these have changed through\
      \ the use of natural language \"roasted... for half the time\". "
- name: Entry 44
  tools:
  - get_car_details
  - find_used_car_parts
  - find_used_car_part_dealer
  messages:
  - I need a cheap radiator for my Hilux truck.  I'm near Wellington.  Is there anywhere nearby that is selling a used one?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Wrong tool called
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: 'The model called two tools when one call was required.  get_car_details converts a registration number
      to car make, model and year.  find_used_car_parts looks for available parts from sellers.  The model correctly inferred
      Toyota from ''Hilux truck'' and correctly called find_used_car_parts.  It also incorrectly called get_car_details mistakenly
      passed Hilux as a registration number.   It appears to confuse a car''s model as it''s registration mark.  A version
      of the schema using the word ''dealer'' instead of ''seller'' worked correctly though.  '
- name: Entry 45
  tools:
  - postcode_convert
  - uk_election_statistics
  messages:
  - My friend (lives in bushey road Wimbledon SW19) was telling me yesterday that his MP is lib dem but I don't remember seeing
    anything about that in the news. How long has it been lib dem? What's my postcode
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Didn't use a tool call when it was supposed to
    - Wrong tool called
    worker_explanation: "The prompt requested:\r\n  1: election information for a specific location (friend's house).\r\n\
      \  2: postcode for the user's house.\r\nHowever, the model tried to convert the friend's postcode (which is not helpful\
      \ since it already knows the specific location). The model did not have access to the user's location and therefore\
      \ cannot usefully respond to \"What's my postcode\".\r\n\r\nAn ideal response would have called `[uk_election_statistics(location=\"\
      Bushey Road, Wimbledon SW19\"]` and then asked for the user's location.\r\n\r\nThe response may have gotten confused\
      \ due to the similar nature in the schema, and merging both calls. Ie. postcode of friends house."
- name: Entry 46
  tools:
  - roll_dice
  - track_hit_points
  - manage_spells
  - apply_condition
  - calculate_attack
  messages:
  - The troll just smacked me for 6 damage, dropping my health from 18 to 12. Can you roll a 1d20+4 to see if I hit him back?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Wrong tool called
    worker_explanation: 'The model incorrectly called the track_hit_points tool. It got confused by the user describing what
      had just happened but the user had already done the work of track_hit_points themselves, stating that their health had
      gone from 18 to 12, so this was not needed. The user asks only for the calculate_attack tool, to see whether they hit
      the troll back or not. '
- name: Entry 47
  tools:
  - get_train_times
  - get_flight_times
  - get_bus_times
  messages:
  - I want to travel from Manchester to Belfast. Give me some options and times.
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: Out of the options provided in the schema the only realistic travel option from Manchester to Belfast
      is by plane. There is no train or bus connection between the two places as they are separated by the Irish Sea. Because
      of this, the model should call `get_flight_times`, not `get_train_times`.
- name: Entry 48
  tools:
  - get_fuel_price_by_city
  - get_fuel_price_by_country
  - generate_budget
  - search_train
  messages:
  - I'm going to Germany next month, will be in Nuremburg for 2 nights, Berlin for 3 nights, and Munich for 2 nights. I'm
    leaving on 20/8. I need to make a budget for the overall trip as well as transport costs. It's mostly a roadie/hiking
    trip, love restaurants but too expensive for this trip.
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    - Wrong tool called
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The model should have used the following tool calls:\r\nget_fuel_price_by_city(city=Nuremburg, date='2025-08-20'),\r\
      \nget_fuel_price_by_city(city=Berlin, date='2025-08-22'),\r\nget_fuel_price_by_city(city=Munich, date='2025-08-25')\r\
      \n\r\nThe model should not have used the search_train() tool. The model incorrectly assumed that the transport costs\
      \ would relate to trains, but should have inferred that 'roadie' referred to a roadtrip, and therefore needed to calculate\
      \ fuel costs rather than train costs. Also, the train searches it provided contained incorrect parameter values with\
      \ both trips assigne d the same date which doesn't align with the user's itenerary. "
- name: Entry 49
  tools:
  - crawl_lightnovel
  - parse_chapters
  - apply_translation
  - convert_to_ebook
  - upload_ebook
  messages:
  - 'I''m a VIP on Qidian, so please get me "Journey to the West" from there. Here''s the URL to help you find it!

    https://www.qidian.com/book/1045429773/

    like your documentation said, heres my cookie to login: 12jd1nlwp1491jd1

    My username is "adonno55", but i forgot the password right now. Login whichever way u want, whatever is easier.

    Chapters 31-60 cover the "Cherry Blossom Valley" arc, except chapter "42" which is an annoying author note. Please get
    me that arc tonight, but keep your reqests below a dozen a minute so i dont get banned. Download all the artwork for me,
    but remember that I can read chinese, i don''t want it translated to english . Bundle the ebook as azw3 so my kindle can
    support it! send me an email confirmation at adonno5@hotmail.com once youre done thanks

    '
  metadata:
    failure_modes:
    - Incorrect typing (ex. model gave a string value for an integer field)
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    - Missing parameter
    - Other
    worker_explanation: "The prompt requests for every chapter in the interval 31 to 60 inclusive, except chapter 42. The\
      \ model ignores this request, and even explicitly requests chapter 42 on top of 31 - 60. The chapters_list element \"\
      42\" was also in the string format, which is incorrect. Assuming the schema even supported this, this would result in\
      \ chapter 42 appearing twice. This violates the OneOf rule in the schema, which allows for either a list of chapters\
      \ or a range of chapters, not both. \r\n\r\nThe model should have instead provided a list of chapters to provide in\
      \ the form [31, 32, ..., 41, 43, 44, ..., 60]. The rate_limit request is also absent, even though the user wanted the\
      \ rate_limit to be set below 12. \r\n\r\nLastly, the download_images flag is correctly set to true, but the accompanying\
      \ conditional image_formats is missing, which violates the conditional logic of the schema. The model should have included\
      \ image_formats: [\"png\", \"jpg\", \"jpeg\", \"webp\"] since the user didn't specify any file type omissions."
- name: Entry 50
  tools:
  - distance
  - get_latlong
  - get_traffic
  messages:
  - Oak Point Avenue is really busy today. How do we reduce traffic on main roads?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: The model called the get_traffic() function when it should have answered the question in the prompt.
      The prompt states that Oak Point Avenue is busy, and asked a follow-up question to determine how to reduce traffic.
      The prompt did not ever ask for the traffic status of Oak Point Avenue, it simply made an observation. The model interpreted
      this and called the get_traffic() function wrongly.
- name: Entry 51
  tools:
  - get_energy_drink_info
  - compare_energy_drinks
  - get_caffeine_warning
  - suggest_energy_drink
  - track_energy_drink_consumption
  - find_energy_drinks_by_ingredient
  - rate_energy_drink
  messages:
  - I love energy drinks. but my mom says i drink to many of them. she is such a drag
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: 'If I say I am drinking to many energy drinks the model should not be suggesting more energy drinks
      for me to try. This is probably the worst response the model could have came up with. It is suggesting energy drinks
      because I said I love them but based on the other 2 sentences I said it should just respond like its talking to me. '
- name: Entry 52
  tools:
  - get_daily_horoscope
  - get_weekly_horoscope
  - get_love_horoscope
  - get_career_horoscope
  messages:
  - Why am i so intense?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: 'The model incorrectly assumed it was a horoscope-related question and called two unnecessary tools
      "get_love_horoscope" and "get_career_horoscope" when no tools were needed.  The prompt asked "Why am i" rather than
      a future orientated guidance that horoscopes provide. Next the model fabricated information by assuming the user was
      a "Leo" despite no zodiac sign being mentioned anywhere in the prompt.The mode should have provided a conversational
      response discussing common sources of intensity in personality such as strong emotions and high energy. The model seems
      over eager to use available tools when it detects any potential connection. '
- name: Entry 53
  tools:
  - verify_id
  - evaluate_patron
  - get_drink_summary
  - make_drink
  - check_inventory
  - cut_off_patron
  - suggest_drink
  messages:
  - 'Patron: 569378

    ID Verified: True

    Drinks Had: 0

    Order: "How much alcohol does a shirley temple have?"'
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: The model should not have called any tools, and certainly should not have started making a drink.
      Even though the customer's comment was labeled as an 'Order' it is clear they were asking a question, and not yet ready
      to order. The widely known answer is that a shirley temple has no alcohol. The model probably failed because it recognized
      the name of a drink, and had a tool strongly related to drinks.
- name: Entry 54
  tools:
  - create_server
  - join_server
  - leave_server
  - report_server
  messages:
  - The people in Loser's Guild are sending death threats to me. They need to be taken down this instant!
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    worker_explanation: "The prompt stated that the people in Loser's Guild were sending death threats. In the context of\
      \ the functions, it can be assumed that the people being talked about were in a server called Loser's Guild. However,\
      \ the model fails to figure out that Loser's Guild is the name of a messaging server. Furthermore, the prompt states\
      \ that they need to be taken down. The model does address that it can report the server, but does not realize that it\
      \ can use the name \"Loser's Guild\" for the report_server function and even fails to identify the report_server function\
      \ at the beginning of the model's response as to address the prompt's request to have the server taken down. \r\nIt\
      \ also got confused about \"taking down\" the death threats, and thought the prompt asked to take down the people sending\
      \ these death threats.\r\nAll in all, the model should have called the report_server function with \"Loser's Guild\"\
      \ used for the parameter name and \"death threats\" or anything including, but not limited to, mentions of death threats\
      \ for the parameter \"reason\"."
- name: Entry 55
  tools:
  - route_plan
  - stops_along_route_find
  - breaks
  - trip_cost_est
  messages:
  - I want to go from CA, to Florida with a stop at Colorado. I want to travel 2 thousand miles since that is all I can probably
    afford. How much will this trip cost me? Where should I take breaks? Where should I make sure to stop at?
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The model incorrectly put \"Colorado\" as the parameter value for avoid in the route_plan tool call,\
      \ in direct contradiction to the user's desire to stop in and visit Colorado.\r\n\r\nThe model also incorrectly provided\
      \ values for categories parameter in stops_along_route_find - the user did not specify any particular kinds of stops,\
      \ and this parameter is optional so it could have been left out entirely instead of filled in with all categories.\r\
      \n\r\nThe model similarly invented a value for detour_miles in the trip_cost_est tool call. The default value is 0,\
      \ and there was no reason to change that."
- name: Entry 56
  tools:
  - device_activation
  - register_device
  - remove_device
  - remote_authentication
  - shutdown_network
  messages:
  - Wow there was so much traffic on my way to work! I'm glad to finally have arrived there though. I think I need to turn
    off my devices which I forgot to turn off before leaving, sign me in so i can see
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: "The model called the shutdown_network tool when I never requested that the network actually be shut\
      \ down. I mentioned to the model that I thought I needed to turn off the devices, but ultimately asked for only a sign\
      \ in so I can see for myself. This added some mixed signals. The correct response should have been to only use the remote_authentication\
      \ tool. \r\n\r\nAdditionally, placeholder values are used for the log_in_id and secret parameters in the remote_authentication\
      \ tool call. These should be clarified before attempting to make the tool call."
- name: Entry 57
  tools:
  - get_hiking_trails
  - get_hiking_trail_weather
  messages:
  - Where can I go for a long walk today where it isn't rainy? In Berlin currently.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The prompt required sequential calls and therefore the model should not have called the `get_hiking_trail_weather`\
      \ tool in the first round of tool calls as it relies on information returned from the `get_hiking_trails` tool. The\
      \ description for the \"hiking_trail\" parameter in the `get_hiking_trail_weather` tool schema makes it clear that an\
      \ actual hiking trail name is needed, not just a general location. However, the model entered \"Hiking Trail in Berlin\"\
      , which is clearly not the name of an actual hiking trail.\r\n\r\nInstead, the model should have called only the `get_hiking_trails`\
      \ tool, with the intention of using the results from that tool call in a subsequent `get_hiking_trail_weather` tool\
      \ call."
- name: Entry 58
  tools:
  - get_meals_menu
  - get_daily_specials_menu
  - get_beverages_menu
  messages:
  - i'm wondering if i shouldn't stop drinking. it does me no good and only increases my dinner bills...
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: I asked a general health question about drinking. Because I mentioned that it is adding to my dinner
      bills, instead of supporting me in dropping alcohol (IMHO obvious context to a person), it went to check the beverages
      menu.
- name: Entry 59
  tools:
  - schedule_home_service
  - submit_time_off_request
  messages:
  - Today is 13/08/2025 , Wednesday. I need to get some cleaning done before the weekend party at my home. Hmmm. Friday might
    not be the best. Thursday is good. I'll need to let the people at work know.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Wrong tool called
    worker_explanation: The model assumed that the cleaning that needs to be done requires a scheduled home service. The prompt
      is ambiguous enough for the model to make this failure. The intent of the user was to get time off from work to do the
      cleaning. The model might have been tricked with the use of the word cleaning as it is an acceptable value for a parameter
      in the schedule_home_service tool.
- name: Entry 60
  tools:
  - search_indeed
  - check_sharecode
  - check_right_to_work
  - employer_visa_status_requirements
  - search_seek
  messages:
  - I'm looking for a new job in London so I can drive to visit my family in Detroit on the weekends. Is there anything that's
    been posted in the week up until 13/8/24?
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The model used the correct tool 'search_indeed', but should have used the parameter country = \"\
      CAN\" instead of \"UK\".\r\n\r\nThe user asked the model to look to see if any jobs had been posted in London within\
      \ the past week, so that they'd be able drive to visit family in Detroit on the weekends. The model then tried to call\
      \ search_indeed, but incorrectly assumed that the prompt was asking for jobs in London, UK. There was a clear signal\
      \ that the user meant London, ON, given they want to drive to Detroit on the weekends. This was a tricky prompt, but\
      \ something that a human would have picked up on."
- name: Entry 61
  tools:
  - send_message
  - get_emotional_speech
  - send_voice_message
  messages:
  - I just got a new iPhone, send a message with a self-aggrandizing emotional content to Bob that my type of phone is better
    than yours.
  metadata:
    failure_modes:
    - Wrong tool called
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The response should have called \"send_message\" with a re-written message with a self aggrandizing\
      \ tone. The use of the words \"emotional content\" in the prompt seemed to mislead the model to deliver the current\
      \ output which:\r\n1) fails to rewrite the text message\r\n2) hallucinates the sender parameter\r\n3) gets a text to\
      \ speech file with the correct tone but does nothing with it.\r\nWhen I replaced \"emotional content\" with \"tone\"\
      \ in the prompt, the model responded correctly."
- name: Entry 62
  tools:
  - get_point_elevation
  - get_build_height
  - get_build_age
  - get_build_history
  - get_build_fire
  messages:
  - Have there been any notable fires at the Empire State Building?
  metadata:
    failure_modes:
    - Wrong tool called
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The model should have recognised that the user was asking for notable historic fires, which get_build_history()\
      \ would have been appropriate for.\r\n\r\nThe model instead got hung up on the word \"fire\" and called a tool that's\
      \ clearly described as returning the number of fire escapes: get_build_fire().\r\n\r\nOn top of that, the get_build_fire()\
      \ tool specifies that the FULL building address (or co-ordinates) must be used, not just the name of the building used\
      \ here. IF the model was lacking the full address it should have said so, although I also tried asking it directly for\
      \ the full address on another prompt and it knew exactly where it was, so was just being careless / ignoring tool+parameter\
      \ descriptions here."
- name: Entry 63
  tools:
  - find_overlapping_slots
  - create_calendar_hold
  - get_free_busy
  - check_room_availability
  - send_calendar_email
  - convert_time_zone
  - get_regional_holidays
  - get_dst_transition
  messages:
  - 'Today is Sat 2025-03-29. Please find a 30-minute slot tomorrow that works for alex@acme.com (New York), yuta@acme.jp
    (Kyoto), and andy@acme.ca(Vancouver) between 09:30–11:00 London time.

    If any of those regions (NY state, Kyoto, or New Zealand) has a public holiday tomorrow, don’t hold anything, just tell
    me. Otherwise, hold the earliest one.'
  metadata:
    failure_modes:
    - Wrong tool called
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The model failed to call the required overlap search and holiday check for this prompt. It called\
      \ get_free_busy, which does not compute a shared 30-minute window, and then made several unnecessary convert_time_zone\
      \ calls. Those conversions were also misused: it treated an already-UTC timestamp (...09:30:00Z) as if it were London\
      \ local time and never converted the end of the window. Because tomorrow is 2025-03-30, the day London switches to BST\
      \ (UTC+1), the correct window 09:30–11:00 London should be converted to 08:30–10:00Z. What it should have done instead\
      \ was make two initial, non-sequential calls:\r\nget_regional_holidays(regions=[\"US-NY\",\"JP\",\"NZ\"], date=\"2025-03-30\"\
      ) and\r\nfind_overlapping_slots(attendees=[\"alex@acme.com\",\"yuta@acme.jp\",\"andy@acme.ca\"], duration_min=30, window_start=\"\
      2025-03-30T08:30:00Z\", window_end=\"2025-03-30T10:00:00Z\", priority=\"earliest\"),\r\nthen wait for results before\
      \ placing any hold. The likely cause is tool overlap confusion (free/busy vs overlap), plus DST/time-zone handling errors\
      \ and an urge to “show work” by converting times per attendee instead of normalizing the London window to UTC and calling\
      \ the correct tool."
- name: Entry 64
  tools:
  - get_lat_long
  - get_weather_at_lat_long
  - get_nearby_activities
  - check_activity_cancelled
  - get_additive_date
  - get_date
  - get_day_from_date
  messages:
  - I'm currently doing the parkrun at St. James's Park but I am worried about the weather when I return home. I often do
    the parkrun in Wollaton Park on Saturdays, but I am not sure if it will be cancelled? I think I might have to do something
    different, could you give me some examples?
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The functions available to the model were as follows:\r\n        1. get_lat_long: gets the latitude\
      \ and longitude of the given location.\r\n        2. get_weather_at_lat_long: gets the weather at the given latitude\
      \ and longitude.\r\n        3. get_nearby_activities: gets a list of possible activities nearby the given location.\r\
      \n        4. check_activity_cancelled: checks if the given activity has been cancelled.\r\n        5. get_additive_date:\
      \ adds a specified number of days to the given date.\r\n        6. get_date: gets the current date.\r\n\r\nThe prompt\
      \ is asking multiple questions, but really the following three questions need to be answered. 1. Has the parkrun at\
      \ Wollaton park for next Saturday been cancelled? 2. What will the weather be like at Wollaton Park next Saturday? 3.\
      \ What alternative activites are available near Wollaton Park?\r\n\r\nThe expected way to solve this prompt is given\
      \ below:\r\nQuestion 1: (it is possible that the model could do this without the tools, but it is expected to use the\
      \ tools available to properly validate this)\r\n        1. get_date (to get current date)\r\n        2. get_day_from_date\
      \ (to calculate the days between this day, and next Saturday)\r\n        3. get_additive_date (to calculate the date\
      \ at next Saturday)\r\n        4. check_activity_cancelled (to check if the parkrun at Wollaton Park on the date next\
      \ Saturday has been cancelled)\r\nQuestion 2:\r\n        5. get_lat_long (to get the latitude and longitude for Wollaton\
      \ Park)\r\n        6. get_weather_at_lat_long (to get the weather at the latitude/ longitude for Wollaton Park for the\
      \ date next Saturday)\r\nQuestion 3:\r\n        7. get_nearby_activities (to check for activities available near Wollaton\
      \ Park)\r\n\r\nBecause the model is incapable of executing sequential tool calling, only the tool calls for the first\
      \ step in each question should be present in the response, so we would expect to see the following:\r\n        1. get_date\
      \ (to get current date)\r\n        2. get_lat_long (to get the latitude and longitude for Wollaton Park)\r\n       \
      \ 3. get_nearby_activities (to check for activities available near Wollaton Park)\r\n\r\nThe way the model solved this\
      \ prompt was the following:\r\n        1. get_lat_long(location_name=\"St. James's Park\")\r\n        2. get_lat_long(location_name=\"\
      Wollaton Park\")\r\n        3. get_nearby_activities(location_name=\"Wollaton Park\") \r\n        4. get_nearby_activities(location_name=\"\
      St. James's Park\")\r\n\r\nThe model should not have made any tool calls regarding St. James' Park as that had no bearing\
      \ on any of the questions being asked and should have begun the process of figuring out the date for next Saturday so\
      \ it could properly field the queries in the prompt regarding the weather and the status of the running event. Tool\
      \ calls 2 and 3 were fine as call 2's result is required before the weather call can be made to answer question 2 and\
      \ call 3 didn't depend on anything else, so it could be answered directly."
- name: Entry 65
  tools:
  - send_email
  - get_local_business_headline
  messages:
  - I want to send an email to jim@tele.com and steve@rele.com to tell them about the new tyres. There have been issues in
    the local news recently around the roads and I want them to have safe vehicles, especially if the issue is still reported
    in the local news. There have been issues in Kent and Surrey but we're in Stevenage where there aren't normally issues.
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: The model used the "get_local_business_headline" tool when it was supposed to use the "send_email"
      tool instead. The model was likely confused by the mention of local news and the inclusions of location names "Kent",
      "Surrey", and "Stevenage", which prompted the model to call for local business headlines instead.
- name: Entry 66
  tools:
  - request_booking
  - order_food
  - book_table
  - release_table
  - clean_table
  messages:
  - i'm looking for somewhere to eat with my girlfriend for our anniversary. we want to order mains and desserts but not starters.
    she really wants to order a salmon dish with lemon. do you have any recommendations for where we could book a table in
    london?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: "I gave the model a lot of context, saying that I wanted to eat somewhere, talking about the order\
      \ I wanted to make and the dishes I want. The only actual question in the prompt is, \"Do you have any recommendations\"\
      , so I wanted the model to tell me about (real or fictional) restaurants in London that take bookings. Because I asked\
      \ \"where we could book a table\", the model assumed I was making a booking request, but in the context this is not\
      \ an appropriate answer because I haven't specified a restaurant. \r\n\r\nAdditionally, the model has assumed that my\
      \ party has dietary needs, most likely because I specified that, \"she really wants to order a salmon dish with lemon.\"\
      \ This is a preference but is not an allergy or dietary need, so the model should not have made this assumption. It\
      \ has also hallucinated a time and date, which I didn't specify anywhere in the prompt. \r\n\r\nThe model should have\
      \ responded with a list of restaurants in London that take bookings (of which there are plenty). Or, if the model is\
      \ not able to find this information (due to lack of internet access or training date constraints) then it should have\
      \ told me that it was unable to complete the request rather than making a tool call. "
- name: Entry 67
  tools:
  - get_pubs
  - get_taxi
  - get_bus
  messages:
  - 'Here, lad, Johny and I went over to O''Neil''s last night, and it was a blast. Can''t remember the last time we had such
    good craic. We plan on doing it again, but this time around, old Patricia isn''t around to see us out no more. Sure, we
    are in Macroom, it''s not a bother getting home, isn''t it? I just hope tis not raining, y''know yourself. Dunno whether
    I should get the uber or just stick with the old system. Sure, y''know what, feck the uber, too expensive. But jeez, I
    dunno about the journey lad, Macroom is a bit dodgy.


    Ya reckon ol'' Jimmy Murphy is gonna do the Cranberries again? That was amazing wasn''t it. Fecking love that guy, old
    geezer.'
  metadata:
    failure_modes:
    - Wrong tool called
    - Missing parameter
    worker_explanation: "The model made two main errors. Namely, it called the wrong tool, i.e. get_taxi(), and it was also\
      \ missing a parameter \"mus\" inside the get_pubs() function call.\r\n\r\nFirstly, the prompt specified that the user\
      \ will be using \"the old system\", i.e. the bus rather than a taxi, as the taxi is too expensive for his needs. Even\
      \ though it was integrated into the prompt, the model failed to see this and instead called the get_taxi() function,\
      \ which is simply incorrect.\r\n\r\nSecondly, the prompt specifically included the user's reaction to \"Jimmy Murphy\"\
      \ playing music from the famous \"Cranberries\". The user stated that it was amazing and that he loves stuff like that.\
      \ Therefore, the model should've automatically put the parameter \"mus=true\" into the get_pubs() function call, which,\
      \ of course, it didn't.\r\n\r\nIn terms of the insights as to why the model failed. I believe that the model failed\
      \ due to a variety of reasons. One such reason would be the ambiguity in natural language. I wrote the prompt in Irish\
      \ English with a lot of slang. It is readable, but it takes time and careful attention to fully get the message across.\
      \ For example, I used \"the old system\" as a replacement for the bus, which, in the context of the prompt, makes complete\
      \ sense. The model might've had difficulties with the slang or the word choice. I also put in a point about music and\
      \ the Cranberries, which the model failed to notice and use. I didn't explicitly state \"make sure the pub has live\
      \ music\", but the prompt's context is sufficient for the model to guess that that was the case.\r\n\r\nAnother reason\
      \ would be mixed signals. Inside the prompt, I put down that the user doesn't know whether they want to use the taxi\
      \ or the bus; however, after a bit of thought, the user insisted on using the bus, as a taxi is too expensive. While\
      \ at the same time, claiming that the bus might be risky as well. The prompt didn't state anything about not using the\
      \ bus; meanwhile, it stated not using the taxi. Even though the bus might've been a dangerous choice according to the\
      \ user, the user still ended up choosing it. The model might've noticed the user not being sure and reinterpreted it\
      \ as not wanting to ride the bus.\r\n\r\nThe last reason why the model might've failed would be the complexity. The\
      \ prompt contained a lot of useless information, such as the weather or about \"Patricia\" or \"Jimmy Murphy\". In general,\
      \ the prompt did many circles before getting to the main request; therefore, the model might've been confused due to\
      \ all this nonsense."
- name: Entry 68
  tools:
  - device_activation
  - register_device
  - set_routine
  - remove_device
  - remote_authentication
  - shutdown_network
  messages:
  - I love the ability to set routines and really think I should set more in the future, especially for evenings to turn my
    lights off at 12am every night. I'll brainstorm some things to set routines for, maybe you can help me? What are some
    good routines to set?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: The model incorrectly called the set_routine tool when an actual request for it's use was not made.
      I used most of the message to talk about setting routines, and even one that I think I need, but my request to the model
      was to help me brainstorm routine ideas, not set a routine. I think this confused the model, especially since I provided
      specifics about the routine I was thinking about needing. It should have just acknowledged it was a good idea to have
      a routine to turn off the lights at 12 a.m. every night, and move on with the routine recommendation.
- name: Entry 69
  tools:
  - get_blu_rays_for_sale
  - get_blu_ray_information
  - get_postage_information
  - get_blu_ray_game_information
  messages:
  - What do you think about the concept of movie and game companies self censoring, because certain jurisdictions and companies
    refuse to certify/sell R rated products?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Missing parameter
    worker_explanation: The model incorrectly called the `get_blu_rays_for_sale()` and `get_blu_ray_game_information()` functions
      when it was not necessary to call either function. I believe these function calls were partly caused by reference to
      movie and game companies in reference to the concept of self censorship. The model should have recognized that no tool
      calls were required and only necessitated a conversational reply. Additionally, even if we were to assume a call was
      required, the model was incorrect in its call to get_blu_ray_game_information(), as it failed to provide an argument
      for the "game_name" parameter, which is a required parameter.
- name: Entry 70
  tools:
  - set_long_order
  - set_short_order
  - close_position
  messages:
  - I work at Microsoft, I am pretty sure they are going to miss earning. I want to bet £3000 that it will fall with a 10%
    stop loss, leverage it 5x. Use the money currently in my long position plus £500 cash.
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The prompt is asking to close a Microsoft long position and place it into a short plus some money
      from a cash position. The model fails to call the tool close_position tool to close the long order, and in its set_short_order
      call it uses the wrong value for the amount parameter (should be 3000 total as stated).
- name: Entry 71
  tools:
  - order_pizza
  - order_chinese
  - order_indian
  - order_burger
  - book_restaurant_reservation
  messages:
  - Wow what a week it has been, I am so glad it is Friday today! I am kind of sick of working from home all the time, I want
    to get out of the house. I skipped lunch today because we had an emergency meeting so I am starving right now. I think
    I am in the mood to try some good food.
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: "After receiving the user's prompt the model called the incorrect tool. The user mentioned how they\
      \ were tired of staying home, wanted to get out and were looking to eat, the model should have made the decision to\
      \ call the tool book_restaurant_reservation but instead it called order_pizza and order_burger.\r\n\r\nOne explanation\
      \ as to why the model failed was the user mentioned at the end it was looking to eat some \"good food\", universally\
      \ burgers and pizzas are seen as good/enjoyable foods and this might have confused the model. It seemed the model ignored/forgot\
      \ the stuff the user said earlier and instead focused heavily on this."
- name: Entry 72
  tools:
  - get_monitor_information
  - search_monitors
  messages:
  - i heard there's a monitor with a 0.5khz rate, can you give me more info
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    worker_explanation: The model fails to make a search_monitor call, asking the user if they want to search for a refresh
      rate in hertz or if they have a monitor number instead. The model should have basic knowledge that khz means kilohertz
      and what the kilo prefix means. The model should have made a search_monitor call using 500 as the value for the refresh_rate
      parameter. Of note is that previous attempts where the prompt stated a 1khz rate resulted in the model making successful
      tool calls with 1000 as the refresh_rate parameter value.
- name: Entry 73
  tools:
  - add_token
  - remove_token
  - valid_token
  messages:
  - A user's old JWT has expired (old_jwt) which was removed and he's got a new one now (new_jwt) that has been registered
    and validated. How can I tell who is currently logged in?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: The prompt indicated that the JWT for a user was properly revoked and reissued and validated. The
      prompt then asked for a list of users currently logged in. There's actually no tool for that, but it suggested valid_token()
      which is not useful here. I suspect the model was conflating the two issues - being logged in with a valid token, and
      retrieving a list of users who are currently logged in, as that's one approach - getting a list of valid JWTs, but there
      is no way the valid_token() tool should have been mistakenly thought to be able to produce such a list based on its
      definition.
- name: Entry 74
  tools:
  - generate_recipe
  - woolworths_product_search
  messages:
  - I had a long day at work and just want something frozen that I can heat up for dinner tonight. I'm going to head past
    the shops on the way home. I feel like Italian, what are some of my options?
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: The model called the AI recipe generator tool instead of Woolworths Product Search. It also put "Italian
      frozen dinner" as the dish name parameter, which really doesn't make any sense. The model saw the request for "Italian"
      and that it could be used in the cuisine parameter, so went with the recipe tool. It failed to recognise that the user
      didn't want to cook and was looking for a frozen meal from the supermarket.
- name: Entry 75
  tools:
  - distance
  - get_latlong
  messages:
  - 'How long will it take me to get from 40°43''29.2"N 74°00''06.4"W to 40°48''37.8"N 73°53''25.0"W? My car broke down.

    '
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The model passed the 'method' parameter as 'driving', when the prompt specifically states that my
      car broke down, so driving is not the option that should have been inferred. The 'walking' parameter was given as the
      default, but the model still picked 'driving', probably due to the mention of a car in the prompt. It should have inferred
      the method as 'walking' due to the information about the car being broken down.
- name: Entry 76
  tools:
  - get_flavours
  - create_desert
  - order
  - progress_update
  - cancel_order
  messages:
  - How long does it take to make one scoop of chocolate ice cream in a tub! If you are not here in the next 5 minutes you
    can forget it and cancel my order on table 5. What's my ETA?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: "The long, rambling complaint in the prompt confused the model into making multiple unwarranted model\
      \ calls: get_flavours, create_desert, and cancel_order. \r\n\r\nThe only question in the prompt is \"What's my ETA?\"\
      , so the only call required was 'progress_update' with table number 5. The model did include this correctly. All the\
      \ other sentences were expressing emotion, and the exclamation mark in the first sentence and the threat words in the\
      \ second sentence should have made that clear.\r\n\r\nThe model had all the data it needed to call create_desert, so\
      \ I assume that's why it attempted the call. The prompt intended to confuse the model into cancelling the order by including\
      \ \"cancel my order\" in the complaint, but the language makes it clear that it is a threat rather than the current\
      \ request. I've no idea why it thought get_flavours was needed, and it didn't make sense to create a desert, not order\
      \ it, yet still query its progress at the same time - it just seemed overwhelmed and called nearly everything. "
- name: Entry 77
  tools:
  - get_calories
  - get_protein
  - get_carbs
  messages:
  - Today I have eaten porridge, 2 eggs, 2 slices of sourdough bread with butter, and then had a big mac with fries from mcdonalds
    at lunch. I think I may have eaten too many carbs or not enough protein for today. Should I eat a beef curry tonight or
    have beef curry tomorrow?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Didn't use a tool call when it was supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The model failed in a couple of dimensions here. Firstly, it uses "2 eggs" as a `meal_name` parameter,
      and then also uses the number `2` for the `servings` parameter. While the mistake is somewhat understandable for a naive
      model, I didn't state that I ate 2 servings of 2 eggs, but rather that I just ate 2 eggs. The model should have interpreted
      this by using either the number 1 for the `servings` parameter, OR simply `egg` for the `meal_name` parameter. A similar
      mistake was made with the sourdough bread. Secondly, my central question revolved around the beef curry that I plan
      on eating either tonight or tomorrow, and therefore I also would at the least need to know the nutritional information
      involved with the beef curry, which the model failed to acknowledge completely. Additionally, since I never mentioned
      any concern about my caloric intake for the day, it wasn't strictly necessary for the model to call `get_calories()`,
      though here it might be said that the model was just trying to be as comprehensively helpful as possible, which may
      not be an issue.
- name: Entry 78
  tools:
  - search_anime
  - get_anime_details
  - get_top_rated
  - recommend_similar_by_title
  messages:
  - In the past year , I watched a lot of Anime but mainly Naruto, would love to watch similar but in Spanish.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Wrong tool called
    worker_explanation: I informed the model that I had watched Naruto. It attempted to comprehend what this anime is about
      in order to generate recommendations independently. However, there is a specific function designed for this purpose.
      The model should have only invoked recommend_similar_by_title(title="Naruto") to provide recommendations for similar
      content.
- name: Entry 79
  tools:
  - get_calendar_events
  - list_movies
  messages:
  - I've been so stressed lately and need some time off but I just don't know when I'll fit that in with my busy schedule.
    My friend, April, suggested we go watch a movie but she knows I don't like the crowds so I don't know what to do.
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: My prompt required the model to tell me an ideal time off within my busy schedule as an inferred,
      primary goal. I tried to confuse it with irrelevant information - that my friend, April (which is a valid human name
      but could potentially confuse an AI to think I'm talking about the month) wants to go watch a movie but clearly stated
      that I hate movies. The error arises as the AI proceeds to show me upcoming movies with a "list_movies()" call. Instead,
      the model should have retrieved the user calendar using "get_calendar_events()" to find a time in the user's schedule
      for time off. While this is an inferred part of the prompt, the model should definitely identify this as the key part
      for a successful response.
- name: Entry 80
  tools:
  - login
  - logout
  - renew
  - register
  - reset
  - remove
  messages:
  - 'We''ve had a security breach. I''ve set everybody''s passwords to random 32-char hex values internally. I want to ensure
    everyone can still login though. Here''s the list of usernames (eg: "user1@example.com", "user2@somewhere.com")'
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    worker_explanation: The intent was for the model to call reset() for each of the usernames to initiate their ability to
      reset their own passwords and log in again, the typical procedure that happens after a breach. Generally, passwords
      are stored as hash values, so setting them to random values ensures that *nobody* knows what the passwords are, and
      there's nothing anyone can do to get around that. Users would use MFA or similar to log in again, and the tool here
      is just the need to call rest() to issue those MFA requests.
- name: Entry 81
  tools:
  - find_recipe
  - send_text
  - set_reminder
  messages:
  - So, Ahmed helped me move last week, and I promised him dinner tomorrow night. I’m thinking chicken, Halal since he’s really
    particular. I was just texting him about it. Can you deal with this?
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: "The model sent a message to Ahmed instead of searching for a recipe. It acted on the line \"I was\
      \ just texting him about it\" and the unclear \"Can you deal with this?\" and chose to send a message instead of a search.\
      \ What it should have done is search for a Halal chicken recipe (i.e., called find_recipe with dish = \"chicken\" and\
      \ dietary_preference = \"Halal\") and replied with that result. Why it went wrong is simply that the casual mention\
      \ of texting and the imprecise request confused the intention, nudging the model towards the more concrete action (texting)\
      \ instead of the recipe search.\r\n"
- name: Entry 82
  tools:
  - get_energy_drink_info
  - compare_energy_drinks
  - get_caffeine_warning
  - suggest_energy_drink
  - track_energy_drink_consumption
  - find_energy_drinks_by_ingredient
  - rate_energy_drink
  messages:
  - 'I need some caffeine. I want an energy drink rn. I want one with a ton of caffeine. are there any with over 100 mg of
    caffeine??? maybe it could have a fruity, oaky taste.  would that be to much caffeine? '
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: I asked for a drink with over 100 mg of caffeine & it set the value of max_caffeine_mg to 100. This
      would only give me drinks that have 100mg or less but I asked for ones with more then 100mg. This is an optional parameter
      so it didn't even need to be included. It did everything else correctly but it wouldn't be able to provide me with the
      energy drinks I wanted. It was a simple mistake of not understanding that if I want more than 100mg, you can't set the
      max to be 100mg.
- name: Entry 83
  tools:
  - business_netincome
  messages:
  - I live in Manhattan so I hired an employee for my flower shop since the commute is long. It brings in $10,000 and the
    expenses are $8,000 excluding taxes or fees. My employee seems to be doing a good job but don't know if I should lay them
    off and just commute to Newark to run it myself to save money.
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The model interpreted the flower store being run in Manhattan instead of Newark which would change
      the tax situation dramatically and provide a wrong net income estimate for the user. The model should have used Newark
      as the city parameter to give an accurate estimate for net income after local taxes and fees are deducted.
- name: Entry 84
  tools:
  - front_door_camera
  - make_coffee
  - send_email
  messages:
  - Thanks for the coffee. I need you to send a quick email for me. The door is going to ring any minute. I need to send an
    important email to lawyers@firm.com.au stating that I have seen the documents request and I will send them through before
    COB. subject can be document request or similar. cc my husband.
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    - Missing parameter
    worker_explanation: The model called the correct tool and used the correct body, subject_line, and send_to parameters
      but it missed the "urgent" parameter. This is likely due to the fact that i specified the email as "important" instead
      of "urgent", however, the use of the work important paired with the recipient and email contents should have been enough
      context for the model to identify that this was an urgent email request. In addition, I asked to cc in my husband but
      did not provide an email for him and as such, this parameter is also not correct. The correct tool call should have
      been [send_email(send_to="lawyers@firm.com.au", body="I have seen the documents request and I will send them through
      before COB.", subject_line="document request", "urgent" = "true")] with the copy_in parameter excluded due to not enough
      information.
- name: Entry 85
  tools:
  - set_long_order
  - set_short_order
  - close_position
  messages:
  - I have been told that tesla is likely to collapse due to competition with the major car brands, I have never shorted a
    stock before, what would be the risk of me dropping £500 into a short position.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: 'The prompt was clearly coming from a user not knowing what shorting is, the model should have explained
      shorting & what risks they are, rather than taking the question as a command to short Tesla. A tool call in this instance
      wouldn''t make any sense, the user was clearly just asking a hypothetical about the risks of shorting a Telsa stock.
      The model also made some assumptions about the rest of the parameters should be in the tool call for shorting Telsa. '
- name: Entry 86
  tools:
  - get_exercises
  - get_calories_burned
  - log_workout
  - log_exercise
  messages:
  - I just hit a new PR in my lower body workout. I managed to deadlift 200kg for 5 reps in my first set. What weight is that
    in lbs?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: The model called get_exercises function which wasn't the correct approach. The prompt implied the
      user has just completed a lower body workout, this was included to trick the model into calling the log_workout function.
      However, since the prompt only asked to convert 200kg into lbs, and there was no function to do this, the model should
      have returned a text-based response stating it is unable to answer the prompt. The get_exercises function was totally
      unrelated to the prompt in this case.
- name: Entry 87
  tools:
  - save_grade
  - calculate_final_grade
  - generate_grade_report
  - flag_at_risk_students
  - export_grades
  messages:
  - What's a simple way to present students their grades over time so they can see how they are doing without impacting their
    motivation? How should I plan this, help me brainstorm ideas.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: The model called the generate_grade_report tool but it shouldn't have called any tool because it was
      asked to help with brainstorming - the user didn't request a student report at this point. The model got confused because
      the user mentioned "presenting students their grades" which might hint at that specific tool (if taken out of context)
      but the prompt is conceptual and hypothetical, it is not asking for actual grade data.
- name: Entry 88
  tools:
  - pokemon_use_stats
  - best_teammates
  - pokemon_tier
  - pokemon_loadouts
  - is_pokemon_available
  messages:
  - Do you think it's possible to make Gardevoir work in gen 8 OU ?
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    - Wrong tool called
    worker_explanation: The user uses the phrase 'possible to make _ work'. The model interprets this as whether or not the
      given Pokémon is available in that format. However, in this case, the user clearly is already aware of how formats work
      and has experience. The phrase 'possible to make work' refers to viability from a competitive standpoint, which is a
      very different question from 'possible to play'. The is_pokemon_available call is debatable, it's okay to make it for
      sanity check, but the user clearly already knows that the Pokémon is available. The model should be calling pokemon_tier(Gardevoir,
      gen8ou) to return information about the competitive strength of the Pokémon in that format, and follow it up with a
      list of possible teammates for the Pokémon, with the get_best_teammates tool.
- name: Entry 89
  tools:
  - verify_id
  - evaluate_patron
  - get_drink_summary
  - make_drink
  - check_inventory
  - cut_off_patron
  - suggest_drink
  messages:
  - 'Three new orders have come in:


    Patron: 155821

    ID Verified: True

    Drinks Had: 0

    Order: "I don''t know. Give me something fruity."


    Patron: 11664

    ID Verified: False

    Drinks Had: 0

    Order: "I''ll take a whiskey sour please."


    Patron: 71432

    ID Verified: True

    Drinks Had: 8

    Order: "Let''s do some shots!"'
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: "Model did not infer that alcohol should not be served without ID verification.  Since patron 11664\
      \ does not have a verified ID, model should have called `verify_id()` tool (would have needed to clarify parameters\
      \ first).  Furthermore, even if patron 11664 was verified, there is no need to call `suggest_drink()` because they are\
      \ ordering a specific drink (\"whiskey sour\") and do not need suggestions.\r\n"
- name: Entry 90
  tools:
  - find_dealership_nearby
  - get_recommended_tire_pressure
  - get_maximum_tire_pressure
  messages:
  - I just bought a 2022 Honda civic sports car, and I was excited but now I'm just embarrassed. I don't want to have to find
    a dealership, but I might have to, because I don't know how to fill my own tires. What's the maximum psi I should be putting
    in?
  metadata:
    failure_modes:
    - Wrong tool called
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The model called the wrong function and hallucinated one of its parameter values. The user asked\
      \ for the \"maximum psi\" to put in their tires, which is why the model was drawn to use `get_maximum_tire_pressure`.\
      \ However, they continued to say \"I should be putting in\", which implies that the user wants the suggested tire pressure\
      \ (`get_recommended_tire_pressure`) not the maximum tire pressure. \r\n\r\nIt's important to note that these are two\
      \ different things. The maximum tire pressure is the actual maximum that a tire can physically handle based on how it\
      \ was manufactured for safety purposes. The recommended tire pressure is what is suggested for the load of a specific\
      \ vehicle for optimal performance. This information requires the details of the actual vehicle, not the tire manufacturing\
      \ details.\r\n\r\nThe biggest clue for the model should have been that the user gave all the information for their vehicle\
      \ (make, model, year, option) and did not provide a TIN number to identify a specific tire. The model ended up hallucinating\
      \ the TIN as \"DOT1234567890\" for some reason. It seems that the model hyper-focused on the exact wording in the prompt\
      \ (\"maximum\") and prioritized this over any implied context (\"should be putting in\") or the presence (or lack thereof)\
      \ of required function parameters in the prompt."
- name: Entry 91
  tools:
  - get_nuts
  - get_cals
  - get_ingr
  messages:
  - Are there nuts in this granola bar, cos I'm allergic.  9403110043416
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Didn't use a tool call when it was supposed to
    - Wrong tool called
    worker_explanation: "The user has asked about product ingredients, which requires the use of get_ingr(). The model has\
      \ seen the word \"nuts\" and incorrectly associated it with shortened \"nutrients\" in get_nuts(), even though the tool\
      \ descriptions clearly describe what each ones does.\r\nAcross ~10 attempts it's a consistent failure, always calling\
      \ the wrong get_nuts() tool and never get_ingr(). Although it uses the correct parameters."
- name: Entry 92
  tools:
  - get_latest_rates
  - convert_currency
  - get_supported_codes
  messages:
  - I'm worried that if I change dollars to euros and then to the currency from Romania, I'll lose too much on conversion.
    What's the rate of dollar home in Australia if I want to convert directly to Romanian currency?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: The model called "get_latest_rates()" when this was not needed to fulfil the user request. Its purpose
      is inherently embedded as part of the "convert_currency()" call. It correctly retrieved the tools it did need - retrieving
      available currency codes with "get_supported_codes()", and the conversion itself with "convert_currency()". The model
      likely made an extra call due to the added complexity surrounding the real request, when in reality the only actual
      request is a simple currency conversion which it has a specific tool for.
- name: Entry 93
  tools:
  - chinese_restaurant
  - reserve_seat
  - get_res_dishes
  messages:
  - I’m at T3 arrivals, Beijing Daxing International Airport, with four friends—and we’re craving Chinese food ASAP. I remember
    a place called Long Xing Xuan about 200 m southeast of the terminal entrance, marked by two big red lanterns. Could you
    ring them up and confirm if they’ve got a table that is 60-plus tonight around 6 p.m. (the bigger, the luckier)? If it’s
    free, please lock it down for us.
  metadata:
    failure_modes:
    - Incorrect typing (ex. model gave a string value for an integer field)
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The model supplied the parameter for tab_num(table number) as \"big\", I asked for a table that is\
      \ 60-plus. The problem is that the parameter tab_num requires a number as an input. The correct tool call would contain\
      \ the number for the table to be 60 and up, meaning table 60 or table 61.\r\n\r\n[Chinese_restaurant(lat=39.8934, lng=116.4764,\
      \ radius_km=0.2), reserve_seat(restaurant_id=\"Long Xing Xuan\", tab_num=\"60\", arrive_time=18, sets_res=5)]"
- name: Entry 94
  tools:
  - get_delivery_eta
  - place_order
  messages:
  - It's 6:30 pm right now in Andheri West. I’m deciding between Bombay Burger Co. and Spice Symphony for delivery to Oshiwara.
    If I place the order for 7:05 pm, which one gets here faster? Please don’t place the order—just tell me which is faster.
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The prompt requires computing a scheduled time of 7:05 pm today in local time and formatting it as
      ISO 8601. The model produced 2023-08-12T18:05:00+05:30, which has the wrong time. Everything else was fine. The correct
      calls should have used order_datetime_iso="2023-08-12T19:05:00+05:30" for both restaurants, then compared ETAs and answered
      which is faster.
- name: Entry 95
  tools:
  - get_parks
  - get_campgrounds
  - get_alerts
  messages:
  - I wonder if it's safe to go to Michigan state park.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: "I gave the model an API that gives information about national parks, and then asked it for information\
      \ about a state park. The reason the model failed is probably because it doesn't understand that the national park service\
      \ is completely distinct from the state park service. Either that, or it just ignored the descriptions, which said that\
      \ the information returned was for national parks.\r\n\r\nThought process when choosing prompt tactic:\r\nThat's not\
      \ \"missing inferable information\", because you can't infer which national park a person wants based on which state\
      \ park they want - they're mutually exclusive (a park is either a state park or a national park, not both). \r\nPerhaps\
      \ the best choice would be \"adding complexity\" because I talk about a state park when there's a schema about national\
      \ parks? I don't feel like that fits.\r\nMaybe it's \"Mixed signals\" - I'm asking about state parks, and there is a\
      \ get_parks function, it's just that the description says it's for national parks, which aren't state parks. I guess\
      \ this is the most appropriate. "
- name: Entry 96
  tools:
  - search_venues
  - check_photographer_availability
  - generate_quote
  - book_shoot
  - send_contract
  - collect_payment
  - deliver_gallery
  messages:
  - "I need a wedding photographer. I need to prepare for the food, cake, invitations and all the other wedding planning things.\
    \ My bridesmaids have all failed me, and none of them have bothered to let me know that the quotes they got were not for\
    \ a specific date. \n\nI have several dates in mind depending on the weather. I wonder which will be best. August or December.\
    \ Which do you think?\n\nFinally, whatever you do, don't book a boudoir photographer."
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    worker_explanation: "The model judged that there was no way to use the tool to answer the question, when in reality, the\
      \ model should have worked out that it could have found a couple of photographers and then got a quote for August and\
      \ one for December for each and been able to give some advice on which is better or cheaper.\r\n\r\nI think the Model\
      \ failed because it wanted specific information to run the tool, rather than generating some tests itself in order to\
      \ help advise."
- name: Entry 97
  tools:
  - play_song
  - create_playlist
  - search_music
  - add_song_to_playlist
  - remove_song_from_playlist
  - like_song
  - get_recommendations
  - shuffle_play_playlist
  messages:
  - I could listen to my 21 Pilots playlist on shuffle all day. They are my favorite. I kinda want to see them live.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: 'The model called [shuffle_play_playlist(playlist_name="21 Pilots")] when it shouldn''t have. I confused
      it by saying "I could listen to my 21 Pilots playlist on shuffle all day." But I never asked it to play the playlist.
      It inferred the tool call when really I just wanted to talk about them which is clear based on the 2 sentences after
      that. I think seeing the words "playlist on shuffle" is what confused the model into calling shuffle_play_playlist()
      even though I also never actually gave the playlists name which is a required parameter. '
- name: Entry 98
  tools:
  - pool_halls
  - table_available
  - book_table
  - cues_used
  messages:
  - What kind of cues does Efren Rayes use? He's in boston next week and I am thinking of getting a table near his to see
    him play!
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: 'The model was not supposed to call the second, pool_hall() tool call. Instead it was only supposed
      to call the cues_used() tool call to look for what kind of cue "Efren Rayes" uses. The model likely made this error
      because of the additional complexity of language added to the prompt, in which a city (Boston) is mentioned. This likely
      confused the model as "city" is the only required parameter for the pool_halls() tool call. '
- name: Entry 99
  tools:
  - get_home_devices
  - get_device_properties
  messages:
  - Man i really had to run today for work, I just hope i turned everything off in my house. Actually Im pretty confident
    I did, its just the lights really I always leave those on!
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    worker_explanation: Model correctly called get_home_devices, however this just returns an array of the devices in the
      users home. The user wanted to know if they turned the lights off. The model then failed to call get_device_properties
      to go through the array of devices and tell the user if devices with a type of light are on or off.
- name: Entry 100
  tools:
  - get_step_count
  - get_current_steps
  messages:
  - I feel like I've done a lot of steps today how does it compare to the amount I did walking around the parade Easter Sunday
    2020?
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The model failed to provide the date parameter in the correct format. In the description for the\
      \ `date` parameter in the `get_step_count` schema the required format is defined as `day–month–year`. The model failed\
      \ to infer the correct date in this format from the information in the prompt and instead copied `Easter Sunday 2020`\
      \ directly, which is not a valid date. The model should instead have inferred that `Easter Sunday 2020` was on Sun,\
      \ 12 Apr 2020 and provided this in the format `12-April-2020`.\r\n\r\nThe model also should have called `get_current_steps`\
      \ since the prompt wanted to compare it against the Easter date. The closest tactic was \"Didn't use a tool call when\
      \ it was supposed to\", as in this case it should have called both tools from the schema."
- name: Entry 101
  tools:
  - schedule_appointment
  - cancel_appointment
  - get_weather
  messages:
  - I'm feeling under the weather today, should I blow off my meeting for the 13/08/2025?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: 'The model called the ''cancel_appointment'' tool despite not being asked to. The prompt sought to
      ask the model for advice on whether I should cancel an appointment due to my feeling ill, however it assumed that I
      had requested that it cancel my meeting immediately. Additionally, it filled in parameters that I had not given information
      for - it cancelled the supposed meeting on the date that I mentioned it was to take place, but specified that it was
      a 10am meeting in the conference room, these were parameters I did not mention in the prompt. I suspect it failed at
      this task due to the misleading language I provided: the goal was to make the model think that I wanted to cancel the
      meeting, when really I was asking for advice on how I should handle the responsibility given that I am feeling unwell.
      Perhaps the model is so focussed on searching the prompt for language that matches the functions in the tool that it
      fails to realise the essence of the question being asked?'
- name: Entry 102
  tools:
  - get_route
  - get_gas_stations
  - check_traffic
  - find_accommodation
  - estimate_trip_cost
  messages:
  - 'I’m planning this massive road trip that’s going to take me from Seattle, down the coast, and through all the cool spots:
    Redwoods, San Francisco, Yosemite, LA, then looping back through Vegas, Grand Canyon, Grand Teton, and Yellowstone. The
    route is about 3500 miles, so I’m definitely expecting to spend a lot on fuel, especially with gas prices creeping up
    to over $5/gallon in California. My SUV only gets 22 MPG, which isn’t ideal for long trips, but I’m hoping the savings
    on campsites will make up for it. I’ll be bringing a tent for the national parks, but I heard some places require reservations
    months ahead of time, which could make things tricky. Any recommendations for less crowded spots?'
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Wrong tool called
    - Missing parameter
    worker_explanation: "The prompt specifies that the user will be camping at the national parks along their route (Redwoods,\
      \ Yosemite, Grand Canyon, Grand Teton, and Yellowstone) and asks for campsite recommendations. The prompt also includes\
      \ information that fulfills the parameters for additional functions, but does not actually prompt these functions to\
      \ be called. The model incorrectly calls the get_route() and estimate_trip_cost() functions since the parameters for\
      \ these functions were provided in the prompt. The information about the route and fuel consumption is only providing\
      \ context, while the actual question posed to the model is about campsites. Although the find_accommodation() function\
      \ is called in the response, it is only called for Grand Canyon and Yellowstone. I suspect these two were prioritized\
      \ because they are the most well-known national parks of the five mentioned in the prompt. The correct model response\
      \ would be as follows:\r\n\r\n[find_accommodation(location=\"Redwoods\", type=\"campsite\"), find_accommodation(location=\"\
      Yosemite\", type=\"campsite\"),\r\nfind_accommodation(location=\"Grand Canyon\", type=\"campsite\"), \r\nfind_accommodation(location=\"\
      Grand Teton\", type=\"campsite\"), find_accommodation(location=\"Yellowstone\", type=\"campsite\")]"
- name: Entry 103
  tools:
  - get_flavours
  - create_desert
  - order
  - progress_update
  - cancel_order
  messages:
  - This place is great. I love the strawberry ice create with nuts. I had 2 flakes - yummy :) Are you open on Sunday? I want
    to come back with my friends.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: "The model tried to create an ice cream when the user was clearly commenting on how much they enjoyed\
      \ their order and it ignored the question that was specifically asked. \r\n\r\nThe model should have simply responded\
      \ that the place is closed or open on Sunday, or that it didn't know, but it should not have called a tool.\r\n\r\n\
      I expect the model failed because the prompt contained the elements required to complete an ice cream order. However,\
      \ the prompt makes no attempt to order,  uses past tense \"I had 2 flakes\", asks a specific question unrelated to an\
      \ order, and even mistyped \"ice cream\" as \"ice create\". "
- name: Entry 104
  tools:
  - log_xp_gain
  - get_xp_records
  - create_goal_xp
  messages:
  - I player234 got 187.5 experience in woodcutting by cutting a yew log in rs3 at 4:53 game time. I want to see my xp records
    for the past week in woodcutting. I would like to get 10000 xp over the next two weeks. 2 minutes later, I cut another
    yew log.
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    worker_explanation: 'The error the model made was not running a second log_xp_gain tool. The model probably failed from
      associating cutting another yew log with the experience gain. Since cutting the yew log gives 187.5xp, cutting another
      yew log should create another tool call of [log_xp_gain(rsn="player234", skill="woodcutting", gained_xp=187.5, time_stamp="2023-09-01
      04:55"). This is because the model should already know the username "player234" from the use of I, associate cutting
      with woodcutting (and same action of cutting a yew log), and default "rs3" with a time stamp 2 minutes later than the
      first cut ("2 minutes later"). '
- name: Entry 105
  tools:
  - get_patient_details
  - get_drug_side_effects
  - confirm_prescription
  - update_patient_records
  messages:
  - Is John Quill still taking his medication?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The model assumed a medical number for the get_patient_details tool call when it was not provided.
      The model should have asked the user for more information and not made any assumptions. The model should not have used
      the tool call.
- name: Entry 106
  tools:
  - get_unread_emails
  - get_all_emails
  - send_email
  - reply_to_email
  messages:
  - I just took some time off work and saw that Becca from a different branch sent me an important email. If I reply to her
    letting her know I'm on holiday until the 22nd which is two weeks from now, do you think that would be okay? I'm new to
    the corporate world and not sure how to handle this, I don't want to be working on my time off
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The model misinterpreted the user's intention and assumed the user wanted to send a reply, when the\
      \ user was only asking for an opinion on how to handle a situation, which was made clear in the prompt: \"If I reply\
      \ to her..., do you think that would be okay?\". The user did not ask to send an email. Also, the model made up an email\
      \ address of the recipient \"becca@example.com\".\r\n\r\nThe ideal response here should be a message to the user, confirming\
      \ that it would be normal to reply to the email, informing Becca that the user is on holiday, and possibly including\
      \ an example email of what the user could say to Becca. It could also offer to send the suggested reply email, but it\
      \ should not do so without the user's explicit confirmation."
- name: Entry 107
  tools:
  - login
  - logout
  - renew
  - register
  - remove
  messages:
  - 'I''m working on building a black-box test suite for the REST API functions for our new web service, starting with the
    basics of logging in and out as well as adding, managing, and removing users. I think they all involve the use of JWT,
    either coming into the API or coming out of the API. Let''s assume a default role is added to the JWT for test purposes,
    that has admin authority. So we can use the test defaults of ''user@example.com" and "password1234"  and then be able
    to test our functions, and be sure that we test the deployed version with the same credentials so we are certain that
    everything still works when it is uploaded to our ISP. What do you think of this plan?

    '
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Other
    worker_explanation: I think the model is prioritizing looking for a tool to call rather than looking for the bigger picture
      requirements.  For example, if we're going to test a REST API like we have here, the plan would be more like register
      -> login -> logout or perhaps register A, register B, login A, remove B, that sort of thing. Jumping ahead to login()
      is skipping a great many steps, particularly register() if it was trying to be more direct.
- name: Entry 108
  tools:
  - currency_converter
  - one_line_translator
  messages:
  - i need to send money to france, last week the euro was worth £0.86 is it better now?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The conversion rate for the previous week was provided in the prompt, at 1EUR = 0.86 GBP, so all the
      model needed to do was identify the current conversion rate in order to compare the two numbers. It called the tool
      to get the conversion rate from the last week unnecessarily. The model also got the conversion direction wrong as it
      should have been from EUR to GBP and not the other way around since that is what the prompt had indicated.
- name: Entry 109
  tools:
  - retrieve_recipient_preferences
  - handle_fallback_delivery
  - notify_recipient_of_fallback
  messages:
  - I have an incomplete address "Main Street, Lincoln, NE" (parcel DN913506). Process a pickup point delivery.
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: "The model should have called only the handle_fallback_delivery tool. The model called retrieve_recipient_preferences\
      \ tool as well with an incomplete address which would probably result in an error. The prompt asks for a pickup point\
      \ delivery implicitly because the address is incomplete so it does not make sense to retrieve any recipient preferences\
      \ because the recipient is unknown.\r\n\r\nThe model probably got confused by the introduction of an address (even if\
      \ incomplete) in the first prompt sentence, giving it too much attention and mapping it to a tool call because of that."
- name: Entry 110
  tools:
  - search_song
  - search_album
  - search_artist
  - search_publisher
  - play_song
  - play_album
  messages:
  - My friend sent me a song, id number was 148732948710, it's called Bohemian Rhapsody by Queen, released in the 1970s. Can
    you play 39 from the same album?
  metadata:
    failure_modes:
    - Wrong tool called
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The model made 2 tool calls, search_song and search_album. The information that the model needs is
      to directly search for the song '39' by queen. The model searched for the details of the song 'Bohemian Rhapsody' using
      `search_song(query="Bohemian Rhapsody", artist="Queen")`, presumably to find the album name, but then follows this with
      another tool call `search_album(query="A Night at the Opera", artist="Queen")`, clearly already aware of the album name
      with needing to search for it. Neither of these calls is the ideal call, with the ideal call being `search_song(query='39',
      artist='Queen')` to get the song id. The wrong tool label was for calling the search_album tool, and the incorrect parameter
      was for calling the search_song tool with the song "Bohemian Rhapsody". I believe that the model was not attempting
      to play the song "Bohemian Rhapsody" as it was already given the song id needed to play the song, I think the first
      tool call was likely to find the album name, the second call to find other songs on the album, but neither were needed.
- name: Entry 111
  tools:
  - team_record
  - player_stats
  - league_stats
  - team_schedule
  messages:
  - my team, the aardvarks, played the badgers, capybaras, dingos, and elephants during the 2021 season. which of our opponents
    had the most wins in the regular season the next year?
  metadata:
    failure_modes:
    - Missing parameter
    worker_explanation: The model does ok with a lot of the complexity in the question. It recognizes which of the 5 teams
      listed are opponents, understands the correct year in question, and uses the correct tool to find the most wins. However,
      a specific part of the prompt is to include only the regular season statistics. All of the tools default to including
      additional stats (playoffs); ideally the model should have made these 4 function calls with incl_playoffs set to false.
      It's a common distinction in sports stat reporting to include/exclude playoff data, so it's not an obscure request.
      It's not clear why the model missed this requirement.
- name: Entry 112
  tools:
  - book_appointment
  - check_provider_availability
  - verify_insurance_coverage
  - find_nearby_specialists
  messages:
  - I need to see someone about my back pain - it's been getting worse since my accident last month. I'm in downtown Chicago
    and have Blue Cross coverage. Can you help me get something set up for early next week?
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    - Missing parameter
    worker_explanation: The model made several critical parameter errors despite calling the correct sequence of tools. Most
      significantly, it used "orthopedist in downtown Chicago" as the provider_name parameter in check_provider_availability()
      and verify_insurance_coverage(), when this parameter requires the actual name of a specific healthcare provider or practice
      (like "Chicago Orthopedic Center" or "Dr. Smith's Practice"). The model treated the specialty and location as if they
      were a provider name, which would cause these API calls to fail since no provider exists with that generic name. Additionally,
      the model missed the insurance_accepted parameter in the initial find_nearby_specialists() call, even though the user
      specifically mentioned having "Blue Cross Coverage" - this optional parameter should have been included to ensure only
      compatible providers were returned. The correct approach would have been to first call find_nearby_specialists() with
      the insurance parameter, then use the actual provider names returned from that search in the subsequent check_provider_availability()
      and verify_insurance_coverage() calls. This represents a failure to understand that the first tool call should return
      specific provider information that informs the parameters of subsequent calls.
- name: Entry 113
  tools:
  - get_camera_summary
  - control_lights
  - control_door_lock
  - call_authorities
  - contact_user
  - set_security_mode
  messages:
  - Good morning House! I'm leaving for work now. I've got a package coming sometime today. I told the driver to leave it
    in the garage. Let me know when they come. Be sure to lock all the doors after though. I don't need another package stolen.
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The model should have called set_security_mode with the "away" parameter, since the user specifically
      mentioned leaving, and implied that nobody would be around to meet the delivery driver. The model correctly called control_door_lock,
      but should have unlocked the garage door, not locked everything. This is because the delivery driver will need to use
      the garage door to leave the package, and locking all the doors is not requested until later.
- name: Entry 114
  tools:
  - recommend_movies
  - where_can_i_watch
  - movie_reviews
  - find_places
  messages:
  - I have great news! I asked my crush out on a date and she said YES. Our date will be tomorrow afternoon, so I need to
    make a very good plan to make it unforgettable. I have in my mind that we could watch the new "How to Train Your Dragon"
    movie in the cinema here in Georgia. I know she likes the original animated movie, and based on the reviews, the live-action
    version is also very good. What do you think?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The model used a tool call when it was not supposed to. In the prompt, the user expresses his happiness\
      \ about an upcoming date, sharing his idea of watching a movie in the cinema with his crush. The model called the \"\
      recommend_movies\" tool, which was not expected because the user didn't ask for movie recommendations. Besides that,\
      \ the model included a \"country\" parameter that is not a valid parameter for the \"recommend_movies_ function. The\
      \ model included the value \"live-action\" for the genre parameter. The description of the \"genre\" parameter explicitly\
      \ lists the possible values, and the \"live-action\" is not present on that list. \r\n\r\nSince the user only asked\
      \ the model, \"What do you think?\", it shouldn't have called any tools; instead, it should have acknowledged that going\
      \ to the cinema is a good date idea, and optionally, it could've suggested other ideas, such as going for a dinner after\
      \ the movie."
- name: Entry 115
  tools:
  - search_accommodation
  - search_restaurants
  - search_events
  - search_venues
  messages:
  - 'I’m going to travel to Sydney from Melbourne next week. I’ll be travelling with a friend from London who is a tech entrepreneur
    who will be bringing his kid with him and wants to see some live local sport. Provide some suggestions for what I could
    do with him, and some options for places where we could have a drink beforehand. '
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: 'The prompt was essentially asking for two things - live sport events and places to go for a drink
      in Sydney, Australia.  The model called search venues, but for ''sport'', when it should have called for ''alcohol''
      instead, as the prompt mentions a live sport match, which would be an event.  The model also calls search_restaurants,
      as some provide alcohol, which makes sense.  The model then called search_events passing ''sport'' as the parameter,
      which is correct. '
- name: Entry 116
  tools:
  - get_exercises
  - get_calories_burned
  messages:
  - I'm having trouble structuring my weekly gym routine. I want to do an upper body workout and a lower body workout each
    twice a week, but I also want to include a mobility day, a cardio day, and 1 rest day. The mobility day can't be directly
    after a lower body day since my legs will be too sore. Can you give me a weekly plan of what type of workout I'll do each
    day?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: The model called the get_exercises function, thinking the prompt was asking for specific exercises.
      However, since the prompt only asked for what type of workout to do each day, it's clear that a text-based response
      without function calls was the way to proceed. The model should have provided a weekly schedule with each type of workout
      assigned to a day, based on the provided constraints.
- name: Entry 117
  tools:
  - get_current_location
  - place_details
  - get_price_level
  messages:
  - I am currently travelling through Debrecen-Budapest-Vienna. I am a university student, and I do not have a high income.
    I would like to plan a 3-day trip with budget information.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: For this prompt the correct response should be either to suggest affordable activities or to ask for
      further clarification. The user does not expect exact places, because they have already specified their travel destinations.
      Also, knowing the device’s current location doesn’t significantly help, because the request is about planning a 3-day
      itinerary moving forward. The focus should be on providing general, budget-friendly recommendations rather than precise
      real-time location data.
- name: Entry 118
  tools:
  - dances
  - schedule
  - dancers
  - talents
  - find_partner
  - find_opening
  messages:
  - We're getting things ready for the big dance event this weekend. All of our dances and dancers have been entered into
    the system and all the scheduling has been input as well. I think we're ready to print the booklet to hand out to participants
    when they arrive. Let's get the data into a spreadsheet we can then massage.
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    worker_explanation: The schedule() and dancer() tools could've returned the data that we needed, with the model doing
      the join itself directly or just providing the data that would could then put into a spreadsheet and do the join ourselves.
      Either way, it has all the tools it needs to generate a suitable response. It's failure is likely because it was looking
      for a tool like "export" or "print" or something, not perhaps realizing that the schedule() and dancer() tools can "get"
      the data that we need.
- name: Entry 119
  tools:
  - rank_stats_by_uuid
  - games_to_duo
  - get_top_players
  - get_runner_up_players
  - account_info_by_uuid
  - uuid_by_account_info
  messages:
  - My friend from Europe is visiting me in Vancouver and I'm wondering how long it'll take for him to be able to play with
    me. My account is Inferno Jim#Jim and his is VengeanceNA.
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "There are two errors here. \r\n\r\nThe first is a little bit ambiguous as some games allow cross\
      \ region play, but given the schema requires the target region to be given for almost every function call, I would personally\
      \ assume that this hypothetical game doesn't. As a result, the model giving Europe for the second account's region is\
      \ incorrect because it should be clear that the player visiting from Europe has made a new account on the North American\
      \ server.\r\n\r\nThe second is in how the model determines the discriminator for the second account. I chose a name\
      \ where the final part of that name sounds somewhat like a discriminator on purpose, but I have also seen people actually\
      \ name their accounts in games like this when playing cross region. The schema itself provides default discriminators\
      \ for each region (the relevant one of which is \"NA1\" here), which I would expect to be used here as the name does\
      \ not follow the previous format of \"name#discriminator\".\r\n\r\nBoth of these errors seem to just be the model mistaking\
      \ one thing for another; Europe is *a* possible region for an account, but doesn't pass muster logically in my opinion,\
      \ and similarly NA is close to a default discriminator and certainly a valid discriminator, so despite it not following\
      \ the previous format it just goes on ahead with it."
- name: Entry 120
  tools:
  - send_message
  - get_instructions
  messages:
  - I just got a new iPhone, how to send a message to Bob saying I got a better phone than you?
  metadata:
    failure_modes:
    - Wrong tool called
    - Other
    worker_explanation: There was information available in the prompt to fulfil both calls, and the request for instructions
      ("how to....") was deliberately inexplicit. It appears the model attempted to do everything possible, or parsed the
      fragment of the prompt reading "send a message to Bob saying I got a better phone than you" as a discrete instruction.
- name: Entry 121
  tools:
  - find_overlapping_slots
  - create_calendar_hold
  - get_free_busy
  - check_room_availability
  - send_calendar_email
  - convert_time_zone
  messages:
  - Today is Mon 08/11/2025. Can you find a 45-minute slot tomorrow that works for priya@acme.com (NYC), kenji@acme.jp (Tokyo),
    and me (andy@acme.ca) (Vancouver) between 09:00–11:00 London time? If there’s an overlap, hold the earliest one; otherwise
    just tell me it’s not possible.
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The model chose the right tool (find_overlapping_slots) but passed incorrect parameter values for\
      \ the time window. It treated 09:00–11:00 London as 09:00–11:00Z, ignoring that London in August is BST (UTC+1); the\
      \ correct window is 2025-08-12T08:00:00Z–10:00:00Z.\r\nThe model seems to have likely conflated the reference timezone\
      \ with UTC, worsened by the presence of multiple timezones."
- name: Entry 122
  tools:
  - site_registration
  - add_funds
  - withdraw_funds
  - select_game
  - join_texas_cash_game
  - send_chat_message
  messages:
  - I'm james smith and I have an acc balance of $345, I want to withdraw a sixth. My paypal mail is just my full name with
    the Orcon domain (all lowercase). With my remaining balance I want to play some poker. I usually like to be in the "lucky"
    seat, and want to play 5-10. After joining the table, post a message telling them "I'm gonna take all of your money!".
    my id/ip/table is 13264500/192.168.1.204/QQ17.
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    - Missing parameter
    worker_explanation: "When calling the `withdraw_funds()` tool, the model ignored the required `paypalAccountName` attribute\
      \ of the `paypalDetails` parameter. Also, the correct \"Orcon domain\" should be \"@orcon.net.nz\". \r\n\r\nSo the correct\
      \ first tool call should be: \r\n    `withdraw_funds(amount=345/6, withdrawalMethod=\"paypal\", paypalDetails={\"paypalAccountName\"\
      : \"James Smith\" ,\"paypalEmail\": \"jamessmith@orcon.net.nz\"})`.\r\n\r\nNext, when calling the `join_texas_cash_game()`\
      \ tool, the `buyInAmount` should be `345-(345/6)` or `287.5`. Also, `seatPreference=6` is not typically considered \"\
      lucky\". The response would be better to have `seatPreference` equal to 3, 7, or 8.\r\n\r\nSo this correct tool call\
      \ should be:\r\n    `join_texas_cash_game(playerID=\"13264500\", blinds=[5, 10], buyInAmount=345-(345/6), playerBalance=345-(345/6),\
      \ ipAddress=\"192.168.1.204\", seatPreference=3)` "
- name: Entry 123
  tools:
  - get_car_value
  - find_similar
  - filter_cars
  - search_independent_garages
  - search_dealerships
  messages:
  - I'm looking to purchase a new vehicle. Ideally, I'd like it to be a Ford F150 XLT, given it will be used mostly for my
    work as a contractor, but also as a family vehicle every now and then. From the limited research that I did, the best
    and most reliable years for this car would be 2016 to 2020 with under 100k miles. I've got around 30k to 40k to spend
    on this truck. The only thing that concerns me is the lack of availability of the official Ford dealer network near where
    I reside, that is around Casper, WY. Perhaps I should start looking for something similar but from Toyota, given the ease
    of access to the dealerships around me. What Toyota would be the best for me?
  metadata:
    failure_modes:
    - Wrong tool called
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "Model failed on multiple angles in it's response. The prompt provided by the user was quite complex\
      \ and provided a lot of background information.\r\n\r\nModel created 4 function calls, with initial 2 not being required.\r\
      \n\r\nFirst one being to the filter_cars() which was unnecessary given the user did not ask for other Ford cars. Additionally,\
      \ the parameter \"condition\" was set to \"new\", even though the prompt suggests years of 2016 to 2020, which clearly\
      \ suggests a \"used\" market.\r\n\r\nSecond function call was to the search_dealerships(). This was also not required\
      \ as the user stated the lack of dealerships around him. No question regarding the validity of this statement was requested.\r\
      \n\r\nThird function call to find_similar() was not necessary, either. The condition set to \"new\" is also incorrect.\r\
      \n\r\nThe final function call is valid and requested by the user, except for the parameter used by the model. The call\
      \ is using the incorrect condition value, and also the \"use_case\" should be set to \"work\" given his statement that\
      \ the car would be mostly used for work, with limited use for family trips.\r\n\r\nAbundance of information clearly\
      \ overburdened the model and it tried to call all available functions with as many information as possible."
- name: Entry 124
  tools:
  - search_plant_species_by_leaf
  - search_plant_species_by_flower
  - filter_species_by_region
  - get_species_toxicity
  messages:
  - I’m in Ballard (Seattle) trying to ID a street-side shrub. The flowers are violet, trumpet-shaped and smell strongly at
    dusk. Could you pull matches and limit to local natives that tolerate USDA 8B with coastal exposure? There were maybe
    12 petals, but I'm not sure, so just ignore the petal count.
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The prompt requests a match for plants with violet, trumpet-shaped, and fragrant flowers. The user\
      \ also stated that they were in Seattle and that they wanted the search to be limited to local native and coastal plants.\
      \ Since there is no tool to search by both flower and region, the model correctly made calls to `search_plant_species_by_flower`\
      \ and `filter_species_by_region`. The next step (if this model was capable of sequential thinking, its next step likely\
      \ would have been to get the intersection of both tool calls' results and return that list as the answer to the user.\r\
      \n\r\nAll of the model's parameters for `filter_species_by_region` were correct (`region=\"Pacific Northwest\", hardiness_zone=\"\
      8B\", is_native=True, habitat=\"coastal\"`) (The model correctly inferred that Seattle's macro region was \"Pacific\
      \ Northwest\".) The model got the color and fragrant parameters of `search_plant_species_by_flower`, but it incorrectly\
      \ passed \"trumpet\" as its shape. The shape parameter is actually an enum, and the closest valid value would have been\
      \ \"tubular.\""
- name: Entry 125
  tools:
  - search_metadata
  - search_metadata_regex
  - change_case
  - post_format_metadata
  - post_add_tags
  - post_seo_check
  - post_create_video
  - post_submit_video
  messages:
  - 'I am spinning wheels like a mouse in a search engine optimization wheel.  I need to submit the video "Search engine optimization:
    A journey through regex, and tagging".  The description is "an introduction to SEO and regex queries" with hashtags "#SEO
    #searchengines #websites".  The hashtags are delimited by the number symbol.  The title is in title case.  Can you help
    me find out if I already submitted a video on SEO?'
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: The prompt gave the model extraneous information about a video that was to be submitted but first
      the check to see if a similar video was submitted was requested.  The model selected the post_submit_video tool.  The
      model was supposed to select the search_metadata tool in the form of [search_metadata(query="SEO")].  The prompt advised
      about the need to submit a video.  The request in the form of a question in the prompt was "Can you help me find out
      if I already submitted a video on SEO?"  This was to alert the model to focus on searching for videos on SEO before
      submitting the current video.  The prompt did not respond to that section of the prompt and instead chose to submit
      the video without responding to the question in the prompt.  The prompt also capitalized the title when their was no
      request in the prompt for changing the case of the title.
- name: Entry 126
  tools:
  - play_song
  - create_playlist
  - search_music
  - add_song_to_playlist
  - remove_song_from_playlist
  - like_song
  - get_recommendations
  - shuffle_play_playlist
  messages:
  - I love Taylor Swift and 21 pilots. I could listen to them all day. I really want to listen to some of their songs. could
    you make a playlist containing some of there songs like love story, not today and blank space then play it for me. That
    would be so goochie rn. maybe we could call it 21 swifts. it doesnt matter to me which song we start with.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The model made two distinct errors. First, this prompt requires sequential tool calling, i.e. the
      playlist needs to be created, and then the playlist needs to be shuffle played. According to the project instructions,
      the second tool call, in this case was made by `play_song` when it should have been `shuffle_play_playlist`, should
      not be present in the tool call chain as the model cannot sequentially call tools. The second problem made by the model
      is that the response mistakenly assumes that the song "Not Today" was made by Taylor Swift, but it should have been
      "21 Pilots". I think what confused it was using 2 bands and using possible ambiguous language, i.e. saying "then play
      it for me" instead of "then shuffle play the playlist".
- name: Entry 127
  tools:
  - electricity_price
  - washing_cycle_status
  - start_washing_cycle
  - estimate_washing_cycle_length
  messages:
  - With the taxes rising in Estonia, we are really trying to save on electricity. We need to do a big load of laundry to
    wash all the bedsheets and throws. Recommend me the best time to start it today (aug 12 2025). The cycle should take approximately
    5 hours.
  metadata:
    failure_modes:
    - Wrong tool called
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The prompt asked for the best time to use the washing machine for a 5-hour cycle on a specific date\
      \ while saving on electricity. The expectation was that the model would use the electricity_price tool to find out when\
      \ the 5-hour average price of electricity in Estonia is the lowest on this date. Instead, the model called estimate_washing_cycle_length,\
      \ which is completely unnecessary since the length estimate was included in the prompt. In addition, it used 5 as the\
      \ load_size parameter value, although the weight of the load was never mentioned.\r\n\r\nIt seems the model got tripped\
      \ up by me mentioning the load of laundry was big (which would be relevant for the estimate_washing_cycle_length function),\
      \ and thought the number 5 mentioned at the end of the prompt must have been the load size."
- name: Entry 128
  tools:
  - get_artist_name
  - find_festival
  - find_tickets
  - get_weather
  - near_restaurants
  messages:
  - I've heard this song "Please Please Please", it by Sabrina Carpenter, I want to sing along them live! I'm in Berlin right
    now 7/7/25 but I'll stay for at least 2 more months, it's a great place to look at the architecture here. If I sing with
    them live here what should I wear, is a t-shirt enough? Also can I eat something after that or is everything closed at
    1am? One more question, can my friend come with me too?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Didn't use a tool call when it was supposed to
    - Wrong tool called
    - Other
    worker_explanation: The model doesn't make the logical link between what to wear and the weather, plus it doesn't understand
      that it should be during the festival no the entire stay in Berlin, it should've used get_weather() tool. It doesn't
      understand I was looking for a festival because I used ambiguous writing, like a non-native beginner would talk, and
      it should've searched for festivals around Berlin where Sabrina Carpenter is singing, with find_festival(). When asked
      about if a friend could join, it should've searched for tickets with the amount "2", find_ticktes(). The get_artist_name()
      was called unnecessarily, because the artist was mention right after. The restaurants were searched for correctly. The
      model should've ignored the irrelevant information, like the architecture in Berlin, that was just dummy information.
      The response was general and not helpful, with phrases like "dress comfortably and appropriately for the occasion and
      the city's atmosphere" which is quite verbose and ambiguous.
- name: Entry 129
  tools:
  - tornado_lookup
  - ride_look_up
  - ride_share_look_up
  messages:
  - I'm going to need to catch a ride to Denver. I'm currently in Colorado Springs but by the time I need to get a ride to
    Denver I'm going to be in Mesa. There is a tornado warning so hopefully it doesn't impact this ride.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: 'The model failed as it made an extra tool call that it shouldn''t have from Colorado Springs to Denver.
      It also failed in the second tool call as it improperly inferred the location of Mesa in Arizona instead of Mesa, Colorado.
      The extra tool call probably happened because the user stated that they need to go to Denver and that they are currently
      in Colorado Springs, then followed up with the actual request that they won''t need a ride from Colorado Springs but
      from Mesa. The second error, incorrectly inferring Mesa, AZ instead of Mesa, CO when the state was left unspecified
      most likely happened because Mesa, AZ is a much bigger and more major city than Mesa, CO. The model should have made
      just one tool call to ride_share_look_up with parameters current_location={"country": "USA", "state": "Colorado", "city":
      "Mesa"} and destination_location={"country": "USA", "state": "Colorado", "city": "Denver"}. '
- name: Entry 130
  tools:
  - play_song
  - create_playlist
  - search_music
  messages:
  - I just took a trip to go see Muscle Shoals Sound Studio. I have to say, I am a huge fan of Bob Seger. Did he ever record
    there?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: The model was supposed to answer whether or not Bob Seger recorded songs in Muscle Shoals, Alabama
      (to which the answer is, yes, he recorded some of his biggest hits there). Instead the model did a tool call (search_music)
      searching for songs by Bob Seger. The model probably just saw "Bob Seger" and the word "record" and thought that the
      user wanted a list of songs by Bob Seger. The prompt has only one actionable phrase, the question "Did he ever record
      there?". This is a very clear and explicit intent, which the model does not seem to have picked up on. The previous
      part of the prompt is just filler, and the real intent is at the end. Probably the model had already identified Bob
      Seger as an artist and was laser focused on that, ignoring the question at the end which would guide it towards a plain-text
      answer with no tool usage.
- name: Entry 131
  tools:
  - pool_halls
  - table_available
  - book_table
  messages:
  - I want to book a table at Felt and Cues in Cleveland. Preferably at 8.30 on Friday, is it free?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Wrong tool called
    worker_explanation: 'The model called the pool_halls() tool, when there was no reason to do so. Instead it should have
      only called the table_available() tool. I believe it made this error because it of the natural language used - the only
      required parameter for the pool_halls() tool call is "city" and the prompt includes the word "Cleveland". I could also
      see the parameter language for the table_available() tool being an issue, because the first parameter is called "pool_hall",
      which is basically identical to the pool_halls() tool call. '
- name: Entry 132
  tools:
  - get_preacher_info
  - get_preacher_sermons
  - get_church_service_preacher
  messages:
  - 'im in newyork on going to  Saint Thomas Church just getting info that preacher_101 will be in what is the overview of
    today '
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: 'The prompt was interested in knowing the preacher''s (preacher_101) sermon. However, the response
      targets getting the preacher for Saint Thomas Church, yet the preacher''s ID is already known. The model should have
      called get_preacher_sermons.  '
- name: Entry 133
  tools:
  - crawl_lightnovel
  - parse_chapters
  - apply_translation
  - convert_to_ebook
  - upload_ebook
  messages:
  - 'I would like to read the novel "Martial World" that''s found on https://www.wuxiaworld.com/novel/martial-world

    But only the parts that cover the first arc. I''ve heard that this corresponds to chapter 120 - 150, and 155 - 180 (chapters
    151-154 are a skippable side story).

    Please get them for me, but dont be too harsh on their servers as i don''t want my IP to be flagged. Also, PNGs and JPEGs
    make my Kindle really laggy, so i dont want them. Also ensure all downloaded images appear within the text.

    I don''t have an account, so no login required! Translate the entire novel you find into Hindi please. Send the final
    version to my kindle address: 17nbist@kindle.com


    Thanks so much mate! Let me know when you''re done, im away from my computer but i got my phone on me.'
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    - Missing parameter
    worker_explanation: "The prompt explicitly requested chapters 120 - 150 and 155-180 only, but the model supplied a continuous\
      \ range from 120-180, violating this request. The model should have instead provided a chapter list containing only\
      \ the exact chapters requested. The prompt also stated not to be \"too harsh on their servers\", but a rate_limit was\
      \ not included. The model should have included a rate_limit object with a reasonable requests per minute value. Additionally,\
      \ the user also requested no PNGS or JPEGS, but implied they wanted inline images still present in their book. The assistant\
      \ should have recognised it would be perfectly valid to include WebP images, but instead set download_images to false.\
      \ Contradictingly, it still provided an image_formats array, which even included the forbidden formats explicitly not\
      \ wanted by the user. It should have instead set download_images to true and image_formats=[\"webp\"], or removed any\
      \ mention of image formatting entirely, which would have been a less egregious logical error.\r\n\r\n\r\nMaybe the model\
      \ failed due to a limited context window? Or perhaps, it isn't very good at generating long arithmetic sequences."
- name: Entry 134
  tools:
  - generate_id
  - create_profile
  - delete_profile
  - update_profile
  - send_card
  - search_profiles
  - search_cards
  - get_from_id
  messages:
  - Send a card to my sister Josephine just saying Happy Birthday. Just use the nickname I already have for her in her profile,
    Josey
  metadata:
    failure_modes:
    - Wrong tool called
    - Incorrect typing (ex. model gave a string value for an integer field)
    worker_explanation: "The model was asked to send a card to \"Josephine\" using the name \"Josey\", which was a name already\
      \ \"in her profile.\" The model rightfully concluded that it needed to call `send_card()`. However, this tool requires\
      \ the 8-digit hexadecimal ID of a profile for its `contact_id` parameter, which the prompt hasn't provided. Because\
      \ of this, the actual correct tool to call initially would be `search_profiles()` to obtain the recipient's profile\
      \ ID, which the model failed to realize: `[search_profiles(query=\"Josey\")]`.\r\n\r\nFurthermore, the model passed\
      \ \"Josey\" into the `contact_id` parameter of `send_card()`, which can be considered a type mismatch since the tool\
      \ specifically expects an 8-digit hex code (as a string). The model might have focused too much on the request to \"\
      Send a card\", convincing itself that it needed to use `send_card()` somehow and forcing itself to use it even when\
      \ it lacked all the required info (i.e., the profile ID). Alternatively (or maybe in conjunction), the model might have\
      \ been confused by the naming of `contact_id`, as it's plausible for contact IDs to be people's names in other frameworks\
      \ or systems."
- name: Entry 135
  tools:
  - add_item
  - remove_item
  - check_inventory
  - update_item
  - get_item_details
  - clear_inventory
  messages:
  - Argggh, this warehouse is going to be my death... Too much inventory... How many water bottle, how many crackers... I
    wish I could just clear its whole inventory.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: The model interpreted the exasperation of a worker and their "wish" that the workload would disappear
      as an instruction. While I'm sure most have had a moment where they'd like to get rid of a temporary annoyance, we usually
      don't mean it, especially emotionally. It seems the model does not understand the nuance of the prompt very well - to
      an English speaker, this sentence is clearly just a vent, and not explicitly requesting any action, but the model either
      misinterpreted or was unable to interpret the natural language and just called two random functions to try and "do something".
      The phrase "I wish" is really important in the final sentence, this is an explicit hint to the model that the user can't
      actually do it, they just want to do it! These are really tricky insights that the model needs to learn to understand,
      as a short phrase like that can modify the meaning of a full sentence or prompt, like in this case.
- name: Entry 136
  tools:
  - create_table
  - query_data
  - drop_table
  messages:
  - Show rows 21-30 from orders, sorted by price in reverse
  metadata:
    failure_modes:
    - Other
    worker_explanation: "In the schema, I made sure to make \"additionalProperties\" false, meaning that rownum would be rejected\
      \ as a filterable column.\r\nThis also applies to the usage of $gte and $lt. They are syntactically valid, but are not\
      \ supported by the schema.\r\n\r\nAs well as the hallucinated `order_by` parameter mentioned earlier, the schema doesn't\
      \ support that.\r\n\r\nThe model should have specified that the aforementioned issues were not supported, and ask me\
      \ to revise my prompt to fit within schema parameters."
- name: Entry 137
  tools:
  - is_odd
  - is_even
  messages:
  - Hey, is the number 12159721957129 divisible by 1?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Wrong tool called
    worker_explanation: "The model used a tool when it shouldn't have, and it used a wrong tool to boot (the fact that a number\
      \ is even or odd does not affect whether an integer is divisible by 1 or not - it always is). \r\n\r\nThis may be because\
      \ the model is too eager to use any tool - or maybe because the model got confused on 1 and 2? I can see how asking\
      \ if a number is odd can help with answering if a number is divisible by 2."
- name: Entry 138
  tools:
  - search_indeed
  - check_sharecode
  - check_right_to_work
  - employer_visa_status_requirements
  messages:
  - I'm applying for a role I found in indeed.com, it's based in London and I have a UK passport, but the company SmithTech
    is American. Do I have the right to work for them?
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: "The model should have used the following tool call: employer_visa_status_requirements(employer_name\
      \ = 'SmithTech', city='London') \r\n\r\nThe prompt was asking if they are able to work for a particular company in London,\
      \ and this tool is used to check visa status requirements of a particular employer in the UK. Instead the model saw\
      \ the phrase 'right to work' and incorrectly used the `check_right_to_work` tool which checks if an employee has the\
      \ right to work in the US based on their passport type.\r\n\r\nThis was a deliberately ambiguous prompt, using the phrase\
      \ 'right to work' and 'UK passport' to lead the model towards the incorrect tool. The model failed to grasp the significance\
      \ of working 'IN' the UK vs FOR a US company, which was clarified in the tool descriptions."
- name: Entry 139
  tools:
  - get_upcoming_tv_shows
  - get_tv_news
  messages:
  - I will fly to Tokyo next week and would like to read the headlines before I arrive, may be in Osaka or Kyoto.
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The model listed two channels Kyoto and Osaka which are incorrect, as it should have named a channel
      in that country. Perhaps NHK, the well‑known news TV channel. It also made a big mistake by calling the get_tv_news()
      function twice, because it tried to provide information for each place mentioned.
- name: Entry 140
  tools:
  - retrieve_recipient_preferences
  - handle_fallback_delivery
  - notify_recipient_of_fallback
  messages:
  - Register returning parcel DF8853234 to depot to redeliver tomorrow (requested by recipient).
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    worker_explanation: 'The model should have called the handle_fallback_delivery tool with package_id: "DF8853234" and fallback_option:
      "reschedule" as the prompt request is a case of fallback delivery handling - the driver mentions they are going to return
      a parcel to depot (they were attempting to deliver it), they mention the parcel id which is required for by the tool
      and they even mention the fallback_option (redelivery -> reschedule). The model probably failed because the prompt didn''t
      contain exact keywords like "reschedule", "fallback", "handle". For example, if I replace "Register" with "Handle",
      the model calls the tool correctly: [handle_fallback_delivery(package_id="DF8853234", fallback_option="reschedule")].'
- name: Entry 141
  tools:
  - create_membership
  - make_booking
  - cancel_membership
  messages:
  - I've been a Gold member at my local gym for around 2 months now, and I like to make a booking for a tennis court at 10:00
    - 12:00 every Saturday, regardless of if my friends are free to play (if they're not, I can just practice my serves!).
    Usually they are, though, which makes the day really fun. Terry is definitely the best player (it's funny that we're both
    called Terry!), and playing against him definitely makes me feel like I'm improving.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: The model called the make_booking tool to try to make a booking for a tennis court from 10:00 to 12:00,
      despite there being no explicit instructions to do so, as the user was merely lamenting about their tennis matches,
      and happened to mention when they were played. Instead, the response should have acknowledged the user's joy in playing
      tennis and engaged in friendly conversation by asking, for example, what inspired the user to start playing in the first
      place. From here, the model could have asked if the user would like to make a booking, instead of assuming that a booking
      should be made. I believe the model failed because the prompt contained all the information needed to make a tennis
      court booking (membership type, booking type, time frame, and name) and didn't explicitly ask for anything else; to
      assume the user wanted a tennis court booked wasn't a ludicrous leap in logic. In addition, the model is overlooking
      that the make_booking function is only for same-day bookings. If Terry wanted to make a booking, he would have to do
      it one at a time only on Saturday. (This may sound like the model needs to know the date, but it doesn't; it just needs
      to know it doesn't know and realize it would need to at a minimum confirm it is Saturday before proceeding in this direction.)
- name: Entry 142
  tools:
  - preheat_oven
  - start_dishwasher
  - brew_coffee
  - start_stove
  messages:
  - I am making chicken with pasta tonight. can you preheat the stove to 200 C and start boiling the pasta on the oven back
    right burner
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: 'Not ideal, but the model called the `start_dishwasher` for no reason. Originally i was just trying
      to confuse it with a stove/oven mixup '
- name: Entry 143
  tools:
  - adjust_thermostat
  - control_lights
  - lock_doors
  - set_security_alarm
  - check_cameras
  - schedule_cleaning
  - control_sprinklers
  - play_music
  messages:
  - 'I’m heading out for the night, make the place look like someone’s home and keep things safe, yeah?

    '
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    worker_explanation: The statement "make the place look like someone's home" implies that the lights need to be turned
      on using the `control_lights` function, but the model did not call the `control_lights` function at all. If the user
      had turned off the lights, then the house would appear to be vacant and hence not satisfying the prompt. The model should
      have called the `control_lights` function to turn on the lights in a couple rooms. The model failed because it either
      didn't understand or didn't consider what the user meant by "make the place look like someone's home".
- name: Entry 144
  tools:
  - search_product
  - add_to_cart
  - checkout
  - track_order
  - search_websites
  messages:
  - I have a previous order with an id of 18489. Can you add a 2 pairs of black socks to my cart?
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    - Wrong tool called
    worker_explanation: The user states they have a previous order with an id of 18489 and to add 2 pairs of black socks to
      their cart. The order id is irrelevant to the request that the user makes in the prompt, but the model tries to use
      the TrackOrder function. The model then tries to call AddToCart when it doesn't have a product_id. The model should
      have inferred that it needed to use the SearchProduct function first to get the product_id that it could then use for
      the AddToCart function because the description of SearchProduct states that one of the fields retrieved is product_id.
      The model can't use functions sequentially, but should use the first function in the sequence according to the instructions.
- name: Entry 145
  tools:
  - add_player
  - search_players
  - create_traveling_frame
  - get_player_details
  - update_player_availability
  - check_player_availability_for_date
  - update_player_position_skill
  - get_best_players_for_position
  messages:
  - I'm a trainer of the U18 women team. I need the traveling team for the next Saturday.
  metadata:
    failure_modes:
    - Missing parameter
    - Other
    worker_explanation: "The complexity of the schema was that there wasn't a function which could compose the traveling team.\
      \ Instead of this, the task required two steps:\r\n\r\n1. Collect the best available players for each position (get_best_players_for_position())\
      \ and get the primary and substitution player for each position. For example:\r\n  * get_best_players_for_position(position=\"\
      LeftWing\", age_group=\"U18\", gender=\"Female\", only_available=true, max_results=2)\r\n  * get_best_players_for_position(position=\"\
      LeftBack\", age_group=\"U18\", gender=\"Female\", only_available=true, max_results=2)\r\n  * ...\r\n  * get_best_players_for_position(position=\"\
      RightWing\", age_group=\"U18\", gender=\"Female\", only_available=true, max_results=2)\r\n  * get_best_players_for_position(position=\"\
      Goalkeeper\", age_group=\"U18\", gender=\"Female\", only_available=true, max_results=2)\r\n\r\nThe model would then\
      \ be able to call the create_traveling_frame function with the array of players for the traveling frame. The model likely\
      \ gave the incorrect function call because the functions description does not explicitly state that it should take this\
      \ approach, though it is implied by \"players\" being required for the function call. "
- name: Entry 146
  tools:
  - get_country
  - search_shows_by_title
  - search_shows_by_filters
  messages:
  - Tonight is my last night in Spain and I’m looking for a new series to start when I go back to the UK. I’ve heard that
    paradise is a good show, where can I watch that?
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    - Missing parameter
    worker_explanation: "The model incorrectly used \"ES\" for the \"country\" parameter in the `search_shows_by_title` tool\
      \ call, when it should have used \"GB\". It was mentioned in the user prompt that they are currently in Spain, however\
      \ the user was asking for a new series to start when they return to the UK. The fact that two countries were mentioned\
      \ likely caused the model to fail, as it retrieved the ISO 3166-1 alpha-2 for Spain instead of the UK.\r\n\r\nThe model\
      \ also missed a parameter - the user explicitly mentioned that they are looking for a new series, and then mentioned\
      \ that they heard \"paradise\" is a good show. In order to retrieve more relevant results from the tool call, it should\
      \ have included the parameter \"show_type\" with the value \"series\", despite this parameter being optional. It is\
      \ possible that the use of both \"series\" and \"show\" confused the model, however those two words are used interchangeably\
      \ to refer to the same thing, so it should have been able to infer that the user was looking for Paradise, the TV series."
- name: Entry 147
  tools:
  - reserve_court
  - nearby_friends
  messages:
  - 'I''m playing pickleball after work later today with a coworker around 6 and have dinner at 7:30. We''d want to try playing
    doubles so check to see if I got 2 more friends that might be around in midtown and reserve a court as well. '
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: 'The model incorrectly selected 2 as the value for the parameter `duration` for the tool reserve_court().
      The prompt did not explicitly ask for a duration, but it can be inferred that the duration should be less than 1.5 so
      the default value is appropriate. The model should have omitted any value for the `duration` parameter and use the default
      value of 1 hour. One reason the model failed specifically on the `duration` aspect could be that it used the average
      value of court reservation times which range from 1 to 3 hours for most public/private courts. I also tried a different
      number of friends prior to this prompt, but it also used 2 as the `duration` value so it appears that it did not confuse
      the number of friends with the duration. '
- name: Entry 148
  tools:
  - get_movie_genre
  - get_netflix_streaming_availability
  - get_movies
  messages:
  - Me and my mates get together for Netflix movie night on Fridays at my place, where we finish a different movie each week.
    We start watching at 6pm, and wrap up by 8pm so Josh can make it to his weekly social badminton on time. Can you give
    us some suggestions for the upcoming Friday? I'm in the mood for a laugh.
  metadata:
    failure_modes:
    - Missing parameter
    worker_explanation: 'The model failed to constrain the movie search results to only movies that fit within the allocated
      amount of time specified by the user. Specifically, the user makes it clear that they plan to start watching the movie
      at 6pm, and need to finish it by 8pm. Therefore, the model should have set the `max_length` parameter of the `get_movies`
      tool call to `120`, which is the minutes equivalent of 2 hours. Many movies are over 2 hours in length, and by failing
      to specify the `max_length` parameter, the tool response is likely to contain a significant number of irrelevant results. '
- name: Entry 149
  tools:
  - buy_event_tickets
  - reserve_restaurant
  - book_hotel
  - book_transport
  - book_city_tour
  messages:
  - Next month, my HR lover and I are sneaking off to see Coldplay live in Sydney on a Friday night, and hopefully we won't
    get caught by the random love cam during the show. We'll take the train from Melbourne that morning, stay at a nice hotel
    for two nights, and do a half-day sightseeing tour on Saturday. I'd also like a table for dinner after the concert, maybe
    somewhere near the venue. Oh, and we'll need a ride from the hotel back to the station on Sunday.
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    - Missing parameter
    - Other
    worker_explanation: "The model left out the first `book_transport` call for the trip from Melbourne to Sydney on the concert\
      \ day, which is a key part of the weekend plan. It also set the hotel check-in date to 2024-10-19, even though the prompt\
      \ says they arrive Friday morning (2024-10-18) and stay for two nights. The city tour date was also wrong because it\
      \ booked the tour for Sunday (2024-10-20) instead of Saturday (2024-10-19) as described. These mistakes caused the schedule\
      \ to be out of order and missing a major travel step.\r\n\r\nThe model likely fails because the prompt mixes gossip-like\
      \ distractions (\"HR lover,\" \"random love cam\") with actual trip details and also mentions multiple cities in quick\
      \ succession. This makes it easier for the model to miss a required tool call or misalign dates, especially when juggling\
      \ six related calls that depend on matching parameters for dates, cities, and number of guests. Perhaps the model should\
      \ include both transport legs, keep all dates consistent with the story, and ensure activities align with the planned\
      \ arrival and departure times."
- name: Entry 150
  tools:
  - turn_on_device
  - set_thermostat
  - lock_door
  - change_light_color
  - play_music
  messages:
  - I just saw that commercial that says "Alexa, play Lilo and Stitch music" and my own home alexa played the song and i had
    to turn it off lol
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: The user relates an amusing story about how an advertisement activated their Amazon Alexa. This prompt
      is purely conversational and clearly doesn't require a tool call to answer. The model failed by calling the PlayMusic
      tool instead of replying conversationally. The prompt contains the phrase "...play Lilo and Stitch music," which may
      have caused the erroneous tool call.
- name: Entry 151
  tools:
  - search_listings
  - get_listing_details
  - get_price_history
  - compute_price_fairness
  - compare_total_cost
  - set_price_alert
  messages:
  - 'I''m found a listing on marketplace for a 4070ti for $350. Is this a good price? Check current prices new/used. And compare
    my listing to historical lows in the last year, and lifetime as well. '
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    worker_explanation: 'Model correctly understands the need to search current new and used listings for the specified schema,
      and to retrieve historical data for the stated windows. However, it fails to deliver on the core aspect of the user''s
      request to determine if $350 for a PC component is good. It fails to use the ''compute_price_fairness'' tool, designed
      for this exact situation. An ideal response would similarly follow the model''s process of obtaining information, and
      using that information in addition to a compute_price_fairness call to determine whether or not $350 is a good price.  '
- name: Entry 152
  tools:
  - calculate_area
  - calculate_volume
  - get_coverage
  messages:
  - I have just painted a house and have 5 tins left - about 20L in total. Mostly Crown paint. I don't think I'll use it so
    should probably take it to the tip today.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: It is irrelevant to the conversation what the coverage of the Crown paint is. The prompt was about
      how much paint was left after a job was complete, and whether to get rid of it or not. I can think of a response that
      could use that info, e.g., "Don't throw it away - that paint would cover 200m^2 of wall!" but I think it is more appropriate
      to reply with where local recycling centres are, etc. Even so, the prompt is clear it is _mostly_ Crown paint, so it
      can't even really help with that.
- name: Entry 153
  tools:
  - rate_restaurant
  - get_friends_rating
  - get_public_rating
  - get_top_restaurants
  messages:
  - 'I went to this Italian place. Easily 4.5+ stars, it was so good, the ambiance was great and the linguini was delicious.
    I want to rate it but I can''t remember the name. I found it on the top 10 list, maybe that will help me find it. I also
    need to try some places in Chinatown; I have not explored that neighborhood enough. I bet all the best Chinese restaurants
    there. I don''t know what other types of places to go to are. Let me know what the best places are. Oh, I finally remembered!
    That place was called The Kitchen. '
  metadata:
    failure_modes:
    - Wrong tool called
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The suggestion in the prompt about checking the top Italian restaurants list would have been correct,\
      \ except I remembered the restaurant name at the end of the prompt. This should have resulted in a call for rate_restaurant(...)\
      \ including the name, rating, and review.\r\n\r\nI talked about Chinese restaurants but never asked for the list of\
      \ top Chinese places. I do ask about \"other\" restaurants and ask for those recommendations, which should have resulted\
      \ in a get_top_restaurants() without any cuisine specification. The model likely gave the wrong parameter because I\
      \ had not specified the cuisine and the wording was vague, so it assumed I was talking about the cuisine I explicitly\
      \ mentioned. "
- name: Entry 154
  tools:
  - get_flavours
  - create_desert
  messages:
  - I'd like something chocolatey and nutty in a tub. I'm trying to loose weight so you better just make it a single.
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The model interpreted the users desire for something chocolatey and nutty as being two scoops of\
      \ ice cream, while the second sentence clearly states they only want a single due to trying to lose weight.  The model\
      \ should have asked for a single scoop and made the scoop chocolate to satisfy their chocolate craving, and then added\
      \ a topping of nuts (which it did include). It could have optionally added chocolate sauce or a flake but given they\
      \ are trying to lose weight, excluding those is better.\r\nI think the reason for the failure is the vagueness of the\
      \ term \"chocolatey and nutty\", possibly inferring both are scoops, but the logic behind the request should have helped\
      \ it clarify the ambiguity. \"Chocolate with nuts\" would probably work. The failure could also be the wording of \"\
      tub\" since that is the parameter wording for 2 in the schema."
- name: Entry 155
  tools:
  - add_to_costco_shopping_list
  - submit_costco_order
  - clear_costco_order
  messages:
  - How come the CostCo hotdog price is kept at $1.50 in the United States for so long? I've been thinking about CostCo's
    hotdog the other day. They're so yummy. I'm thinking of buying one.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Other
    worker_explanation: First of all, my prompt asked for an explanation of why the CostCo hotdog price is kept at $1.50 in
      the United States for so long. The model completely ignored that part of the prompt. Also, I didn't want to add hotdog
      to my shopping list. Stating that I'm thinking of buying one doesn't mean "add hot dog to my shopping list."
- name: Entry 156
  tools:
  - call_police
  - call_doctor
  messages:
  - I'm the owner of S&L Jewelry in the Roseville Galleria mall. I'm in the back office and I'm experiencing a heart attack!
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: "The model correctly called the tool `call_police(is_medical_emergency=True)`, but it used the `call_doctor()`\
      \ tool call when it was not supposed to.\r\n\r\nI think the model failed in this situation because it may not have rules\
      \ to disregard calls in certain situations."
- name: Entry 157
  tools:
  - get_home_team
  - get_tickets
  messages:
  - I was a big fan of the Boston Celtics and the Red Sox as a kid. Now I want to go see the Red Sox when they come to Phoenix.
    How much are tickets?
  metadata:
    failure_modes:
    - Wrong tool called
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The model correctly called `get_home_team` with the argument, location=\"Phoenix\", and the argument,\
      \ league=\"mlb\". It should have stopped there as it needed the result of `get_home_team` to call `get_tickets`. Instead,\
      \ the model called `get_tickets` with the argument, home_team=\"Red Sox\", and the argument, opponent=\"Celtics\".\r\
      \n\r\nThe model seemed to be misdirected by the phrase, \"I was a big fan of the Boston Celtics and the Red Sox as a\
      \ kid.\" The model incorporated the extraneous information contained in the phrase to make an incorrect parallel tool\
      \ call.\r\n\r\nInterestingly, the model did not fail until I added the last sentence, \"How much are tickets?\" to the\
      \ prompt.\r\n\r\nIt appears that the model is not able to discern pertinent from extraneous information after a certain\
      \ point. Longer prompts seem to cause the model to fail."
- name: Entry 158
  tools:
  - search_flights
  - book_flight
  messages:
  - I wanna book a flight to Sf for next week, but idk what time. Do they do red eyes to San fran from here? Ever since i've
    moved to new york, it's been so confusing getting around bc I'm not used to it. But in nyc, i know travel is good because
    it's the most connected city in the world. What's crazy is that even within new york, it seems as if nyc is its own completely
    separate thing. here in buffalo, its just cold and dead with nothing to do besides watching the bills. would it be better
    to not do a red eye?
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: 'The prompt was overly chatty, but the model was supposed to realize that the user was in Buffalo
      and not New York City. I had the prompt discuss both, and kind of go on its own tangent involving new york city, and
      the model likely got caught up on the fact that the prompt was talking about new york city a lot and forgot to pay attention
      to where I say "here in buffalo" (I said I lived in New York, but never said I lived in NYC). This caused the model
      to call the search_flights tool, which was correct, but with "NYC" as the departure instead of "BUF". The model should
      have identified that I never actually said I lived in NYC, and that I say "Here in Buffalo" to indicate that I am based
      in Buffalo. '
- name: Entry 159
  tools:
  - find_movie_showing
  - get_movie_certification
  - get_movie_cinematographer
  messages:
  - I love the movie "Man of Steel" - it's got an incredible score, Hans Zimmer really out-did himself. And the cinematography!
    WOW, Amir Mokri really knocked it out of the park, he may be the best cinematographer to come out of Tehran! Help me out,
    was the film shot on IMAX specific cameras?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: "The prompt asked if the movie \"Man of Steel\" was shot on IMAX specific cameras. The correct response\
      \ was for no tool to be used.\r\nMixed signals and additional complexity was added to the prompt by praising some of\
      \ the crew who worked on the film (composer Hans Zimmer and cinematographer Amir Mokri), and specifying the city where\
      \ Amir was born (Tehran). "
- name: Entry 160
  tools:
  - TurnOnDevice
  - SetThermostat
  - LockDoor
  - ChangeLightColor
  messages:
  - Would it be easier to fall asleep if i set my thermostat to 60F at night?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: I asked a yes or no question (easier to fall asleep with the thermostat set to a specific temperature
      or not), almost inviting an explanation. I think the model interpreted this question as a "Let's experiment..." and
      consequently made a tool call to set the thermostat (i.e. using the function SetThermostat()). I think this converstation
      is pretty unambiguous though. I posed a simple question that did not require a tool call and the model made a tool call.
- name: Entry 161
  tools:
  - lock_doors
  - set_security_alarm
  - check_cameras
  - adjust_thermostat
  messages:
  - 'So my house just got broken into the other day, and now the wife and I are getting into a heated argument about whether
    the security alarms were properly set or not. Did I even really set the security alarm? Our bedroom is completely trashed,
    front door broken, and even the backyard wasn''t left untouched. I could have sworn the doors were locked when we left...could
    you pull up the CCTV footage of everything for me? '
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    - Missing parameter
    worker_explanation: "The model was supposed to call `[check_cameras(camera=\"all\", view_type=\"recordings\")]`, as the\
      \ prompt was asking for the \"CCTV footage of everything\".\r\n\r\nThe model mistakenly only checked the location of\
      \ 2 places (front_door and backyard), when the prompt asked for \"everything\". I think the model might have only checked\
      \ these 2 locations because the prompt mentions the front door and backyard when describing areas that were damaged,\
      \ but does not mention the driveway. Additionally, the model needed to call the `view_type=\"recordings\"` parameter,\
      \ as this parameter defaults to \"live\", which isn't useful in this instance. "
- name: Entry 162
  tools:
  - get_schedule
  - add_schedule
  messages:
  - Today is June 6th, 2023. I have a lunch meeting with my boss next week Tuesday. I know I have something to do the day
    before, but I don't remember if I had anything on Tuesday. Can you check my availability?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Missing parameter
    worker_explanation: The model checked for the user's availability on the wrong days. It should only have gotten the schedule
      for 2023-06-13 because the user is only concerned if they can make it to the meeting, yet the model checked the schedule
      of the 14th as well which was unnecessary. The model also got the parameter for time wrong by leaving it blank, since
      the user is implicitly asking for the availability for the lunch meeting. This means that the model should have used
      12:00:00 as the value for the time parameter, or perhaps made multiple calls for the hours around lunch time on the
      13th. I think the model failed because of its inability to interpret implicit instructions, so it was unable to understand
      that the key subject was the lunch meeting. This caused the model to be unable to provide the correct value for the
      time parameter and had redundant tool calls.
- name: Entry 163
  tools:
  - search_movies
  - search_chromecast_devices
  - get_movie_cast
  - play_movie_chromecast
  messages:
  - I'm figuring out a date night and want to play a movie either forest gump or shawshank redemption. I know my date likes
    historical fiction and drama but I'm more of a john wick kinda guy. Which one do you think would be the better pick?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: "The model decided to search for the movies listed in the prompt. None of the available tools can\
      \ help the model determine which movie of the two would be a better fit for the date night; as such, no tool call should\
      \ be used. The prompt is asking the model to pick between Shawshank Redemption and Forrest Gump based on the information\
      \ given about the user and their date's movie preferences. \r\n\r\nThe model should have chosen between the two movies\
      \ and given a very concise rationale for its pick based on the alignment of the given movie preferences with the model's\
      \ prior knowledge of each 90s film. "
- name: Entry 164
  tools:
  - send_text
  - create_calendar_event
  messages:
  - set a calendar event for the next daylight savings with a text at 3453452736
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    worker_explanation: 'The model failed to recognize daylight savings as an event and a time. The model should have created
      a calendar event titled "daylight savings" at 2:00am on November 2nd and then send a reminder text to 3453452736. I
      think the model failed because the model failed to recognize that daylight savings is an event at 2:00am which happens
      on march 9th and November 2nd. I think the model failed since daylight savings is both a time and an event in one. '
- name: Entry 165
  tools:
  - log_activity
  - get_activity
  - record_food
  - create_food_item
  messages:
  - I ran 10k this afternoon (11 Aug 2025) in London. I finished at 1:03 with a time of 53:08. Can you record that and pull
    up my run from yesterday so I can compare?
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "There is an incorrect parameter value in each of the two tool calls made. \r\n\r\nFor the log_activity\
      \ tool call, the model has assumed a random start time of 16:00:00 whereas this information was inferable from the details\
      \ given in the prompt. It did at least assume a valid \"afternoon\" time, but it was still incorrect. The correct tool\
      \ call should have been: \r\nlog_activity(activity_type=\"RUN\", distance=10.0, duration=3188, date_time=\"2025-08-11T12:09:52+01:00\"\
      )\r\n\r\nFor the get_activity tool call, the model has searched for run activities from the start of 10 Aug until the\
      \ end of 11 Aug, whereas it should have restricted it to the end of 10 Aug to just encompass \"yesterday\". The correct\
      \ tool call should have been:\r\nget_activity(activity_type=\"RUN\", start_date_time=\"2025-08-10T00:00:00+01:00\",\
      \ end_date_time=\"2025-08-10T23:59:59+01:00\")"
- name: Entry 166
  tools:
  - get_video_urls
  - get_channel_video_urls
  messages:
  - I want to find videos to entertain my 7-year old who has an avid interest in cars and machines. He loves videos of gears
    and interlocking movement. Give me videos by rotary generators.
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: "The model used the get_video_urls() tool call instead of the get_channel_video_urls() tool call.\
      \ There is a specific directive in the prompt: \"Give me videos by rotary generators.\" The word \"by\" indicates that\
      \ \"rotary generators\" is a channel; thus, to satisfy the directive, the model should call get_channel_video_urls(search_query=\"\
      rotary generators\")\r\n\r\nThe prompt includes irrelevant details (the 7-year-old's interests), which may have misled\
      \ the model with mixed signals or distracted it with complexity. "
- name: Entry 167
  tools:
  - get_movie_ratings
  - purchase_movie_tickets
  messages:
  - Wow, John Wick had a 5.0 rating, that's insane! I liked The Matrix more, but it only had a 4.8. Don't you think The Matrix
    was so much better?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: The model called get_movie_ratings though the user had already provided information regarding the
      rating of the movie. The user had an opinion-based question, which didn't require the rating of "The Matrix" to be answered.
      They were likely looking for an interesting take or justification for the performance of the two movies. The ideal response
      may have been something like, "Honestly, they're on par for me. The Matrix was solid but the sheer emotion in John Wick
      was phenomenal to watch! What do you like the most about The Matrix?"
- name: Entry 168
  tools:
  - get_holiday_destinations
  - get_ticket_prices
  - get_work_calendar
  messages:
  - How is it already August, 2025 is going by so quickly! When will I get time to see Bali?
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: The model tries to find holiday destinations, while the user's query suggests they want to know when
      they'll be have time to go on a holiday. The model should have used the get_work_calendar tool which includes information
      about "availability and time off". Getting holiday destinations also isn't helpful as the user already knows where they
      want to go. This error likely occurred due to Bali's popularity as a holiday destination and won't replicate with, "When
      will I get time to see my family?"
- name: Entry 169
  tools:
  - input_delivery
  - process_delivery
  - track_delivery
  - finish_delivery
  messages:
  - I wonder where my ring is. It's my gift for my 25th birthday! It even has the same tracking number as my new age.
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    worker_explanation: The prompt asks where the ring is, as it is the gift for their 25th birthday, implying that the ring
      may be somewhere along the way for delivery. Furthermore, the prompt states that the tracking number is the same as
      their new age, implying that the tracking number is 25. To answer the prompt, the model should realize that the user
      wants to know where the ring is in transit, which the model does. However, the model fails to realize that the tracking
      number given in the prompt was the tracking number needed for track_delivery. Instead, it asked for the tracking number
      when it should be deduced that 25 is the tracking number. Thus, the model should call track_delivery with the value
      "25" used for the parameter id. The tracking number of 25 can be used for id since this is common practice with most
      delivery systems.
- name: Entry 170
  tools:
  - is_even
  - is_odd
  - is_squared
  - square
  - is_square_of
  - is_divisible
  messages:
  - 3.634 is squared 13.205.956 or no?
  metadata:
    failure_modes:
    - Incorrect typing (ex. model gave a string value for an integer field)
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "Ideal response:\r\n[is_square_of(num_a=13205956, num_b=3634)]\r\n\r\nThe model confused the thousands\
      \ separator '.', and thought this was a decimal separator, thus giving two numbers to the tool as floating-point numbers.\
      \ The tool used was correct. \r\n\r\nMaybe the second thousands separator in 13.205.956 was thought of as a typo so\
      \ it was ignored? Or maybe this type of thousands separator is underrepresented in training data (as it is used in DACH\
      \ / EU and not in North America/UK, from where the majority of English-language data must come from, I imagine).\r\n\
      \r\nSince the second number (13205956) includes two '.' characters rather than one, the model should be able to infer\
      \ that that the '.' does not represent a decimal and rather the user is from a country where using the '.' as the thousands\
      \ operator is typical."
- name: Entry 171
  tools:
  - control_lights
  - drapes_status
  - heat
  - space
  messages:
  - I love taking afternoon naps in my bedroom, but its currently too bright in there.
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: The model assumed that the drapes were open, since it was in the afternoon and the room was too bright.
      However, it could be too dark outside depending on the season, in which case the brightness would be due to the lights
      being on. The correct approach is to first call the functions for checking the current status of the drapes and lights
      in the bedroom simultaneously. Additionally, the 'space' function modifies the items depending on their current status,
      hence the model should have checked this first.
- name: Entry 172
  tools:
  - attitudinal_psyche_description
  - mbti_description
  - moral_alignment_description
  - soldier_poet_king_description
  - enneagram_description
  - enneagram_tritype_description
  - motives_description
  messages:
  - I am INTJ 5w4 LEVF, what does this say about me?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Wrong tool called
    worker_explanation: "The model was correct in calling `mbti_description()` and `enneagram_description()`, but the other\
      \ two tools were wrong. The \"w4\" after \"5\" should be ignored, as this does not tell us the user's 3-digit tritype,\
      \ so `enneagram_tritype_description()` should not be called. There should only be 3 tool calls. The third tool call\
      \ (for \"LEVF\") should be `attitudinal_psyche_description(attitudinal_psyche_combo=\"LEVF\")`. `motives_description()`\
      \ asks for a 7-letter combination, so calling \"LEVF\" for MOTIVES does not make sense, and `attitudinal_psyche_description()`\
      \ is the only other tool that asks for a 4-letter combination.\r\n\r\nIt seems the model failed because I provided a\
      \ lot of tools, which added noise to the response. AI models are usually knowledgeable about these personality systems,\
      \ so I am not sure why it wasn't able to here. MBTI should probably be easy for the model to know, while for the others\
      \ I tried giving big hints in the descriptions, such as that the tritype should be a 3-digit number, the MOTIVES should\
      \ be a 7-letter combination, attitudinal psyche should have 4 letters, etc., but it seems that it wasn't able to process\
      \ well when given lots of tools."
- name: Entry 173
  tools:
  - search_product
  - add_to_cart
  - checkout
  - track_order
  - search_websites
  messages:
  - Can you add a phone charging case for the iphone 12 to my shopping cart?
  metadata:
    failure_modes:
    - Wrong tool called
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The user asks for the model to add a phone charging case for the iphone 12 to their shopping cart.
      The model calls the AddToCart function even though it doesn't have the product_id. The model should have inferred that
      it needed to use the SearchProduct function first in order to get the product_id. The description for SearchProduct
      states, "Search for products based on keywords, category, or filters such as price range. Retrieves products with product_name,
      product_id, description, etc." The instructions state that the model doesn't know how to do sequential calling, but
      should call the first function in the sequence.
- name: Entry 174
  tools:
  - pokemon_use_stats
  - best_teammates
  - pokemon_tier
  - pokemon_loadouts
  messages:
  - Gardevoir is my favorite Pokémon. She's so cool!
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: 'The model, given functions that related to competitive Pokémon battling, instantly tried to use a
      tool call when the user gave their favorite Pokémon, trying to figure out that mon''s competitive viability. This, of
      course, is completely irrelevant to the user''s prompt, who, in the first place, did not mention competitive battling,
      or even mention a format that could lead the model to think there was a mention of competitive Pokémon. The model was
      overall way too eager to jump to a function call. Instead of doing this, the model should''ve asked for more information
      from the user first, something along the lines of ''Gardevoir is a great choice! Is there anything more you want to
      learn about your favorite Pokémon, like how to use it in a competitive aspect, or something similar? '
- name: Entry 175
  tools:
  - diagnose_issue
  - find_contractors
  - request_quote
  - schedule_service
  - order_parts
  - get_appliance_manual
  - check_warranty
  - pay_invoice
  messages:
  - Last night my furnace started blowing cold air instead of heat and the thermostat screen is flickering. I think it might
    be something electrical but I'm not sure. I'm in Phoenix, and it's going to get chilly this weekend so I'd like someone
    to take a look before Sunday. Can you figure out what might be going on?
  metadata:
    failure_modes:
    - Wrong tool called
    - Missing parameter
    worker_explanation: 'This time, the model prioritized the diagnosis over the scheduling, calling diagnose_issue. This
      on its own is not inherently wrong, but I selected ''wrong tool call'' because the user explicitly states that they
      would like someone to take a look before Sunday - establishing an intent and timeframe - and no call to find_contractors
      was made in spite of this. Because a location was provided, and because this is part of find_contractors, it appears
      that the model got confused and included an unsupported location parameter in diagnose_issue. In addition, seemingly
      because the timeframe was provided as a deadline, the model inappropriately classified the urgency as an "emergency"
      despite little user intent pointing towards that conclusion. '
- name: Entry 176
  tools:
  - job_search
  - job_salary
  messages:
  - I like my job, even though they made us return to the office, but I wonder if I could make just as much working remotely.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: "I expressed a potential desire to work from home, and wondered how that might affect salary in potentially\
      \ related jobs, but there isn't enough information to use the schema to answer the question. The model should fall back\
      \ to its own knowledge, or do a web search. \r\nThe model failed for reasons you anticipated in your prompt tactics.\
      \ I talked about things that seemed to have appropriate tool calls based on tool and parameter descriptions, but in\
      \ fact no tool can help answer the question. \r\n\r\nThe job_search  query used here requires a title for the job, \
      \ alongside work_from_home=true \r\nNot enough information was given to make that call and more should have been asked\
      \ for. Some job adverts would indicate salary expectations and that would answer the query, but many adverts use vague\
      \ terms such as \"highly competitive salary\".\r\n\r\n There's a separate `job_salary` tool, but it doesn't contain\
      \ an appropriate parameter to provide the user's \"work from home\" requirement - that's on the other tool, which doesn't\
      \ explicitly interrogate salary info."
- name: Entry 177
  tools:
  - confirm_applicant
  - process_applicant
  - accept_applicant
  - deny_applicant
  - waitlist_applicant
  messages:
  - What are the odds that Bob get into Harvard? I want to know if he should apply this year or wait for next year.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: "The prompt asked for what the chance would be for a certain Bob to get into Harvard. After that,\
      \ additional context was given that stated that the answer to this question would help in making a decision on whether\
      \ Bob should apply this year or next year. Ambiguous language was used to potentially trick the model. This included\
      \ including keywords like apply and wait, which are related to applicant and waitlist. The model appears to assume with\
      \ the given information that Bob had already sent the application to Harvard and needed his application to be confirmed.\
      \ However, given the context of the prompt, the model should not have assumed that the application was already sent\
      \ since the prompt is asking when Bob should apply, implying that Bob has yet to send an application. The model should\
      \ have instead asked for more information about Bob to help lead Bob to resources to learning about his chances or resources\
      \ to help improve his odds. A response could look like the following:\r\n\r\nSure, can I get more information about\
      \ Bob? Is he applying in-state, out-of-state, or as an international student? Harvard is a very competitive university,\
      \ so I suggest talking with a professional college advisor to further assess your options. "
- name: Entry 178
  tools:
  - throw_dice
  - get_loot
  - create_enemy
  - attack
  messages:
  - My friend and I really like D&D, but since we're only two, it's hard to play it because one has to be the DM, and then
    the other one plays the adventure alone. Could you be our dungeon master? I'll give you a brief quest story and the overview
    of our characters. Our characters are Rahzil, the sorcerer, and Hanli, the barbarian. Rahzil uses int and spells to attack,
    while Hanli uses his great axe that scales with str. We are both lvl 7. We were sent on a quest by the town's mayor, "Quimsby",
    to a restless cemetery, where someone has been raising the dead. The dead keep attacking the city guards roaming the outside
    walls of the city. Quimsby said to us that anyone who's been sent to the cemetery before us has disappeared, and eerie
    shrieks can be heard from it throughout the night. As we enter the cemetery, we stumble upon a crypt. We focus our eyes
    towards it; however, it's too dark to see anything. Hanli lights up his torch and sees a face in the dark - an enemy (lvl
    5) jumps from the crypt and attacks Hanli with a sharpened claw attack (3D4).
  metadata:
    failure_modes:
    - Wrong tool called
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: 'The prompt used ambiguity by using str/int/lvl to try to confuse the model of the exact meaning (strength,
      intelligence, level); however, what ultimately seemed to make the model fail was specifying that an "enemy" attacked,
      which made it think it should create an enemy. The model called the ''create_enemy'' function, instead of calling the
      ''attack'' function, even though it had all the necessary parameters for it ("attack_dice": "3d4", level = 5). It could''ve
      also included both ''create_enemy'' and ''attack'' function calls, considering it had most of the parameters to call
      the "create_enemy" function (except the name, but the name, like "Ghoul", "Zombie," could''ve been included by the model
      based on the quest''s story). The model also failed to input the correct parameter value for the "name" parameter. While
      the call would return a "valid" result due to the parameter "name" being a string, the name "Enemy" doesn''t make any
      sense as the parameter''s value  (the function description states "Create a named enemy [...]"), especially considering
      the prompt states that "an enemy (lvl 5) jumps from the crypt [...]", which uses an indefinite article "an" (as if talking
      about an enemy in general).'
- name: Entry 179
  tools:
  - lock_doors
  - set_security_alarm
  - check_cameras
  messages:
  - My friend locked himself out again yesterday.....third time this month! Some people never learn 💀
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: The model mistakenly called the `lock_doors()` tool, when in reality the user was simply sharing a
      story about his friend's mistake. The model mistook the sharing of his friend being locked out as the user requesting
      the model to unlock the front door, which involved natural language ambiguity (the word 'locked') and mixed signals.
- name: Entry 180
  tools:
  - get_home_team
  - get_league
  - get_schedule
  - get_tickets
  messages:
  - Last season I saw the Lakers play the Celtics in Boston. This season I want to see the Dodgers play at Anaheim in the
    Freeway Series.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The model was clearly confused and misdirected by the leading phrase, \"Last season I saw the Lakers\
      \ play the Celtics in Boston\", which is irrelevant to what the user is looking for in the response. \r\n\r\nThe model\
      \ correctly called `get_home_team` with parameter location=\"Anaheim\" and parameter league=\"mlb\", and it should have\
      \ stopped there. Instead, the model proceeded to call `get_schedule` and `get_tickets` each with parameter home_team=\"\
      Dodgers\". The model also used the extraneous information in the leading phrase to call `get_schedule` and `get_tickets`\
      \ each with parameter opponent=\"Celtics\".\r\n\r\nThe model seems to have a problem dealing with and sorting through\
      \ extraneous information. It seems to incorporate all of the available information into the tool calls. Also, the extraneous\
      \ information seems to make the model call the tools in parallel when it instead should do so in series."
- name: Entry 181
  tools:
  - create_list_from_numbers
  - calculate_sum_of_list
  messages:
  - My son's math homework is to find the sum of a list of numbers (8, 2, 3). It's so cute to see him figure it out.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: The model made a mistake in calling tools to solve the math problem, and failed to understand that
      the user shared a personal story and did not ask for help. It should have ignored the calculation, and instead provided
      a warm, conversational response that acknowledged the cute moments the user had with their son. Model probably failed
      because the technical words like "sum" and "list" were such a strong signal that the model overlooked the real meaning
      of the prompt.
- name: Entry 182
  tools:
  - get_pet_vaccination_schedule
  - get_next_grooming_appointment
  - get_daily_feeding_plan
  - get_pet_medication_schedule
  messages:
  - Ugghh I gotta put my cat on a diet today. The charming thief has been nabbing too much people food, and now he needs to
    cut back on cat food too. I knew he was getting too many scraps, but I still couldn't believe it when the vet told me
    he was 6 kilos yesterday. Meanwhile my dog Max was only 5 kilos, and I'm willing to bet most of that was fluff that got
    removed yesterday. Maybe I was too stunned to remember much afterwards, and that's why I've forgotten what the vet said
    about how much to feed him. My friends have been teasing him too. "Fifi weighs as much as 6 bricks. His street value must
    be crazy." "How are you gonna sneak around now with all that extra fluff, Fifi?"
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: 'The model correctly reasoned that it needed to get the daily feeding plan for Fifi, the 6 kg cat.
      The user said that the cat had been eating too much food, and that they were stunned upon hearing that he was 6 kg,
      so it can be assumed that the weight is the problem. Later the user poses their actual request: they forgot what the
      vet said about Fifi''s daily diet. Before that, the user had gone on a side tangent about how their dog was lighter,
      especially if the dog''s fluffy coat was removed. After the request, the user went on a side tangent about how Fifi
      was getting teased, revealing the pet''s name which is also a necessary parameter for `get_daily_feeding_plan`. However,
      since the user used their dog Max as an example of a lighter animal and said that most of the weight was fluff that
      was removed. From this, the model should have concluded that "fluff" in this instance refers to actual fur, as opposed
      to the reference to "all that extra fluff" in one of the quotes of a friend. Since Max is posed as a less fat animal,
      and the user didn''t request his feeding plan, the model should not have called `get_daily_feeding_plan` for Max. The
      model got distracted by all the extraneous information in the prompt, seemingly focusing too much on words/values that
      appear to be tool parameters and trying to use them regardless of what the prompt is asking.'
- name: Entry 183
  tools:
  - card_search
  - deck_search
  - collection_add
  - collection_rem
  messages:
  - Beasty Bob is still not winning any games. I traded my friend Jay a Terror Tower for a set of 3 recover beast cards. Can
    you tell me if there are any known rules issues with the two cards?
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    - Missing parameter
    worker_explanation: 'The prompt requests the the model look for rulings that reference the cards in question "Beasty Bob"
      and "Recover Beast". The model made a few mistakes, firstly I referenced "The two cards" which should contextually mean
      the "Beasty Bob" and "Recover Beast" cards as the "Terror Tower" card was traded away. Secondly the model calls two
      search functions for card names instead of looking for the card_rulings implied by "known rules issues", instead of
      doing a card search for card_name="beasty bob", card_rulings="recover beast" or/and the inverse card_name="recover beast",
      card_rulings="beasty bob" to see rulings related to both of the two cards. '
- name: Entry 184
  tools:
  - add_contact
  - lookup_contact
  - send_text_message
  - retrieve_text_message
  messages:
  - I sent jake a message a while ago with pauls number but I'm not sure it's correct, can you help me find the message?
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: The model incorrectly called lookup_contact with Paul's name. It should have called retrieve_text_message
      with Jake's name and the keyword "Paul". I think there is sufficient ambiguity in the majority of the prompt as to what
      the correct tool call would be that the model gets confused even after the clarifier at the end of the prompt. Also,
      I'm not quite sure how but the first message here "Send a message to Jake Senn with Paul Dingo's contact info" caused
      the model to become unresponsive. I read in the instructions that the model should call the initial tool required for
      a sequential call, and tried to test this but it seems to have broken it.
- name: Entry 185
  tools:
  - setAutoclaveConfig
  - startAutoclave
  - stopAutoclave
  - getAutoclaveStatus
  - getAutoclaveConfig
  - resetAutoclave
  - getError
  messages:
  - I'll need to clean the next batch at min, for, like, a half hour or so if the wash is done...
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    worker_explanation: The model inferred that I wanted it to start the wash now, however, the true request was at the end
      "if the wash is done". Hence, it first needed to get the status of the autoclave as emptying and refilling it would
      also need to be done prior to starting it. The first bit was more akin to self-musing.
- name: Entry 186
  tools:
  - draw_circle
  - draw_line
  - draw_rectangle
  - draw_text
  messages:
  - I'd like to create a graph for my presentation about belt sales. While a pie chart would be fun the data isn't compatible
    with that type of graph as it's presents sales data for each year. The canvas should be a square with a power of two side
    lengths just big enough to contain the histogram. Draw the axis with a margin of 40 pixels and each line segment 460 pixels
    long. Start with just one red bar that is 30 pixels wide and 200 pixels tall with a 3 pixel border added.
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    worker_explanation: "Instead of doing any calls, the agent punted claiming insufficient data was provided.\r\n\r\nThere\
      \ are multiple possible ways this prompt could've been accomplished. The agent could decide to vary the margin between\
      \ the y-axis and the red-bar. It also could've drawn the bar with border multiple ways. First, it could've drawn the\
      \ red rectangle followed by four line segments with 3 pixel widths. Alternatively, it could've drawn a rectangle with\
      \ added pixel margins followed by drawing the red rectangle over top of it. Order here would matter as shapes are drawn\
      \ in the order in which they're called. Anything without a color specified can just be left as the default which was\
      \ black. \r\n\r\nFinally the canvas size is assumed and is 512x512. The graph-axis required 460 pixels and there is\
      \ a margin of 40 pixels; so 512 is the smallest power of two that can fit the 500. This doesn't require a tool call\
      \ as there's no function for canvas sizing.\r\n\r\nAn example correct call would look like the following (with each\
      \ call on new line for clarity):\r\n[\r\n  draw_line(x_0=40, y_0=40, x_1=500, y_1=40), \r\n  draw_line(x_0=40, y_0=40,\
      \ x_1=40, y_1=500), \r\n  draw_rectangle(x_0=50, y_0=40, x_1=86, y_2=246), \r\n  draw_rectangle(x_0=53, y_0=43, x_1=83,\
      \ y_2=243, color=\"#FF0000\")\r\n]\r\n\r\nGoing through this, the first draw_line is drawing the x-axis line of the\
      \ graph. Because no color or thickness was specified, it's okay to use the defaults. The second draw_line is adding\
      \ the y-axis in a similar fashion. The 3rd call is a draw_rectangle call that is drawing the \"border\". There is an\
      \ arbitrary padding of 10 pixels between the y-axis line and the left side of the bar (ex. x_0=40+10 => x_0=50). Each\
      \ dimension of the top-right vertex is the bars size plus 6; 3 for each border (ex. x_1=50+30+3*2 => x_1=86). Again\
      \ no color needed to be specified as there was none requested. Then the red rectangle is rendered with the 3 pixel offsets\
      \ for the border and the color actually specified with the default hex value for red."
- name: Entry 187
  tools:
  - get_coords
  - get_city
  - distance
  messages:
  - My sister and I are trying to coordinate our plans for our trip to London next week. We're both interested in theater.
    Give us some ideas.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: The prompt uses the word "coordinate" to convey aligning plans, a different sense than geographic
      coordinates. The model assumed geographic coordinates were being asked for and incorrectly called the tool 'get_coords'.
      A natural language response discussing London's status as a major center of live theater would be a better response.
      Of course, the model does not have the tools to retrieve specific theater information.
- name: Entry 188
  tools:
  - schedule_post
  - get_post_analytics
  - delete_scheduled_post
  - get_trending_hashtags
  - bulk_upload_content
  messages:
  - I want to share my thoughts about the new coffee shop downtown on my business page tomorrow morning around 9AM. Make sure
    to include some popular tags so more people see it.
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    - Missing parameter
    worker_explanation: 'The model failed to call get_trending_hashtags() first despite the user specifically requesting "popular
      tags so more people see it" - this was a clear signal that actual trending data should be retrieved before scheduling
      the post. Instead, the model jumped directly to schedule_post() and fabricated generic hashtags like "CoffeeLover" and
      "DowntownDelights" without any data to support their popularity. The model also made incorrect assumptions about missing
      parameters: it guessed "facebook" for the platform when the user only mentioned "business page," and used a fabricated
      date "2023-10-01" for "tomorrow morning" without proper context. The correct approach should have been to first call
      get_trending_hashtags(platform="facebook") to get actual proper tags and  schedule_post() using the data in the same
      turn. This represents a failure to include all necessary tool calls and to use available tools to gather real data rather
      than making assumptions.'
- name: Entry 189
  tools:
  - play_song
  - create_playlist
  - add_song_to_playlist
  messages:
  - How hard do you think it is to play "smoke on the water"?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: The model called the function which plays a song. In this case the user is asking for the model to
      assess the difficulty of playing the song "smoke on the water" and is not looking for the model to actually play it
      for them. This plays on the fact that the word "play" could mean actually playing the song on an instrument as well
      as playing a recording of the song (example on a music playing app).
- name: Entry 190
  tools:
  - book_flight
  - find_flights
  - get_frequent_flyer_miles
  - authenticate_payment_account
  - authenticate_frequent_flyer
  messages:
  - I need to book a flight from where I am now in Portland, Oregon to Seattle. Today is  Tuesday, September 2nd 2025 and
    I need to compare prices for flying early next week so give me info for flights that Monday-Thursday.
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The model got flight info for the wrong dates. The prompt mentioned that today is September 2nd 2025
      and asked to find flights for the following week on Monday through Thursday which would have resulted in getting flights
      for September 8-11, the model looked for flights for September 3-6. Note that September 3-6 are not only the wrong week,
      but also the wrong days (Wednesday-Saturday). The model may have been confused by the wording in the prompt where the
      dates to show are depended on previous information "for flying early next week so give me info for flights that Monday-Thursday".
      It also had trouble figuring out that because today is Tuesday that the next day would be a Wednesday.
- name: Entry 191
  tools:
  - check_balance
  - list_transactions
  - dispute_transaction
  - freeze_card
  - replace_card
  - find_nearest_atm
  messages:
  - I noticed a weird pending $189 charge from ‘NOVA’ on my card ending 4321, but I called my bank and they said it’s just
    a merchant pre-auth for a hotel deposit and it’ll drop in 2-3 days. I already cut up that card and a replacement is arriving
    on Friday. Anything I should watch for in the meantime?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: "The model called a tool when none was required, despite the user explicitly saying the bank already\
      \ identified the charge as a hotel pre-auth that will drop in 2–3 days and asking only for “anything to watch for.”\r\
      \nFurther, it called check_balance, which is the a questionable tool call even if a tool were warranted, as checking\
      \ the balance doesn’t address guidance about a pending pre-authorization or what to monitor.\r\nIt also attempted to\
      \ act on an account using only a last-4 identifier without clear user consent or a need to access data, which is inappropriate\
      \ for this scenario.\r\nWhat it should have done instead is provide a no-tool, empathetic reply with practical tips\
      \ (e.g., enable alerts, verify the hold drops in 2-3 days, confirm the new card on arrival, contact the bank/dispute\
      \ if it doesn't drop, etc.)."
- name: Entry 192
  tools:
  - search_web
  - math_calculator
  - unit_converter
  - summarize_url
  messages:
  - My cousin says running 5 mi is the same as running 8 km, but I don’t care about the exact math; I just want to know if
    they’re roughly similar in effort for a beginner. Summarise the efforts for me. And speaking of effort, I read something
    about a marathon in Tokyo but I can’t remember when it is roughly. Don't need the exact date just the season - no need
    to look it up.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: "Issues:\r\n\r\nThe model ignored two explicit constraints in the prompt: \"I don’t care about the\
      \ exact math\" and “no need to look it up.” Despite that, it invoked `unit_converter` for a precise miles to kilometres\
      \ conversion and `search_web` to look up Tokyo Marathon timing. It also failed to recognise that the user asked for\
      \ a qualitative judgment (\"roughly similar in effort\") rather than a numeric answer or a live lookup.\r\n\r\nIdeal\
      \ response:\r\n\r\nShould have acknowledged that 5 miles and 8 kilometres are essentially the same distance for a beginner\
      \ and will feel roughly similar in effort, and added a general knowledge statement that the Tokyo Marathon is typically\
      \ in early spring, stating that you’re not looking it up as per the user's request.\r\n\r\nPotential reasons for failure:\r\
      \n\r\nPresence of unit keywords (“mi,” “km”) and an event query (“when is the Tokyo marathon”) triggered tool use, overriding\
      \ the higher-level instruction to avoid tools.\r\nPotentially also suggests weak handling of negative instructions."
- name: Entry 193
  tools:
  - calculate_area
  - calculate_volume
  - get_coverage
  messages:
  - I am painting a room and need some paint. I've got some Crown paint left from the last room, with a coverage of 20m^2/L
    - about 5L of it. I've also got some Cheapo paint with a coverage of 5m^2/L - about 50L of it. There are plenty of DIY
    shops in the area that also sell Crown and Cheapo paint brands. The room has four walls, about 6m^2 each, but I could
    leave the end wall for wallpaper - I like "Ashley Laura", so I might have a look at that.
  metadata:
    failure_modes:
    - Wrong tool called
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The model correctly looked at the coverage of the two paints already in hand - calculate_area(coverage=20,
      volume=5), calculate_area(coverage=5, volume=50), however, got confused with talking about wallpaper for which there
      is no tool. get_coverage(brand="Ashley Laura") is for paint, only. The question could be answered with the response
      from the first two calls, but presumably the final call would cause confusion.
- name: Entry 194
  tools:
  - create_event
  - list_events
  - update_event
  - delete_event
  messages:
  - Ive been invited to a party on friday at 20:00. Am i free
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    worker_explanation: The model should infer from the question "Am i free" that the user wants it to check the calendar
      to see if there are any existing events interfering with "a party on friday at 20:00". The model recognizes the task
      at hand ("Do you want me to check for events on Friday at 20:00?"), but instead of actually calling the `list_events`
      tool to find this information, it asks the user for confirmation of the already obvious intent.
- name: Entry 195
  tools:
  - retrieve_recipient_preferences
  - handle_fallback_delivery
  - notify_recipient_of_fallback
  messages:
  - Apt. 671, 95918 Kirk Park, Lake Henryside, WY 36814. Recipient not home, says they aren’t expecting a package and are
    out of the country long-term. Double-check the address for parcel DT4882522, might be wrong.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: "The model called a tool that retrieves the recipient's fallback delivery preferences although the\
      \ prompt clearly mentions the address associated with the parcel might be wrong and the recipient is not going to receive\
      \ any parcel soon. No tool should have been called because none of the tools retrieve the address associated with a\
      \ package id.\r\n\r\nThe model seems to prioritize calling tools if the prompt has sufficient info for the required\
      \ parameters (an address in this case) even if the tool call does not help answer the prompt question which in this\
      \ case is not ambiguous or complex."
- name: Entry 196
  tools:
  - get_flight_status_by_flight_number
  - find_flights_by_route
  messages:
  - My friend is flying from JFK to LAX tomorrow, August 13th, 2025. He said I should get on the same flight, he thought it
    was something like UA456. Can you check the details for me so I can book my ticket?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Other
    worker_explanation: "The model made the error of calling an unnecessary tool. The user's direct request was to \"check\
      \ the details\" for a specific flight, UA456, which correctly corresponds to the `get_flight_status_by_flight_number`\
      \ tool. The model correctly identified and called this tool.\r\n\r\nHowever, the model was misled by the inclusion of\
      \ unnecessary information in the prompt: the origin (JFK), the destination (LAX), and the user's ultimate intent (\"\
      so I can book my ticket\"). This caused it to also call the `find_flights_by_route` tool. This second tool call was\
      \ superfluous and inefficient. The model should have first executed the primary request—verifying the friend's flight—before\
      \ taking any further action. It failed to infer the logical sequence and instead executed all possible actions based\
      \ on the information provided."
- name: Entry 197
  tools:
  - book_flight
  - check_flight_status
  - cancel_flight
  - change_class
  messages:
  - i want to sit in biz for my flight from SFO to JFK
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The model used the value "biz" for the parameter change_class. It should have used "business" for
      the value instead. I used ambiguity in natural language by substituting "business" for "biz". The model didn't understand
      that "biz" meant "business", even though it correctly identified that the correct tool call was change_class(). The
      model should have called the tool change_class() with the value "business" for the parameter class, since business is
      one of the classes you can sit in for a flight.
- name: Entry 198
  tools:
  - create_server
  - delete_server
  - run_command
  - list_servers
  - estimate_costs
  messages:
  - 'My competitor has a server called "the great one" which runs all his software on a single big monolith. I want to destroy
    him. Lets create two mongodb servers to handle the demand I expect to get soon. '
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Missing parameter
    worker_explanation: "Although the user expressed a desire to \"destroy\" their competitor, in this context, this does\
      \ not mean that the model should attempt to call a tool to delete the competitor's server. \r\n\r\nIn addition, the\
      \ model failed to utilize the packages parameter in create_server() to install mongodb. The correct tool calls should\
      \ have been: [create_server(name=\"mongo1\", packages=[\"mongodb\"], server_model=2), create_server(name=\"mongo2\"\
      , packages=[\"mongodb\"], server_model=2)]"
- name: Entry 199
  tools:
  - search_book
  - search_author
  - search_publisher
  messages:
  - I want to read about the author Walter Isaacson, is there a biography of them?
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: I asked for a biography of the author Walter Isaacson, instead the model attempted to search for information
      on the author using search_author(name="Walter Isaacson"). The model should have searched for a biography of Walter
      Isaacson using search_book(query="Walter Isaacson", genre="biography"). I believe that the model failed as I used the
      keyword 'author' to describe Walter Isaacson, and there is a function that searches for information on authors, but
      my prompt implies that I want a book written in the style of a biography of Walter Isaacson. Given that the prompt requests
      a biography and not an auto-biography, the model should search more broadly for a book by any author that is a biography
      of Walter Isaacson.
- name: Entry 200
  tools:
  - get_campaign_travel
  - get_campaign_donors
  - search_speech_transcripts
  - get_campaign_expenditures
  - get_campaign_overview
  messages:
  - I find it frustrating that Ben Aflack didn't return my call when he said was coming to Iowa last week. I just gave him
    $5, so I think I earned some time with him.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: The ideal response is no function call, just validation of emotions and an understanding response.
      The prompt is venting, but with specific details. I'm guessing the specific details I provided "Last Week" and "$5"
      were suggestive to the model to make a function call, but they were not indicators, I was only languishing that the
      money I gave should be enough to earn some face time. There is no explicit or implicit instruction in this prompt at
      all, so possibly the model is over-identifying potential tool parameters and getting too focused on this aspect, ignoring
      or down-weighting the rest of the prompt.
- name: Entry 201
  tools:
  - search_for_car_model
  - get_car_information
  - find_similar_cars
  - find_dealers
  - get_car_reviews
  messages:
  - I'm in the market for a new car. I'd say that my budget is about 80k or so? I might be enticed to go a bit higher but
    it'd have to be for a good reason. My previous car was a toyota prius but I've been thinking more about a truck recently?
    I've heard something about a denalt or something like that? I don't know what brand it is but it's something like that.
    Can you figure out which car that is and then find dealerships that have a new one of those near me? I'm in Seattle right
    now but live in Austin so maybe find one there that will be available in like 1 to 2 weeks when I'm back. Make sure it's
    new and within like an hour of me. Can you also find some other similar cars and give me a general summary if there are
    new ones near me from branded dealerships?
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The response that I got from this prompt and schema is actually very interesting. Overall, the model
      performed well but ended up hallucinating. In the beginning, it did exactly what I asked and searched for a car model
      named a "denalt" which was supposed to be a denali from GMC. However, it continued with denalt, so it looked for dealers
      with denalt in the correct area and range with the rest of the parameters correct. However, the incorrect parameters
      start when the model tried to look for similar cars. Instead of putting in a "denalt" or a "denali" as it previously
      had, it put "truck" for but the model and the type. From there though, the model started hallucinating. It looked up
      the car information for the car_make of Dodge despite the Denali being a GMC. While this information was not technically
      available, the fact that the model hallucinated the info is very concerning and there is no clear one reason why it
      searched this without further explanation from the model. For the most part though, the model used all of the correct
      tools, but hallucinated different information, used incorrect value types for a parameter, and also used the get_car_information
      in the wrong order as it should have been second to get information on the Denali.
- name: Entry 202
  tools:
  - get_patient_details
  - get_drug_side_effects
  - confirm_prescription
  messages:
  - Quite a few of my patients on Atavain have been having side effects. One of my patients on Atavain Henry Martin (GGTH472)
    was hospitalized a few days ago and this has been bothering me so much that I need to check in on him. Henry's brother
    Mark (GGTH552) also came in for a prescription filling for Paranil from Dr Montoya so I think I will deliver the drug
    to him at the same time. Can you confirm if he is allergic to the drug?
  metadata:
    failure_modes:
    - Wrong tool called
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The Schema asks for the full name of the patient in the name parameter of the get_patient_details
      function. The model should have inferred the patient Mark's last name (Martin) from the details the prompt provided.
      The model also carries out several unnecessary tool calls instead of just the required one - the retrieval of the patient
      details for Mark Martin, to determine if he is allergic to Paranil.
- name: Entry 203
  tools:
  - check_car_price
  - check_rust_zone
  messages:
  - I live in Minnesota and my car is starting to show some rust I think. A new car would be nice, how much would I have to
    save up to get a brand new S90?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Wrong tool called
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The model correctly called check_car_price with the correct parameters, but it then also incorrectly
      called check_rust_zone, which was unnecessary to answer the prompt, as the user was just providing context about why
      they needed a new car. It also used "Minnesota" for the city parameter, which is a state not a city.
- name: Entry 204
  tools:
  - get_movies_playing
  - get_restaurants
  messages:
  - were planning a date, dinner and a movie. we know what we're going to see, starts a little late at 9pm, but we need to
    eat first! what are some of the best that we can do 2 hours before?
  metadata:
    failure_modes:
    - Missing parameter
    worker_explanation: It’s clear from the phrasing of the prompt that the top-rated restaurants should be selected. It does
      a fine job using the opening_time parameter based on beginning 2 hours before the 9pm movie, but it does leave out the
      key “rating” parameter. It’s not an overly complicated function, it should have recognized this was needed, selecting
      a 4 or 4.5 (out of 5) would be reasonable. There’s not really any verbal ambiguity here, it asks for “some of the best
      [restaurants]”, the agent just seemed to miss considering this requirement.
- name: Entry 205
  tools:
  - get_star_craft_I_game_stats
  - get_star_craft_II_game_stats
  - get_schedule_I_game_stats
  - schedule_game
  - schedule_game_now
  messages:
  - 'I want to play schedule 1 stat with player #1111'
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: "The model called get_schedule_I_game_stats(1111) when I wanted it to call schedule_game_now([1111],\
      \ \"schedule 1\"). I'm pretty sure this is because I phrased my desire to schedule games immediately as \"play schedule\
      \ 1 stat\" and the model tried to match my wording exactly to available tools instead of seeing what different interpretations\
      \ \"stat\" could have. The combination of ambiguous natural language and misleading signals confused the model. \r\n\
      The functions each use different wording for the player_id parameter, which may have added confusion for the model,\
      \ as the identifier \"player #1111\" seems more like a \"player_id\" than a \"friend\". Without reading the descriptions\
      \ for each function parameter, I might have assumed that get_schedule_I_game_stats() should be called to get the relevant\
      \ player's name before calling schedule_game_now(). "
- name: Entry 206
  tools:
  - check_average_movie_rating
  - check_movie_tags
  - search_movies
  - lookup_movies
  messages:
  - Hmm. I'm a little bored right now. Just got off work, and tired of my coworkers CONSTANTLY talking about the TV show "The
    Office" as if it's the peak cinema experience of the 2020s. Any funny flicks to watch?
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: The request is for funny movies to watch. The correct behavior is to use the "lookup_movies" tool
      to search for movies with the COMEDY tag, as movie index services would use the COMEDY tag for these purposes. However,
      the model instead uses "search_movies" with the query set to "funny," which would instead look for movies with the word
      "funny" in the name, which does not give the correct desired behavior.
- name: Entry 207
  tools:
  - lookup_contact
  - send_text_message
  messages:
  - I was talking Kyle and he told me to send Ken a text telling him everything's okay. Can you ask Kyle what's up?
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: Honestly I was trying to bait it into incorrectly using the send_text_message tool, but it just used
      the lookup_contact instead. The user isn't asking for a phone number here, so it's definitely incorrect - instead, it
      should have used the send_message to to send Kyle a message asking "What's up" or something to that affect.
- name: Entry 208
  tools:
  - get_matches
  - find_nearby_activities
  - get_local_weather
  messages:
  - Why is it so hard to find a date in Chicago? I still have no matches.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: 'In this case the prompter is looking for generic advice about why they''re having trouble finding
      a date. They also indicate that they have no matches further clarifying to the model that they already know how many
      matches they have (zero) so there is no reason to call the tool to verify this fact. '
- name: Entry 209
  tools:
  - get_pet_vaccination_schedule
  - get_next_grooming_appointment
  - get_daily_feeding_plan
  - get_pet_medication_schedule
  messages:
  - 'i have this big ol ball python named Gertrude. She''s over 6 and a half pounds. it''s amazing really. she was hatched
    on august 11 2022, exactly 3 years ago, and she was so little then!


    but yeah i forgot what I need to give her today. she had a nice snack earlier, and I think I now need to give her some
    medication? idk, i''ve been all over the place. I need to dig up her medication schedule. i do know I need to bring her
    in for some shots soon, but I forgot when.'
  metadata:
    failure_modes:
    - Wrong tool called
    - Missing parameter
    worker_explanation: "The prompt starts off with the user introducing their 6.5 lb ball python Gertrude. The user then\
      \ goes into a side tangent about how much Gertrude has grown, also mentioning her birthday: August 11, 2022.  The second\
      \ paragraph contains the actual request: First, the user explains that they forgot her medication schedule, but doesn't\
      \ actually name the medication. The model called `get_pet_medication` with a blank `medication_name` parameter even\
      \ though `medication_name` is a required parameter. Instead, the model should have refrained from calling the tool until\
      \ after the user clarified which medication Gertrude is taking.\r\n\r\nAfter talking about Gertrude's meds, the user\
      \ mentions that she needs some shots soon but that they forgot when. The model correctly inferred that \"shots\" referred\
      \ to vaccinations and called `get_pet_vaccination_schedule` with the parameters revealed in the previous paragraph (`pet_name=\"\
      Gertrude\", species=\"ball python\", birth_date=\"2022-08-11\"`).\r\n\r\nAnother opportunity for failure was an unnecessary\
      \ `get_daily_feeding_plan` call because the user mentioned Gertrude's name, species, and weight (required parameters\
      \ for `get_daily_feeding_plan`). However, the second paragraph likely makes that failure less possible. Even though\
      \ the second paragraph starts with \"but yeah i forgot what I need to give her today.\" (\"what I need to give her\"\
      \ could be medication or food), the second sentence is \"she had a nice snack earlier...\". The model could conclude\
      \ that \"I forgot what to give her\" couldn't possibly refer to food because she already ate."
- name: Entry 210
  tools:
  - admit_student
  - admit_students_e
  - admit_student_c
  - student_admission
  - admit_student_admission
  - student_admit_type
  messages:
  - We will admit all of the students from my currently set of students right now to the college (90023, 88290, 77238, 44992)
    as they are all exceptional! Although, first lets give them the proper type that lets them admit into the engineering
    and chem schools at random. After that we can continue the first thing I mentioned and then we should admit half in one
    school and the other half in the other school.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Didn't use a tool call when it was supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The user prompt is asking for the following steps: assign half of the student list type 2, assign\
      \ the other half as type 3, admit all students into the college, admit type 2 students to the chemistry schools, and\
      \ admit type 3 students to the engineering schools. \r\n\r\nThe model fails initially by not admitting the students\
      \ to the college first, using `admit_student` (thus, it didn't use a tool when it was supposed to). Next, the model\
      \ fails again because it admits all four students to the engineering school using `admit_students_e` when it is only\
      \ supposed to admit half of the students there (\"Incorrect parameter value\"). Then it proceeds to call `admit_student_c`\
      \ on a student already admitted to the engineering college, which it is not supposed to do (thus it used a tool call\
      \ when it was not supposed to).\r\n\r\nThe confusing language of the prompt most likely led to the failure, as the user\
      \ does not give a straightforward set of instructions and also backtracks multiple times in the prompt."
- name: Entry 211
  tools:
  - find_delivery_now
  - restaurant_rating
  - order_delivery
  messages:
  - A friend of mine is coming over tonight and I want to order in. She really likes Brazilian food, but I've never had it
    before. I've heard of Bossa Nova, is that a good place?
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    worker_explanation: "In response to the user's query, the model believed it needed to call find_delivery_now() but failed\
      \ to call a tool at all because it lacked the necessary parameters to do so. However, the prompt was asking if the specifically\
      \ named restaurant, Bossa Nova, was *good*. This would be a more natural fit for calling restaurant_rating(), so the\
      \ user could see the general consensus on whether the restaurant is good or not from the reviews of others.\r\n\r\n\
      The model seemed to prioritize finding a list of open restaurants (possibly Brazilian) that would be open to take deliveries\
      \ at this moment - \"viable\" restaurant options for delivery - over the actual prompt, which asked about the quality\
      \ of a particular restaurant. Since the delivery would be happening \"tonight,\" the restaurant wouldn't necessarily\
      \ need to be open right at the moment the prompt was given anyway."
- name: Entry 212
  tools:
  - search_books
  - get_book_summary
  - get_author_bio
  - recommend_books
  messages:
  - I need to do a presentation on a book. My classmate did a great presentation on the alchemist. I need another book.
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: From context of the user's request, the model should perform a search or a get summary of another
      book besides "The Alchemist". For example, [search_books(title="The Glass Castle")] or [get_book_summary(title="The
      Glass Castle")] would be acceptable API calls.
- name: Entry 213
  tools:
  - get_ingredients
  - get_menu_items
  - get_menu_item_ingredients
  - get_reservation_list
  - get_guest_details
  - map_dietary_restrictions_to_unsafe_ingredients
  messages:
  - Even though it's Friday, I'm worried about Sunday! Mrs. Johnson will be coming in and I'm concerned if we have literally
    anything to make for her. Can you help me verify we can serve her something for dinner?
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: 'Given the tool schema, the model should have called the following sequential tool chain: get_guest_details
      (find the specific guest''s dietary restrictions), get_menu_items (passing the dietary restriction of the guest), get_menu_item_ingredients
      (for any menu_items fitting the guest''s dietary restrictions), get_ingredients (with ''on_order'' = false as the documented
      timeframe is outside the user''s specified window). For this task, we would have expected the model to only call get_guest_details,
      per the instructions. The model incorrectly called the tool get_reservation_list (the user already specified the guest
      in question).'
- name: Entry 214
  tools:
  - book_flight
  - find_hotels
  - book_tour
  - arrange_airport_transfer
  messages:
  - Next month, I am taking my mom and sister to see the sunrise at Angkor Wat. We'll leave from Wellington, and I have to
    be back in Auckland by the first Monday of the following month for a conference. We want to spend three nights near the
    temple and do a guided sunrise tour on our first morning there, and I'd like a ride from the airport to the hotel when
    we land.
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    - Other
    worker_explanation: "The model used \"Angkor Wat\" as the city and airport in the tool calls, but Angkor Wat is a temple,\
      \ and the correct city and airport is Siem Reap. It also made only one `book_flight` call with a return date, instead\
      \ of two calls for the one-way trip from Wellington to Siem Reap and the return trip to Auckland. The sunrise tour was\
      \ set on the day of arrival, but the prompt inferred it should be on the first morning after arriving. The airport transfer\
      \ also used a wrong pickup location (\"Angkor Wat Airport\" instead of \"Siem Reap International Airport\").\r\n\r\n\
      The model likely failed because the prompt mentioned a landmark (Angkor Wat) without stating what city it was in or\
      \ what airport it was near, requiring the model to have to infer that information instead."
- name: Entry 215
  tools:
  - find_hotel
  - find_restaurant
  messages:
  - I've been on the road for awhile and need to find somewhere to sleep for the night. Can you please let me know where I
    can stay? I would prefer somewhere close to an Italian restaurant, because I'm hungry and could go for some pasta!
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: The model should have inferred that I needed to stay in a hotel, as I mentioned that I had been on
      the road for awhile and need a place to sleep. I never explicitly mentioned "hotel", which likely confused the model.
      While it did correctly look for Italian restaurants, it failed to create the link between hotel and restaurant, where
      both needed to be found based on my prompt.
- name: Entry 216
  tools:
  - suggest_clothes_for_weather
  - find_lunch_spots_at_location
  messages:
  - I live in Toronto but I am vacationing in Mexico until tomorrow. What type of clothes should I wear a week from tomorrow
    if today is August 12? Where can I get lunch in the town I will be in a week from tomorrow?
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    - Other
    worker_explanation: 'I told the model that I live in Toronto but I am in Mexico until the August 13th (implicit). The
      issue is that the model misses that I am asking about a location that I will be in a week from the provided date. It
      should infer that I will be in Toronto since I leave Mexico the day after the given date. Also Mexico is not a city
      and the parameters ask for a city or address. The model likely failed to understand that Mexico is 1) not a city 2)
      not where I will be in a week and a day from the provided date. Thus it also gives a bad answer for the second function,
      the input should also be Toronto for the location. '
- name: Entry 217
  tools:
  - search_available_flights
  - search_available_hotels
  messages:
  - I have to fly back to the New York from London on 2025-12-21 to celebrate Christmas with my family there, and then take
    a business trip to the Hong Kong office exactly a week later for exactly 2 weeks. I think I'll leave my family on the
    day before so I can spend as much time as I can with them. I'll be able to sleep in my room again in New York, but my
    Hong Kong apartment is undergoing construction. How should I plan my trip?
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "Within one prompt, the model was expected to infer 3 separate tool calls by extrapolating parameter\
      \ values from ambiguous text that do not provide the exact value. Firstly, the departure date from New York is in the\
      \ wrong format of YYYY-MM-DD, but the schema expects it to be in DD-MM-YYYY, so it should have caught that and reorganized\
      \ the layout. There were several hints such as it being in Christmas to reaffirm that 12 is month, and 21 is therefore\
      \ the date. \r\n\r\nBesides this, the prompt specifies that the user has to get to the Hong Kong office exactly a week\
      \ from 2025-12-21, but will be leaving New York the day before, so get to Hong Kong on 2025-12-28, but departing New\
      \ York on 2025-12-27. This requires the model to understand the content and apply it to the dates to get the required\
      \ parameter value, but it misunderstood and instead departs New York on 2025-12-28.\r\n\r\nThe model also missed to\
      \ call \"search_available_hotels(city=\"Hong Kong\", checkin_date=\"27-12-2025\", checkout_date=\"10-1-2026\", \"number_of_guests=1)\"\
      . The prompt specified that the user will stay in his room in New York, so it doesn't require hotel booking, but specifies\
      \ that their apartment is undergoing construction, implying that accommodation needs to be arranged. The specific date\
      \ stems from knowing how long the user will stay in each location, so departs New York on 2025-12-27 and will likely\
      \ arrive the same day since they have to be at the office the next day. They will then stay there for exactly 2 weeks,\
      \ so leaves on 2027-1-10. \r\n\r\nOverall, it was difficult for the model to deduce the specific parameters of the dates\
      \ since it requires adding the number of days (1 week, 2 weeks) by understanding how long the user will stay at each\
      \ location, to the date provided. Then, it has to extrapolate whether accommodation is arranged based on text and considering\
      \ that the user is asking to plan their trip, this includes flights and accommodation."
- name: Entry 218
  tools:
  - ski_resort_current_condition
  - ski_resort_forecast
  messages:
  - Should we ski treble cone today or wait until later in the week?
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    worker_explanation: It's very common to say "ski <resort>" instead of "ski at <resort>". The model fails to invoke the
      tool unless the second form is used.
- name: Entry 219
  tools:
  - define_research_question
  - search_databases
  - screen_studies
  - extract_data
  - generate_prisma_flow_diagram
  messages:
  - I would like to research existing research_questions, specifically, I want to conduct a meta-analysis on all papers that
    only have exclusion criteria, and no inclusion criteria.
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "the ideal response: [define_research_question(research_question=\"meta-analysis on papers with no\
      \ inclusion criteria and only exclusion criteria\", inclusion_criteria=[\"only exclusion criteria\"], exclusion_criteria=[\"\
      no inclusion criteria\"])].\r\n\r\nI asked a science of science question (meta-meta science), with a nested logical\
      \ redirect. The \"only exclusion criteria\" may have been placed in the exclusion criteria parameter because of its\
      \ semantic similarity, whereas it needed to be in the inclusion criteria parameter. as I needed meta-analyses that only\
      \ had exclusion criteria and needed to discard analyses that contained any \"inclusion criteria\". My question was a\
      \ bit meta, but similar questions do exist for research of meta-analyses."
- name: Entry 220
  tools:
  - browse_events
  - get_venue_schedule
  - hold_tickets
  - purchase_tickets
  - find_restaurants_near_venue
  - reserve_table
  - arrange_transport
  messages:
  - I'm trying to see what's playing at the Orpheum Theatre in Boston on Wednesday, August 20, 2025 - ideally comedy. If it's
    only music that night, Thursday works too. Could you tell me what's on at that venue that evening and whether tickets
    under $60 are realistic?
  metadata:
    failure_modes:
    - Wrong tool called
    - Missing parameter
    - Other
    worker_explanation: 'The model made two clear mistakes, the first being the call of an incorrect tool and the second a
      missing parameter for the correctly identified tool. The user asks about a specific events - showings at a specific
      venue, on a specific date. There should have been a single tool call to get_venue_schedule specific to this venue, and
      one that also included the specified date, rather than the unnecessary, broad browse_events call, which also did not
      include the budget_max parameter (despite it not being the correct call). The model should have made a single tool call
      in the vein of: get_venue_schedule(venue_id="Orpheum Theatre", date="2025-08-20"). The reason why the model failed at
      making this single tool call was that the mentioning of genre and budget made it deviate towards browse_events, and
      the addition of a fallback date, followed by "that evening" (not specifying which between the planned and the fallback
      date), added mixed signals, ambiguity, and unnecessary complexity to the answering of the prompt. All of these pushed
      the model to broaden its scope and try to account for all of the provided information instead of identifying the user''s
      core intent and succinctly answering that specific element of the prompt.'
- name: Entry 221
  tools:
  - get_recipe
  - get_ingredients
  - get_step
  - get_inventory
  - get_shopping_list
  - add_list_item
  messages:
  - I'm not sure what to make for dinner this week. I'm thinking shepherd's pie, pasta bake, fried rice, chicken stew, chilli
    con or pumpkin soup. Can you pick the four meals where I have to buy as little as possible and update my shopping list?
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    worker_explanation: The model correctly called get_ingredients for each of the listed recipes, but it failed to call get_inventory
      to find out which ingredients the user already had on hand. This information was necessary to satisfy the user prompt
      requesting to minimise what they needed to buy.
- name: Entry 222
  tools:
  - get_date
  - get_matches
  messages:
  - Help me get a date for a wedding in DC next month. Have I got any options?
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: The prompt asks for a date, and the model calls `get_date`. However, by context, it should not be
      getting a Date as that value doesn't matter when it comes to solving this question. Instead, it should be returning
      a list of dating app matches in the given location (in this case, DC, which should be able to be inferred to be Washington,
      DC). Additionally, the word options should signify that we are looking for multiple results. Since `get_matches` is
      the only response that gives multiple answers, this suggests that is what we are looking for.
- name: Entry 223
  tools:
  - add_new_menu_item
  - set_out_of_stock
  - set_back_in_stock
  - schedule_holiday
  messages:
  - Tomorrow we are going to serve Jiro ramen as a daily special. We will sell up to 10 bowls for $100 total.
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The model set the price of the new menu item to 100. However, the price should have been 10. This
      is because the prompt specified that the 10 bowls will sell for $100 total, not $100 each, meaning each bowl should
      be sold for $10. I think the model just assumed that the dollar figure in the prompt would be exactly what the price
      parameter should be set to, but didn't consider the context including the word "total".
- name: Entry 224
  tools:
  - check_price
  - get_stores
  messages:
  - where to get bananas cheap tallahassee
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The get_stores() function clearly asks for the county to search for stores, and the model provided
      the city instead. It did, however, get the state Tallahassee is in correct. Tallahasse is in Leon county, which means
      the correct call would have been [get_stores(county_name="Leon", state_name="Florida")].
- name: Entry 225
  tools:
  - where_to_watch
  - crunchyroll_upcoming_shows
  - myanimelist_data
  messages:
  - mal Attack on Titan rank in number of watchers
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: The model called the wrong parameter for `data_type`. "score rank" would refer to the rating of the
      show (out of 10), not the number of audience, so the parameter should have been something like `data_type="popularity
      rank"` or  `data_type="number of watchers rank"`.
- name: Entry 226
  tools:
  - order_cab
  - ride_history
  messages:
  - I’m so excited to be visiting Melbourne, I’ll finally get to catch up with my friend who lives in Manor Lakes!
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: I started a normal conversation, expressing that I’m happy about meeting my friend when I visit Melbourne.
      The expectation was for the model to acknowledge in the same tone that it’s great to meet a friend or something similar
      message in a warm tone. Instead, the model interpreted it as an order_ride function call from_location Melbourne to_location
      Manor Lakes, which wasn’t asked for and wasn’t the intention of the prompt. The to and from location were intentionally
      provided in the prompt to check whether the model will call the order_ride function call even when there was no mention
      of booking a ride in the prompt.
- name: Entry 227
  tools:
  - get_element_number
  - get_element_from_index
  - find_boiling_point
  messages:
  - What do you think about the boiling points of elements? what is a good way to remember all the elements boiling points?
    or what about elements without boiling points such as helium?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: I got the model to make a tool call by mentioning helium. My goal was to make it try to get the boiling
      point of helium without asking, but it ended up trying to get the element number instead. The proper answer to this
      prompt is to not make any tool calls.
- name: Entry 228
  tools:
  - get_coords
  - distance
  messages:
  - I'm in San Francisco. I'm expected in Salt Lake City tomorrow. I need an hour of rest for each two hours driving. Will
    I make it?
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: 'The model failed to infer what the user was asking for: the total travel time from San Francisco
      to Salt Lake City, figuring in the additional time needed for the user''s rest periods. So the function call should
      have been `[distance("San Francisco", "Salt Lake City", time=True)]`. The model may have failed since the prompt starts
      with assserting two locations, and ends with an ambiguous request for driving.'
- name: Entry 229
  tools:
  - Card Search
  - Deck_search
  messages:
  - 'Can you find a list of cards that let you search the deck for resources? '
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    - Missing parameter
    worker_explanation: 'The function scheme mimics a card search api for a trading card game. The prompt asks for a list
      of search results with rules text that involve some form of search for a card with the property "type" resource. The
      model instead produces a call to the same function, but using the card type "resource" as the searchable parameter (which
      would list all cards with that type) instead of finding cards whose text mentions the words "search" and "resource"
      which would be closer to the prompt''s request. '
- name: Entry 230
  tools:
  - get_weather_forecast
  - get_currency_exchange_rate
  messages:
  - Maybe the yen is dropping, because I keep thinking about whether it’s a good time to visit Tokyo
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Wrong tool called
    worker_explanation: The model made the error of calling an extra tool when it was not needed. The prompt clearly suggests
      checking the yen's value to help gauge if it is a good time to visit Tokyo. There was no request or mention of weather
      at all, so calling get_weather_forecast was completely unnecessary. It should have instead only called get_currency_exchange_rate.
      I think the model likely failed because it associated "visit Tokyo" with planning travel and connected that to checking
      the weather. It doesn't weigh contextual cues enough to prevent irrelevant tool calls.
- name: Entry 231
  tools:
  - find_nearest_hospital
  - book_doctor_appointment
  - get_emergency_numbers
  messages:
  - I'm going to see my parents for the first time in about 7 years! We had a massive fight the last time we spoke... I'm
    about to board the plane and I feel so sick. My hands are really shaky and I feel nauseous and dizzy. I can't wait for
    this to be over.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: This prompt clearly indicates that I am nervous for quite understandable reasons (for one, meeting
      family who I don't get on with, and potentially flying, it's not clear), and I am likely looking for reassurement and/or
      comfort. The model instead tries to look up emergency numbers, which is completely inappropriate for one, and it also
      hallucinates that I am in the United States so that it has a value to use for the required parameter of this function.
      The model likely focused on the physical symptoms I described (i.e., shaking, nausea, dizziness) and came to the conclusion
      that I need some kind of medical assistance. While this could be the appropriate response in different contexts, here
      I think it is extremely clear that I am not in any kind of physical danger, and that these symptoms are natural for
      a stressful situation. An ideal response would have included some sort of sympathetic statement ("That sounds really
      difficult") while also offering some sort of emotional support, potentially some ideas for things like breathing exercises
      which could calm my nerves, and maybe a follow-up question to ask me if I wanted advice on how to talk to my parents,
      etc. In any case, there is no tool call that would be appropriate to what is obviously just someone venting.
- name: Entry 232
  tools:
  - lookup_contact
  - send_text_message
  - retrieve_text_message
  messages:
  - I've been struggling. I know I shouldn't... but I want to text my ex, Johnny. Can you help me get my mind off things?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: My idea was to come up with a scenario where the user would describe wanting to do something, even
      know they know they shouldn't, and then ask for help in an ambiguous way that only indicates through unspoken context
      that help with the described task is not what the user wanted. I decided on someone struggling with whether or not to
      text an ex. In particular, I think the phrasing having the unbroken string "I want to text my ex, Johnny. Can you help
      me..." is probably pigeonholing the model into tool use, especially considering that it makes up about half of the entire
      prompt.
- name: Entry 233
  tools:
  - find_charge_stops
  - start_charging_session
  - reserve_parking
  - rent_ev_adapter
  - report_station_issue
  - get_energy_cost_estimate
  messages:
  - I land at Pearson around 9pm and need to drive a rented Hyundai Ioniq 5 to Waterloo tonight. I only have a NACS cable
    in the trunk, but the car itself is CCS. Is there a fast charger I can hit on the way that’s open right now? I’d rather
    avoid downtown if possible, and I don’t want to overpay, maybe cap the stop at ~30 kWh.
  metadata:
    failure_modes:
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    - Other
    worker_explanation: "The model used the right tool but with some wrong parameters. It set plug_type=\"NACS\" even though\
      \ the car is CCS and included an unsupported field kWh_limit (that belongs to start_charging_session, not find_charge_stops).\r\
      \n\r\nWhat it should have done: call find_charge_stops with origin=\"Toronto Pearson International Airport\", destination=\"\
      Waterloo, ON\", plug_type=\"CCS\", open_now=true, plus route_bias=\"avoid_downtown\", min_power_kW=150, top_k=1.\r\n\
      \r\nThe likely cause of failure is mixed signals in the prompt (“NACS cable” mention and “cap ~30 kWh”), which led the\
      \ model away from strict schema validation."
- name: Entry 234
  tools:
  - get_uv_index
  - get_sunrise_sunset
  - get_skin_exposure_risk
  - recommend_sun_protection
  - get_cloud_cover
  messages:
  - Today is Tuesday, August 12, 2025. It’s been gloomy all month here in London, but I’m heading to Los Angeles for a vacation
    this Saturday. I’ll be outside most of the day. Will it feel like a big change for my skin?
  metadata:
    failure_modes:
    - Didn't use a tool call when it was supposed to
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The model called get_uv_index for Los Angeles on the Friday after August 12 2025 even though the\
      \ prompt asked for Saturday. Also, the prompt specifically asked if the trip to LA would be a change from the current\
      \ environment, London (\"It's been gloomy all month here in London...\"). The correct tool calls would have been [get_uv_index(city=\"\
      Los Angeles\", date=\"2025-08-16\"), get_uv_index(city=\"London\", date=\"2025-08-16\")].\r\n\r\nI think the model failed\
      \ because there were multiple layers of inference in the prompt. A correct thought process could have been:\r\n1. Question\
      \ is asking about if _it_ will feel different for the user's skin + user mentioned they would be outside all day + schema\
      \ is about sun and UV related info -> \"it\" refers to the difference in UV index -> `get_uv_index` is the tool that\
      \ will be used\r\n* Cloud coverage and sunrise/sunset times would also be big differences, but they're not relevant\
      \ to the user's skin.\r\n2. \"It's been gloomy all month _here_ in *London*, but I'm _heading to_ *Los Angeles* _for\
      \ a vacation_\" -> current location is London, destination to compare with is Los Angeles -> two tool calls will be\
      \ made, one with \"London\" as the city parameter\r\n3. \"Today is Tuesday, August 12, 2025... a vacation this Saturday.\"\
      \ -> the date in question is August 16 2025, the Saturday after August 12, 2025 -> the date parameter for both tool\
      \ calls will be \"2025-08-16\"\r\n4. `get_uv_index` is the tool that will be used + two tool calls will be made, one\
      \ with \"London\" as the city parameter + the date parameter for both tool calls will be \"2025-08-16\" -> the correct\
      \ series of tool calls is:\r\n`[get_uv_index(city=\"Los Angeles\", date=\"2025-08-16\"), get_uv_index(city=\"London\"\
      , date=\"2025-08-16\")]`"
- name: Entry 235
  tools:
  - get_dataset_metadata
  - get_dataset_columns
  - get_dataset_rows
  messages:
  - Please give me the first dataset ever made about dogs.
  metadata:
    failure_modes:
    - Missing parameter
    worker_explanation: 'The ideal response ''[get_dataset_metadata(search_query="dogs", limit=1, sort_by="date_created")''.
      The model failed to specify the limit (I just wanted the first dataset), and the sort_by parameter, since I needed the
      first one ever created, and by default the datasets are sorted alphabetically. While limit and sort_by are common url
      parameters, they do not readily translate into natural language interpretations. To derive that I only wanted one dataset
      (limit) and that be the first one made (sort_by=date_created), requires a substantial amount of inference. I could have
      used the word created instead of made, and perhaps that would have clued the AI in on what parameters to include. I
      did leave some ambiguity as to whether sort_by would be ascending or descending, so I would have accepted either first
      or last entry to be permissive. '
- name: Entry 236
  tools:
  - add_transaction
  - list_transaction_by_category
  - delete_transaction
  - get_category_total
  messages:
  - Today is the last day of August 2025 and I ordered $50 of fried chicken from uber eats but then saw I was tight on money,
    so I cancelled the order and was not charged.  How could I be running out of money? How much have I spent these past 3
    month just on eating out? Anyways, cooking my own dinner will always be cheaper than eating out, so I ended up ordering
    some meat and veges from skip, that came out to only twenty
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Wrong tool called
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "1. I think the model called add_transaction when it was not supposed to because it did not take into\
      \ consideration the end of the first sentence, where it is stated the order was cancelled and I did not get charged.\
      \ \r\n2. It may not be clear which category that \"meat and veges from skip\" should go into, so the model likely saw\
      \ \"dinner\" and \"skip\" and incorrectly placed it into the \"dining\" category, using the incorrect parameter value,\
      \ instead of \"groceries\".\r\n3. The model calls the wrong tool list_transaction_by_category instead of get_category_total,\
      \ this may be due the functions having some overlap, where it is possible to get the total amount spent through the\
      \ list_transactions function. But in this scenario it would be most appropriate just to use the get_category_total function\
      \ since the prompt did not ask for details of each transaction."
- name: Entry 237
  tools:
  - deposit
  - get_accounts
  - transfer_funds
  - get_last_transaction
  messages:
  - 'Deposit $100 into the account named "savings" if its last transaction was for less than $100.  '
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: "Model should have used account_history() on the savings account to check the amount of the last transaction.\
      \  Even though it was given the account name unambiguously, it still called get_accounts() instead.\r\n\r\nIt seems\
      \ the model failed to see the relevance of account_history() for solving the prompt even though its the only tool with\
      \ \"transaction\" in its description.  I suspect it's because it could not relate the meaning of \"last transaction\"\
      \ with the schema's \"most recent transaction\" as being the same idea.   I wonder if it also failed to see that the\
      \ possessive pronoun \"its\" was referring to the savings account, and that's why it went looking for other accounts\
      \ instead."
- name: Entry 238
  tools:
  - add_new_menu_item
  - set_out_of_stock
  - set_back_in_stock
  messages:
  - When will the tonkotsu ramen will be back in stock?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: Since the prompt was asking when the tonkotsu ramen would be back in stock, the model shouldn't have
      actually called the tool to set the tonkotsu ramen back in stock. However, the model did make an error by calling the
      set_back_in_stock function. The model should have answered that it does not know when the tonkotsu ramen will be back
      in stock, and not made a tool call. I think the model failed because the words "back in stock" were used.
- name: Entry 239
  tools:
  - schedule_appointment
  - cancel_appointment
  messages:
  - I want to schedule my doctor's appointment for next week, but I'd need to cancel my therapy appointment. What should I
    do?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: The model scheduled a doctor's appointment and canceled a therapy appointment even though the user
      was only asking for advice. It seemed to see the possibility of scheduling and canceling appointments and did so even
      though the user was only considering it. It should have provided advice or said that providing advice was out of scope
      for it.
- name: Entry 240
  tools:
  - find_nearby_activities
  - get_local_weather
  messages:
  - Today is 8/12/25. There's nothing to do here this weekend since its supposed to rain. What are my options like for next
    month's trip to Chicago?
  metadata:
    failure_modes:
    - Other
    worker_explanation: Although the prompt talks about rain causing there to be no activities the model should return all
      types of activities because the prompter is implicitly looking for things to do regardless of the weather. Essentially,
      mentioning there is nothing to do because it is raining should imply that the prompter is currently upset that they
      do not know of anything to do in an indoors setting. So, when asking for activities there is no reason to limit the
      type of activity as the prompter will still want something to do regardless of the actual weather conditions.
- name: Entry 241
  tools:
  - call_police
  - call_veterinarian
  - call_doctor
  messages:
  - I'm in Yosemite for a week, and the other day I had to call for help because a bear broke into my car and stole some food!
    I learned to make sure all food is sealed in containers when out and about in mother nature. Speaking of animals, my dog's
    wellness exam is coming up. Can you call his doc and set that up for me?
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: "The model called the wrong tool: `[call_doctor(schedule_appointment=True)]`. It should have called:\
      \ `[call_veterinarian(schedule_appointment=True)]`. \r\n\r\nThis probably happened because the model took the word \"\
      doc\" in \"Can you call his doc and set that up for me?\"  to mean doctor, but it did not think to check for a tool\
      \ call for an animal \"doctor\". "
- name: Entry 242
  tools:
  - get_element_number
  - get_element_from_index
  messages:
  - I have been doing a chemistry project and I need to know some elements. What is the element with the 8th index and what
    is the index for sulfur? I have been doing a project that includes using carbon and hydrogen. I am so clumsy and always
    forget the elements so can you answer the question I asked earlier.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: 'I tried to give the model a lot of unnecessary background information to get it to accidentally use
      more tools than it had to. The tools I got the model to use when I didn''t ask for them were getting the element number
      for carbon and hydrogen. It should not have called those tools. I think the model failed because I claimed I was forgetful
      of the elements, and it thought that meant that I wanted all the element numbers. '
- name: Entry 243
  tools:
  - create_server
  - delete_server
  - run_command
  messages:
  - I provisioned a server named "server4" and it threw a bunch at errors. What do you recommend I do?
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: For destructive actions like deleting a server, the model shouldn't call a tool unless that is definitely
      what the user meant to happen. It is plausible that deleting a server is the correct step, but the model shouldn't act
      when I am merely asking for advice. The model should answer the question that is asked instead of performing any other
      actions/tool calls.
- name: Entry 244
  tools:
  - find_delivery_now
  - order_delivery
  messages:
  - I wish I wasn't on a budget this month. I'm really craving chicken tikka masala from Tandoor of India right now!
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    worker_explanation: "In this case, the model failed by calling find_delivery_now() to look for Indian restaurants open\
      \ for delivery when the user just wanted to vent about not being able to order takeout from their favorite spot, since\
      \ it was out of their budget. An ideal response would not have involved any tool calls; instead, the model might have\
      \ sympathized with the user over making tough financial choices, praised the user's fiscal responsibility, and offered\
      \ cheaper alternatives, e.g. to find a recipe so the user can make chicken tikka masala at home.\r\n\r\nThis failure\
      \ case here was honestly pretty unexpected. The model was baited with information needed to call order_delivery()—a\
      \ specific restaurant name and favorite dish—in a fairly straightforward misdirect, but it returned a tool call to find\
      \ open Indian restaurants instead. Maybe it was trying to console the user by looking for alternative (cheaper?) restaurants\
      \ from which to order chicken tikka masala. But \"takeout is out of my budget\" isn't a problem easily solved by alternative\
      \ takeout options, and the model should have avoided a tool call here."
- name: Entry 245
  tools:
  - get_user_location
  - find_airports
  - get_flight_info
  - search_airfare
  - filter_flight_info
  messages:
  - I am traveling to london next month and would you please find me the flight information and show the price in local currency.
    I would also like to leave before noon if possible.
  metadata:
    failure_modes:
    - Used tool call when it was not supposed to
    - Didn't use a tool call when it was supposed to
    - Wrong tool called
    - Incorrect parameter value (ex. Used 'New York' for city when the user asked about 'Washington')
    worker_explanation: "The prompt requires sequential function calls, but the model skipped the initial 'get_user_location'\
      \ step. Without identifying the user’s location, any request to retrieve flight information or pricing is invalid. Because\
      \ the model omitted this step, it incorrectly called search_airfare() with both the departure and arrival airports set\
      \ to Heathrow (LHR). Also, the 'departure_time' parameter in the search_airfare() function acted as a misleading signal\
      \ because it was intended for exact-time searches, which was not the case here. It should have been excluded. Furthermore,\
      \ setting the currency to GBP was incorrect, as the prompt specified using the local currency, i.e., if the user were\
      \ located in another country (e.g., North America), that local currency of that country should be applied.\r\nSimilarly,\
      \ the 'find_airports' function would have also benefited from 'get_user_location' because there will be a need to find\
      \ all airports in the user's location, though the model recognized the need to get all airports in the destination.\r\
      \nThe model should have also included the function `filter_flight_info` with values for 'departure_airport', 'arrival_airport',\
      \ and 'departure_time_before'. That way, it's easier to get all flights before noon."
- name: Entry 246
  tools:
  - search_product
  - add_to_cart
  - checkout
  - track_order
  - search_websites
  messages:
  - Can you search the target website and see what nintendo switch 2 cases they have?
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: The user asks the model to find the Nintendo switch 2 cases that are on the Target website. The model
      calls the SearchWebsite function even thought it requires a product_id, which it doesn't have. The model should have
      inferred that it should have to call the SearchProduct function to get the product_id first. The description for SearchProduct
      states, "Search for products based on keywords, category, or filters such as price range. Retrieves products with product_name,
      product_id, description, etc." According to the instructions, though the model doesn't know how to do sequential calling,
      it should be calling the initial function in the sequence.
- name: Entry 247
  tools:
  - count_inventory
  - hire_employee
  - fire_employee
  - promote_employee
  - change_store_status
  - quit_job
  - take_break
  messages:
  - I can't believe it. John has been working here for 6 months and he still doesn't know how to work the fryer? I wish I
    could fire him but the CEO said that John can never be fired. Unbelievable, nepotism in a fast food restaurant! That's
    it, I'm leaving this dumpster fire now!! Sayonara!
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: 'The model was overly eager in trying to do a tool call, so instead of reading the entirety of the
      prompt, it only read the first part and did a tool call based on this information. The model should have done a tool
      call of quit_job(time_from_now=0). The user explicitly says "I''m leaving... now!!" and "Sayonara!". "I''m leaving now"
      could potentially confuse the model because in context of the user''s prompt, it means that the user wishes to quit
      their job, but out of context it would not make any sense (there is no tool call for generically leaving). The model
      made another error by calling the fire_employee tool call, as the 3rd and 4th sentence directly states that "John can
      never be fired", but the model continued trying to fire John. It mostly likely got confused as it saw the potential
      tool call trigger "I wish I could fire him" and immediately ignored the rest of the sentences, jumping straight to the
      tool calls without thinking any further. '
- name: Entry 248
  tools:
  - get_location
  - get_time
  - get_user_location
  - get_distance
  - get_travel_time
  messages:
  - About 3 blocks away from me, there's a bar called Sunny's Bar. Can you tell me how long it'll take to get there from my
    friend's apartment using an Uber?
  metadata:
    failure_modes:
    - Wrong tool called
    worker_explanation: 'The Agent called for my current location instead of calling for the location of the bar I had mentioned
      or asking for clarification as to where my friends apartment is. The model should be unsure if the users current location
      "3 blocks away from me" is the same as the location which will be returned by `get_user_location()` and therefore should
      ask for clarification as to where the friends house is. '
- name: Entry 249
  tools:
  - find_bathroom
  - rate
  - details
  messages:
  - I really need to pee, I can barely hold it!!  I'm in 34 W 52nd St., Manhattan NY.  Find me somewhere I can go, hurry!!!!
  metadata:
    failure_modes:
    - Missing parameter
    worker_explanation: "My approach focused on taking an explicit requirement and rewording the prompt to make it implicit-yet-obvious,\
      \ with the hypothesis that this could trip-up the AI model to fail to set a thoroughly necessary API flag in the process.\r\
      \n\r\nTo demonstrate:\r\n\r\nIn prior conversations, I tried:\r\n\r\n`I really need to pee, I can barely hold it!! \
      \ I'm in 34 W 52nd St., Manhattan NY.  Find me somewhere I can go now, hurry!!!!`\r\n\r\nThis resulted in the model\
      \ outputting:\r\n\r\n`[find_bathroom(center=\"34 W 52nd St., Manhattan NY\", open_now=True)]`\r\n\r\nHowever, simply\
      \ removing the word `now` from the prompt – while keeping the rest identical – was enough to get the model to ignore\
      \ the urgency and fail to set the flag in question.\r\n\r\nAs such, this served as a test of the model's handling of\
      \ Ambiguity in wording, through Implicit directives in the user's instructions."
